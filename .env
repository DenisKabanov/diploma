DATA_DIR = "../data/" # путь до папки с данными
RESULTS_DIR = "../results/" # путь до папки с результатами вычислений
EMBEDDING_DIR = "../embeddings/" # путь до папки с эмбеддингами
MODELS_DIR = "../models/" # путь до папки с моделями
MODEL_NAME = "utrobinmv/t5_translate_en_ru_zh_small_1024" # название модели для перевода
DATASET_NAME_HF = "aiana94/polynews-parallel" # название датасета на huggingface
DATASET_NAME_LOC = "polynews-parallel" # название, под которым датасет будет сохранён локально (+ с предобработкой)

MAX_SEQUENCE_LEN = 256 # оптимальное число токенов в документе (если не достаёт — padding, если перебор — truncation), определялось по гистограмме распределения числа токенов в текстах
FP16 = 0 # Использовать ли вычисление в fp16 (1 — да, 0 — нет)

RANDOM_STATE = 42 # число для задания случайности
TEST_SIZE = 0.2 # CHANGE!!! размер тестовой выборки
TEST_MAX_SAMPLES = 10 # CHANGE!!! максимальное число тестовых примеров (max 35289 при TEST_SIZE==0.2)
TRAIN_MAX_SAMPLES = 50 # CHANGE!!! максимальное число обучающих примеров (max 141152 при TEST_SIZE==0.2)

EPOCHS = 10 # CHANGE!!! число эпох обучения
EPOCHS_PATIENCE = 3 # число эпох без изменения наблюдаемой метрики, после которого обучение прекратится
LEARNING_RATE = 0.00001 # learning rate
BATCH_SIZE = 2 # CHANGE!!! размер батча (число сэмплов, передаваемых в модель одновременно => чем больше значение - тем быстрее обучение, но хуже качество из-за аккумуляции градиентов)
