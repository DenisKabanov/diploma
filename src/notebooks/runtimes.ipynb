{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Asjk9Y6jI49"
      },
      "outputs": [],
      "source": [
        "# !pip install evaluate\n",
        "# !pip install onnx\n",
        "# !pip install onnxruntime\n",
        "# !pip install datasets==3.3.1\n",
        "# # !pip install optimum\n",
        "# !pip install openvino\n",
        "# !pip install openvino-dev\n",
        "# !pip install optimum-executorch@git+https://github.com/huggingface/optimum-executorch.git\n",
        "# !pip install --upgrade --upgrade-strategy eager \"optimum[openvino]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "4orUPY6bhxP7",
        "outputId": "1a284353-3adb-4457-d29a-5ca351be7ad2"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        }
      ],
      "source": [
        "import os # для взаимодействия с системой\n",
        "import numpy as np # для работы с массивами\n",
        "import pandas as pd # для удобной работы с датасетом\n",
        "import random as random # для работы со случайностью\n",
        "import json # для сохранения и загрузки объектов\n",
        "from tqdm.auto import tqdm # для отслеживания прогресса\n",
        "\n",
        "from datasets import Dataset, load_dataset, load_from_disk # для работы с HuggingFace датасетами\n",
        "\n",
        "import time # для отслеживания времени выполнения\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import evaluate # для подсчёта метрик\n",
        "\n",
        "\n",
        "# PyTorch Runtime\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# ExecuTorch\n",
        "from optimum.executorch import ExecuTorchModelForSeq2SeqLM\n",
        "\n",
        "# ONNX\n",
        "from optimum.onnxruntime import ORTModelForSeq2SeqLM\n",
        "\n",
        "# OpenVINO (ломает ExecuTorch, поэтому импорт будет в соответствующих блоках)\n",
        "# from optimum.intel.openvino import OVModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTfyF6WdiqLp",
        "outputId": "a44eb37c-1caa-428c-945e-4a04dd8433e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xErxc56ChxP9"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/tmp/data/\"\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/tmp/results/\"\n",
        "MODELS_DIR = \"/content/drive/MyDrive/tmp/models/\"\n",
        "MODEL_NAME = \"t5_pruned_0.2_finetuned\"\n",
        "DATASET_NAME_HF = \"aiana94/polynews-parallel\" # название датасета на huggingface\n",
        "DATASET_NAME_LOC = \"polynews-parallel\" # название, под которым датасет будет сохранён локально (+ с предобработкой)\n",
        "\n",
        "MAX_SEQUENCE_LEN = 256\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "TEST_MAX_SAMPLES = 5000\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JKZrDZohxP-",
        "outputId": "5b17160f-fa82-4820-ea65-4d07e1f3e73c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Status: \n",
            "      DATA_DIR: /content/drive/MyDrive/tmp/data/\n",
            "      RESULTS_DIR: /content/drive/MyDrive/tmp/results/\n",
            "      MODELS_DIR: /content/drive/MyDrive/tmp/models/\n",
            "      MODEL_NAME: t5_pruned_0.2_finetuned\n",
            "      DATASET_NAME_HF: aiana94/polynews-parallel\n",
            "      DATASET_NAME_LOC: polynews-parallel\n",
            "      MAX_SEQUENCE_LEN: 256\n",
            "      RANDOM_STATE: 42\n",
            "      TEST_SIZE: 0.2\n",
            "      TEST_MAX_SAMPLES: 5000\n",
            "      DEVICE: cpu\n",
            "      \n"
          ]
        }
      ],
      "source": [
        "print(f\"Status: \\n\\\n",
        "      DATA_DIR: {DATA_DIR}\\n\\\n",
        "      RESULTS_DIR: {RESULTS_DIR}\\n\\\n",
        "      MODELS_DIR: {MODELS_DIR}\\n\\\n",
        "      MODEL_NAME: {MODEL_NAME}\\n\\\n",
        "      DATASET_NAME_HF: {DATASET_NAME_HF}\\n\\\n",
        "      DATASET_NAME_LOC: {DATASET_NAME_LOC}\\n\\\n",
        "      MAX_SEQUENCE_LEN: {MAX_SEQUENCE_LEN}\\n\\\n",
        "      RANDOM_STATE: {RANDOM_STATE}\\n\\\n",
        "      TEST_SIZE: {TEST_SIZE}\\n\\\n",
        "      TEST_MAX_SAMPLES: {TEST_MAX_SAMPLES}\\n\\\n",
        "      DEVICE: {DEVICE}\\n\\\n",
        "      \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uQIcewOhxQA"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uGZIT_VAi6bB"
      },
      "outputs": [],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(MODELS_DIR + MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5BvMnHuhxQB",
        "outputId": "7dcae2c0-4c20-40d2-82bf-6b40eb7f8add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Датасет по пути /content/drive/MyDrive/tmp/data/polynews-parallel уже был сохранён ранее, используем его!\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(DATA_DIR + DATASET_NAME_LOC):\n",
        "    print(\"Скачиваю и сохраняю датасет...\")\n",
        "    dataset = load_dataset(DATASET_NAME_HF, name=\"eng_Latn-rus_Cyrl\") # скачивание датасета, name — название subset_а с HuggingFace\n",
        "    dataset.save_to_disk(DATA_DIR + DATASET_NAME_LOC) # локальное сохранение датасета (в формате arrow)\n",
        "else:\n",
        "    print(f\"Датасет по пути {DATA_DIR + DATASET_NAME_LOC} уже был сохранён ранее, используем его!\")\n",
        "    dataset = load_from_disk(DATA_DIR + DATASET_NAME_LOC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG1jKeqFhxQB",
        "outputId": "5975ca26-f851-403a-92fc-f7e2bc84cfcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Датасет по пути /content/drive/MyDrive/tmp/data/polynews-parallel_t5_processed уже был сохранён ранее, используем его!\n"
          ]
        }
      ],
      "source": [
        "def preprocess_function(data: Dataset, random_state=RANDOM_STATE):\n",
        "    random.seed(random_state) # Set the random number generator to a fixed sequence.\n",
        "    samples_count = len(dataset[\"train\"]) # общее число сэмплов в датасете\n",
        "\n",
        "    reflected_idx = set(random.sample(range(0, samples_count), int(samples_count/2))) # индексы отражаемых сэмплов (set — для сортировки и удобного вычитания)\n",
        "    regular_idx = set(range(0, samples_count)) - reflected_idx\n",
        "\n",
        "    data[\"new_src\"] = [\"translate to ru: \" + sample if idx in regular_idx else \"translate to en: \" + data[\"tgt\"][idx] for idx, sample in enumerate(data[\"src\"])]\n",
        "    data[\"new_tgt\"] = [sample if idx in regular_idx else data[\"src\"][idx] for idx, sample in enumerate(data[\"tgt\"])]\n",
        "    model_inputs = tokenizer(data[\"new_src\"], text_target=data[\"new_tgt\"], max_length=MAX_SEQUENCE_LEN, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "if not os.path.exists(DATA_DIR + DATASET_NAME_LOC + \"_t5_processed\"):\n",
        "    print(\"Обрабатываю датасет и сохраняю...\")\n",
        "    dataset = dataset.map(preprocess_function, batched=True)\n",
        "    dataset = dataset.remove_columns([\"provenance\", \"src\", \"tgt\"]) # удаление ненужной колонки\n",
        "    dataset = dataset.rename_column(\"new_src\", \"src\") # переименовываем колонку\n",
        "    dataset = dataset.rename_column(\"new_tgt\", \"tgt\") # переименовываем колонку\n",
        "    dataset = dataset[\"train\"].train_test_split(test_size=TEST_SIZE, shuffle=True, seed=RANDOM_STATE) # разбиение датасета на тестовую и обучающую выборки\n",
        "\n",
        "    dataset.save_to_disk(DATA_DIR + DATASET_NAME_LOC + \"_t5_processed\") # локальное сохранение датасета (в формате arrow)\n",
        "else:\n",
        "    print(f\"Датасет по пути {DATA_DIR + DATASET_NAME_LOC + '_t5_processed'} уже был сохранён ранее, используем его!\")\n",
        "    dataset = load_from_disk(DATA_DIR + DATASET_NAME_LOC + \"_t5_processed\")\n",
        "\n",
        "\n",
        "dataset[\"test\"] = dataset[\"test\"].select(range(TEST_MAX_SAMPLES))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqr34bPVhxQC"
      },
      "source": [
        "# Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "18qRntVJhxQC"
      },
      "outputs": [],
      "source": [
        "tokens_count, latency, translations = {}, {}, {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVTTyasJhxQM"
      },
      "source": [
        "## ExecuTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x6iBTtg64r6"
      },
      "source": [
        "Почему-то если использовать её не первой, то загрузить её не получиться..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2xCmanWhxQN",
        "outputId": "4da4d0de-1ee7-47df-9e26-743a708bd148"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/executorch/exir/emit/_emitter.py:1592: UserWarning: Mutation on a buffer in the model is detected. ExecuTorch assumes buffers that are mutated in the graph have a meaningless initial state, only the shape and dtype will be serialized, unless a pass which sets meta[\"et_init_buffer\"] to True such as InitializedMutableBufferPass is run.\n",
            "  warnings.warn(\n",
            "Too many ExecuTorch model files were found in /tmp/tmpudzkx779/encoder.pte ,/tmp/tmpudzkx779/decoder.pte. specify which one to load by using the `file_name` and/or the `subfolder` arguments. Loading the file encoder.pte in the subfolder /tmp/tmpudzkx779.\n",
            "[program.cpp:135] InternalConsistency verification requested but not available\n",
            "Too many ExecuTorch model files were found in /tmp/tmpudzkx779/encoder.pte ,/tmp/tmpudzkx779/decoder.pte. specify which one to load by using the `file_name` and/or the `subfolder` arguments. Loading the file decoder.pte in the subfolder /tmp/tmpudzkx779.\n",
            "[program.cpp:135] InternalConsistency verification requested but not available\n"
          ]
        }
      ],
      "source": [
        "model_exet = ExecuTorchModelForSeq2SeqLM.from_pretrained(MODELS_DIR + MODEL_NAME, export=True, recipe=\"xnnpack\", attn_implementation=\"custom_sdpa\") # export — для моделей трансформеров с версии optimum>=2.0, from_transformers — для optimum<2.0\n",
        "# модель нельзя сохранить, так как эта фича пока не имплементирована..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5ZASTU3hhxQN"
      },
      "outputs": [],
      "source": [
        "def translate_exet(model, tokenizer, texts) -> tuple:\n",
        "    tokens_count = [] # список под количество токенов в тексте\n",
        "    latency = [] # список под величину задержки между запуском модели и выводом ответа\n",
        "    translations = [] # список под переводы\n",
        "\n",
        "    if isinstance(texts, str): # если пришёл объект типа строки\n",
        "        texts = [texts] # делаем из объекта список с одним элементом\n",
        "    elif isinstance(texts, Dataset) or isinstance(texts, dict): # если пришёл объект типа Dataset или словарь (полученный с помощью среза объекта Dataset)\n",
        "        texts = texts[\"src\"] # берём из него только текста, что нужно переводить\n",
        "\n",
        "    for text in tqdm(texts):\n",
        "        time_start = time.time() # замеряем время начала работы  с моделью\n",
        "        generated_text = model.text_generation(\n",
        "            tokenizer=tokenizer,\n",
        "            prompt=text,\n",
        "        )\n",
        "        latency.append(time.time()  - time_start)\n",
        "\n",
        "        tokens_encoded = tokenizer(text, max_length=MAX_SEQUENCE_LEN, return_tensors=\"pt\", truncation=True, padding=True) # токенизируем данные (max_length — максимальное число токенов в документе, return_tensors — тип возвращаемых данных, np для numpy.array, pt для torch.tensor; truncation и padding — обрезание лишних токенов и автозаполнение недостающих до max_length)\n",
        "        tokens_count.append(tokens_encoded[\"input_ids\"].shape[1]) # запоминаем количество токенов\n",
        "        translations.append(generated_text) # декодирование последовательности токенов, skip_special_tokens — выводить ли специальные токены\n",
        "    return tokens_count, latency, translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f43cf28e61fc4bada1a957b33290c295",
            "0b30ac49f9d748b497589b694bc35051",
            "69f1c49395ce4978ac7e8bb6342174b4",
            "96028b1182774d09bbf5b0dfe617bbe6",
            "89eb3b78d1054a21916213b4c061eec7",
            "a4782776578346d58e929e3dc0f33b2e",
            "6fb6d72af4684caa9ada9fd29efd74a9",
            "98a55910e5224b41804912c6ac68fb5b",
            "43505cac29dc40c19c8181b12e81d10b",
            "87378b29de5741288730e23800f80097",
            "838d57a56a5e40cca724b2c814ad1c8a"
          ]
        },
        "id": "GK3d8xkBhxQN",
        "outputId": "bf1114a8-8a0b-47e0-d399-f8ef7940d655"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f43cf28e61fc4bada1a957b33290c295",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "PyTorchObserver {\"prompt_tokens\": 36, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876165207, \"token_encode_end_ms\": 1747876165207, \"model_execution_start_ms\": 1747876166727, \"model_execution_end_ms\": 1747876166777, \"inference_end_ms\": 1747876166777, \"prompt_eval_end_ms\": 1747876165256, \"first_token_ms\": 1747876165306, \"aggregate_sampling_time_ms\": 1562, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 36 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.570000 (seconds)\t\t Rate: \t18.471338 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.049000 (seconds)\t\t Rate: \t734.693878 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.521000 (seconds)\t\t Rate: \t19.066404 (tokens/second)\n",
            "\tTime to first generated token:\t0.099000 (seconds)\n",
            "\tSampling time over 65 tokens:\t1.562000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 35, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876166789, \"token_encode_end_ms\": 1747876166790, \"model_execution_start_ms\": 1747876168519, \"model_execution_end_ms\": 1747876168621, \"inference_end_ms\": 1747876168631, \"prompt_eval_end_ms\": 1747876166842, \"first_token_ms\": 1747876166889, \"aggregate_sampling_time_ms\": 1833, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 35 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.842000 (seconds)\t\t Rate: \t11.943540 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t660.377358 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.789000 (seconds)\t\t Rate: \t12.297373 (tokens/second)\n",
            "\tTime to first generated token:\t0.100000 (seconds)\n",
            "\tSampling time over 57 tokens:\t1.833000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 51, \"generated_tokens\": 50, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876168638, \"token_encode_end_ms\": 1747876168639, \"model_execution_start_ms\": 1747876172048, \"model_execution_end_ms\": 1747876172098, \"inference_end_ms\": 1747876172099, \"prompt_eval_end_ms\": 1747876168821, \"first_token_ms\": 1747876169003, \"aggregate_sampling_time_ms\": 3442, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 51 Generated Tokens: 50\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.461000 (seconds)\t\t Rate: \t14.446692 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.183000 (seconds)\t\t Rate: \t278.688525 (tokens/second)\n",
            "\t\tGenerated 50 tokens:\t3.278000 (seconds)\t\t Rate: \t15.253203 (tokens/second)\n",
            "\tTime to first generated token:\t0.365000 (seconds)\n",
            "\tSampling time over 101 tokens:\t3.442000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 55, \"generated_tokens\": 52, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876172115, \"token_encode_end_ms\": 1747876172115, \"model_execution_start_ms\": 1747876174891, \"model_execution_end_ms\": 1747876174941, \"inference_end_ms\": 1747876174941, \"prompt_eval_end_ms\": 1747876172176, \"first_token_ms\": 1747876172227, \"aggregate_sampling_time_ms\": 2814, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 55 Generated Tokens: 52\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.826000 (seconds)\t\t Rate: \t18.400566 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t901.639344 (tokens/second)\n",
            "\t\tGenerated 52 tokens:\t2.765000 (seconds)\t\t Rate: \t18.806510 (tokens/second)\n",
            "\tTime to first generated token:\t0.112000 (seconds)\n",
            "\tSampling time over 107 tokens:\t2.814000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 49, \"generated_tokens\": 40, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876174956, \"token_encode_end_ms\": 1747876174957, \"model_execution_start_ms\": 1747876177058, \"model_execution_end_ms\": 1747876177108, \"inference_end_ms\": 1747876177108, \"prompt_eval_end_ms\": 1747876175014, \"first_token_ms\": 1747876175063, \"aggregate_sampling_time_ms\": 2139, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 49 Generated Tokens: 40\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.152000 (seconds)\t\t Rate: \t18.587361 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t844.827586 (tokens/second)\n",
            "\t\tGenerated 40 tokens:\t2.094000 (seconds)\t\t Rate: \t19.102197 (tokens/second)\n",
            "\tTime to first generated token:\t0.107000 (seconds)\n",
            "\tSampling time over 89 tokens:\t2.139000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 13, \"generated_tokens\": 13, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876177123, \"token_encode_end_ms\": 1747876177123, \"model_execution_start_ms\": 1747876177743, \"model_execution_end_ms\": 1747876177791, \"inference_end_ms\": 1747876177791, \"prompt_eval_end_ms\": 1747876177150, \"first_token_ms\": 1747876177196, \"aggregate_sampling_time_ms\": 667, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 13 Generated Tokens: 13\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.668000 (seconds)\t\t Rate: \t19.461078 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.027000 (seconds)\t\t Rate: \t481.481481 (tokens/second)\n",
            "\t\tGenerated 13 tokens:\t0.641000 (seconds)\t\t Rate: \t20.280811 (tokens/second)\n",
            "\tTime to first generated token:\t0.073000 (seconds)\n",
            "\tSampling time over 26 tokens:\t0.667000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 60, \"generated_tokens\": 52, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876177797, \"token_encode_end_ms\": 1747876177798, \"model_execution_start_ms\": 1747876182073, \"model_execution_end_ms\": 1747876182125, \"inference_end_ms\": 1747876182125, \"prompt_eval_end_ms\": 1747876177868, \"first_token_ms\": 1747876177918, \"aggregate_sampling_time_ms\": 4314, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 60 Generated Tokens: 52\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t4.328000 (seconds)\t\t Rate: \t12.014787 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.071000 (seconds)\t\t Rate: \t845.070423 (tokens/second)\n",
            "\t\tGenerated 52 tokens:\t4.257000 (seconds)\t\t Rate: \t12.215175 (tokens/second)\n",
            "\tTime to first generated token:\t0.121000 (seconds)\n",
            "\tSampling time over 112 tokens:\t4.314000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 22, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876182142, \"token_encode_end_ms\": 1747876182142, \"model_execution_start_ms\": 1747876183319, \"model_execution_end_ms\": 1747876183366, \"inference_end_ms\": 1747876183366, \"prompt_eval_end_ms\": 1747876182178, \"first_token_ms\": 1747876182227, \"aggregate_sampling_time_ms\": 1214, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 22 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.224000 (seconds)\t\t Rate: \t19.607843 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.036000 (seconds)\t\t Rate: \t611.111111 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.188000 (seconds)\t\t Rate: \t20.202020 (tokens/second)\n",
            "\tTime to first generated token:\t0.085000 (seconds)\n",
            "\tSampling time over 46 tokens:\t1.214000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 31, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876183380, \"token_encode_end_ms\": 1747876183381, \"model_execution_start_ms\": 1747876184947, \"model_execution_end_ms\": 1747876184995, \"inference_end_ms\": 1747876184996, \"prompt_eval_end_ms\": 1747876183432, \"first_token_ms\": 1747876183480, \"aggregate_sampling_time_ms\": 1611, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 31\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.616000 (seconds)\t\t Rate: \t19.183168 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.052000 (seconds)\t\t Rate: \t576.923077 (tokens/second)\n",
            "\t\tGenerated 31 tokens:\t1.564000 (seconds)\t\t Rate: \t19.820972 (tokens/second)\n",
            "\tTime to first generated token:\t0.100000 (seconds)\n",
            "\tSampling time over 61 tokens:\t1.611000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 17, \"generated_tokens\": 10, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876185005, \"token_encode_end_ms\": 1747876185006, \"model_execution_start_ms\": 1747876185483, \"model_execution_end_ms\": 1747876185531, \"inference_end_ms\": 1747876185531, \"prompt_eval_end_ms\": 1747876185040, \"first_token_ms\": 1747876185087, \"aggregate_sampling_time_ms\": 521, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 17 Generated Tokens: 10\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.526000 (seconds)\t\t Rate: \t19.011407 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.035000 (seconds)\t\t Rate: \t485.714286 (tokens/second)\n",
            "\t\tGenerated 10 tokens:\t0.491000 (seconds)\t\t Rate: \t20.366599 (tokens/second)\n",
            "\tTime to first generated token:\t0.082000 (seconds)\n",
            "\tSampling time over 27 tokens:\t0.521000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 24, \"generated_tokens\": 15, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876185537, \"token_encode_end_ms\": 1747876185537, \"model_execution_start_ms\": 1747876186284, \"model_execution_end_ms\": 1747876186331, \"inference_end_ms\": 1747876186331, \"prompt_eval_end_ms\": 1747876185578, \"first_token_ms\": 1747876185626, \"aggregate_sampling_time_ms\": 790, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 24 Generated Tokens: 15\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.794000 (seconds)\t\t Rate: \t18.891688 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.041000 (seconds)\t\t Rate: \t585.365854 (tokens/second)\n",
            "\t\tGenerated 15 tokens:\t0.753000 (seconds)\t\t Rate: \t19.920319 (tokens/second)\n",
            "\tTime to first generated token:\t0.089000 (seconds)\n",
            "\tSampling time over 39 tokens:\t0.790000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876186337, \"token_encode_end_ms\": 1747876186337, \"model_execution_start_ms\": 1747876187481, \"model_execution_end_ms\": 1747876187529, \"inference_end_ms\": 1747876187530, \"prompt_eval_end_ms\": 1747876186390, \"first_token_ms\": 1747876186437, \"aggregate_sampling_time_ms\": 1187, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.193000 (seconds)\t\t Rate: \t19.279128 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t509.433962 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.140000 (seconds)\t\t Rate: \t20.175439 (tokens/second)\n",
            "\tTime to first generated token:\t0.100000 (seconds)\n",
            "\tSampling time over 50 tokens:\t1.187000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 20, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876187538, \"token_encode_end_ms\": 1747876187538, \"model_execution_start_ms\": 1747876188539, \"model_execution_end_ms\": 1747876188587, \"inference_end_ms\": 1747876188587, \"prompt_eval_end_ms\": 1747876187584, \"first_token_ms\": 1747876187631, \"aggregate_sampling_time_ms\": 1042, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 20\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.049000 (seconds)\t\t Rate: \t19.065777 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t586.956522 (tokens/second)\n",
            "\t\tGenerated 20 tokens:\t1.003000 (seconds)\t\t Rate: \t19.940179 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 47 tokens:\t1.042000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 24, \"generated_tokens\": 18, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876188591, \"token_encode_end_ms\": 1747876188591, \"model_execution_start_ms\": 1747876189507, \"model_execution_end_ms\": 1747876189555, \"inference_end_ms\": 1747876189556, \"prompt_eval_end_ms\": 1747876188628, \"first_token_ms\": 1747876188694, \"aggregate_sampling_time_ms\": 959, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 24 Generated Tokens: 18\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.965000 (seconds)\t\t Rate: \t18.652850 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.037000 (seconds)\t\t Rate: \t648.648649 (tokens/second)\n",
            "\t\tGenerated 18 tokens:\t0.928000 (seconds)\t\t Rate: \t19.396552 (tokens/second)\n",
            "\tTime to first generated token:\t0.103000 (seconds)\n",
            "\tSampling time over 42 tokens:\t0.959000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 52, \"generated_tokens\": 46, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876189568, \"token_encode_end_ms\": 1747876189569, \"model_execution_start_ms\": 1747876192045, \"model_execution_end_ms\": 1747876192147, \"inference_end_ms\": 1747876192147, \"prompt_eval_end_ms\": 1747876189629, \"first_token_ms\": 1747876189682, \"aggregate_sampling_time_ms\": 2559, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 52 Generated Tokens: 46\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.579000 (seconds)\t\t Rate: \t17.836371 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t852.459016 (tokens/second)\n",
            "\t\tGenerated 46 tokens:\t2.518000 (seconds)\t\t Rate: \t18.268467 (tokens/second)\n",
            "\tTime to first generated token:\t0.114000 (seconds)\n",
            "\tSampling time over 98 tokens:\t2.559000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 34, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876192157, \"token_encode_end_ms\": 1747876192157, \"model_execution_start_ms\": 1747876195270, \"model_execution_end_ms\": 1747876195318, \"inference_end_ms\": 1747876195318, \"prompt_eval_end_ms\": 1747876192273, \"first_token_ms\": 1747876192392, \"aggregate_sampling_time_ms\": 3149, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 34\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.161000 (seconds)\t\t Rate: \t10.756090 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.116000 (seconds)\t\t Rate: \t258.620690 (tokens/second)\n",
            "\t\tGenerated 34 tokens:\t3.045000 (seconds)\t\t Rate: \t11.165846 (tokens/second)\n",
            "\tTime to first generated token:\t0.235000 (seconds)\n",
            "\tSampling time over 64 tokens:\t3.149000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 26, \"generated_tokens\": 26, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876195327, \"token_encode_end_ms\": 1747876195327, \"model_execution_start_ms\": 1747876196668, \"model_execution_end_ms\": 1747876196718, \"inference_end_ms\": 1747876196718, \"prompt_eval_end_ms\": 1747876195373, \"first_token_ms\": 1747876195423, \"aggregate_sampling_time_ms\": 1385, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 26 Generated Tokens: 26\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.391000 (seconds)\t\t Rate: \t18.691589 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t565.217391 (tokens/second)\n",
            "\t\tGenerated 26 tokens:\t1.345000 (seconds)\t\t Rate: \t19.330855 (tokens/second)\n",
            "\tTime to first generated token:\t0.096000 (seconds)\n",
            "\tSampling time over 52 tokens:\t1.385000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 26, \"generated_tokens\": 21, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876196732, \"token_encode_end_ms\": 1747876196733, \"model_execution_start_ms\": 1747876197780, \"model_execution_end_ms\": 1747876197829, \"inference_end_ms\": 1747876197829, \"prompt_eval_end_ms\": 1747876196770, \"first_token_ms\": 1747876196820, \"aggregate_sampling_time_ms\": 1088, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 26 Generated Tokens: 21\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.097000 (seconds)\t\t Rate: \t19.143118 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.038000 (seconds)\t\t Rate: \t684.210526 (tokens/second)\n",
            "\t\tGenerated 21 tokens:\t1.059000 (seconds)\t\t Rate: \t19.830028 (tokens/second)\n",
            "\tTime to first generated token:\t0.088000 (seconds)\n",
            "\tSampling time over 47 tokens:\t1.088000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 14, \"generated_tokens\": 8, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876197833, \"token_encode_end_ms\": 1747876197833, \"model_execution_start_ms\": 1747876198243, \"model_execution_end_ms\": 1747876198289, \"inference_end_ms\": 1747876198289, \"prompt_eval_end_ms\": 1747876197850, \"first_token_ms\": 1747876197914, \"aggregate_sampling_time_ms\": 455, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 14 Generated Tokens: 8\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.456000 (seconds)\t\t Rate: \t17.543860 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.017000 (seconds)\t\t Rate: \t823.529412 (tokens/second)\n",
            "\t\tGenerated 8 tokens:\t0.439000 (seconds)\t\t Rate: \t18.223235 (tokens/second)\n",
            "\tTime to first generated token:\t0.081000 (seconds)\n",
            "\tSampling time over 22 tokens:\t0.455000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 16, \"generated_tokens\": 10, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876198300, \"token_encode_end_ms\": 1747876198301, \"model_execution_start_ms\": 1747876198778, \"model_execution_end_ms\": 1747876198825, \"inference_end_ms\": 1747876198825, \"prompt_eval_end_ms\": 1747876198332, \"first_token_ms\": 1747876198378, \"aggregate_sampling_time_ms\": 522, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 16 Generated Tokens: 10\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.525000 (seconds)\t\t Rate: \t19.047619 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.032000 (seconds)\t\t Rate: \t500.000000 (tokens/second)\n",
            "\t\tGenerated 10 tokens:\t0.493000 (seconds)\t\t Rate: \t20.283976 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 26 tokens:\t0.522000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 12, \"generated_tokens\": 6, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876198838, \"token_encode_end_ms\": 1747876198838, \"model_execution_start_ms\": 1747876199110, \"model_execution_end_ms\": 1747876199156, \"inference_end_ms\": 1747876199156, \"prompt_eval_end_ms\": 1747876198862, \"first_token_ms\": 1747876198907, \"aggregate_sampling_time_ms\": 318, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 12 Generated Tokens: 6\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.318000 (seconds)\t\t Rate: \t18.867925 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.024000 (seconds)\t\t Rate: \t500.000000 (tokens/second)\n",
            "\t\tGenerated 6 tokens:\t0.294000 (seconds)\t\t Rate: \t20.408163 (tokens/second)\n",
            "\tTime to first generated token:\t0.069000 (seconds)\n",
            "\tSampling time over 18 tokens:\t0.318000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 21, \"generated_tokens\": 14, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876199159, \"token_encode_end_ms\": 1747876199159, \"model_execution_start_ms\": 1747876199858, \"model_execution_end_ms\": 1747876199905, \"inference_end_ms\": 1747876199905, \"prompt_eval_end_ms\": 1747876199202, \"first_token_ms\": 1747876199269, \"aggregate_sampling_time_ms\": 734, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 21 Generated Tokens: 14\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.746000 (seconds)\t\t Rate: \t18.766756 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t488.372093 (tokens/second)\n",
            "\t\tGenerated 14 tokens:\t0.703000 (seconds)\t\t Rate: \t19.914651 (tokens/second)\n",
            "\tTime to first generated token:\t0.110000 (seconds)\n",
            "\tSampling time over 35 tokens:\t0.734000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 79, \"generated_tokens\": 92, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876199908, \"token_encode_end_ms\": 1747876199909, \"model_execution_start_ms\": 1747876206771, \"model_execution_end_ms\": 1747876206824, \"inference_end_ms\": 1747876206824, \"prompt_eval_end_ms\": 1747876199994, \"first_token_ms\": 1747876200047, \"aggregate_sampling_time_ms\": 6888, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 79 Generated Tokens: 92\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t6.916000 (seconds)\t\t Rate: \t13.302487 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.086000 (seconds)\t\t Rate: \t918.604651 (tokens/second)\n",
            "\t\tGenerated 92 tokens:\t6.830000 (seconds)\t\t Rate: \t13.469985 (tokens/second)\n",
            "\tTime to first generated token:\t0.139000 (seconds)\n",
            "\tSampling time over 171 tokens:\t6.888000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 43, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876206840, \"token_encode_end_ms\": 1747876206841, \"model_execution_start_ms\": 1747876208856, \"model_execution_end_ms\": 1747876208904, \"inference_end_ms\": 1747876208905, \"prompt_eval_end_ms\": 1747876206897, \"first_token_ms\": 1747876206945, \"aggregate_sampling_time_ms\": 2052, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 43 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.065000 (seconds)\t\t Rate: \t18.886199 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.057000 (seconds)\t\t Rate: \t754.385965 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t2.008000 (seconds)\t\t Rate: \t19.422311 (tokens/second)\n",
            "\tTime to first generated token:\t0.105000 (seconds)\n",
            "\tSampling time over 82 tokens:\t2.052000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 54, \"generated_tokens\": 43, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876208920, \"token_encode_end_ms\": 1747876208920, \"model_execution_start_ms\": 1747876211184, \"model_execution_end_ms\": 1747876211237, \"inference_end_ms\": 1747876211237, \"prompt_eval_end_ms\": 1747876208981, \"first_token_ms\": 1747876209031, \"aggregate_sampling_time_ms\": 2295, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 54 Generated Tokens: 43\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.317000 (seconds)\t\t Rate: \t18.558481 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t885.245902 (tokens/second)\n",
            "\t\tGenerated 43 tokens:\t2.256000 (seconds)\t\t Rate: \t19.060284 (tokens/second)\n",
            "\tTime to first generated token:\t0.111000 (seconds)\n",
            "\tSampling time over 97 tokens:\t2.295000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 55, \"generated_tokens\": 51, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876211245, \"token_encode_end_ms\": 1747876211246, \"model_execution_start_ms\": 1747876213976, \"model_execution_end_ms\": 1747876214026, \"inference_end_ms\": 1747876214027, \"prompt_eval_end_ms\": 1747876211312, \"first_token_ms\": 1747876211364, \"aggregate_sampling_time_ms\": 2768, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 55 Generated Tokens: 51\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.782000 (seconds)\t\t Rate: \t18.332135 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.067000 (seconds)\t\t Rate: \t820.895522 (tokens/second)\n",
            "\t\tGenerated 51 tokens:\t2.715000 (seconds)\t\t Rate: \t18.784530 (tokens/second)\n",
            "\tTime to first generated token:\t0.119000 (seconds)\n",
            "\tSampling time over 106 tokens:\t2.768000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 20, \"generated_tokens\": 13, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876214042, \"token_encode_end_ms\": 1747876214043, \"model_execution_start_ms\": 1747876214661, \"model_execution_end_ms\": 1747876214710, \"inference_end_ms\": 1747876214711, \"prompt_eval_end_ms\": 1747876214076, \"first_token_ms\": 1747876214124, \"aggregate_sampling_time_ms\": 665, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 20 Generated Tokens: 13\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.669000 (seconds)\t\t Rate: \t19.431988 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.034000 (seconds)\t\t Rate: \t588.235294 (tokens/second)\n",
            "\t\tGenerated 13 tokens:\t0.635000 (seconds)\t\t Rate: \t20.472441 (tokens/second)\n",
            "\tTime to first generated token:\t0.082000 (seconds)\n",
            "\tSampling time over 33 tokens:\t0.665000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 27, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876214717, \"token_encode_end_ms\": 1747876214717, \"model_execution_start_ms\": 1747876216105, \"model_execution_end_ms\": 1747876216152, \"inference_end_ms\": 1747876216153, \"prompt_eval_end_ms\": 1747876214788, \"first_token_ms\": 1747876214836, \"aggregate_sampling_time_ms\": 1428, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 27\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.436000 (seconds)\t\t Rate: \t18.802228 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.071000 (seconds)\t\t Rate: \t464.788732 (tokens/second)\n",
            "\t\tGenerated 27 tokens:\t1.365000 (seconds)\t\t Rate: \t19.780220 (tokens/second)\n",
            "\tTime to first generated token:\t0.119000 (seconds)\n",
            "\tSampling time over 60 tokens:\t1.428000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 42, \"generated_tokens\": 42, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876216160, \"token_encode_end_ms\": 1747876216160, \"model_execution_start_ms\": 1747876219742, \"model_execution_end_ms\": 1747876219791, \"inference_end_ms\": 1747876219792, \"prompt_eval_end_ms\": 1747876216214, \"first_token_ms\": 1747876216262, \"aggregate_sampling_time_ms\": 3611, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 42 Generated Tokens: 42\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.632000 (seconds)\t\t Rate: \t11.563877 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.054000 (seconds)\t\t Rate: \t777.777778 (tokens/second)\n",
            "\t\tGenerated 42 tokens:\t3.578000 (seconds)\t\t Rate: \t11.738401 (tokens/second)\n",
            "\tTime to first generated token:\t0.102000 (seconds)\n",
            "\tSampling time over 84 tokens:\t3.611000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 27, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876219807, \"token_encode_end_ms\": 1747876219807, \"model_execution_start_ms\": 1747876221163, \"model_execution_end_ms\": 1747876221212, \"inference_end_ms\": 1747876221212, \"prompt_eval_end_ms\": 1747876219847, \"first_token_ms\": 1747876219896, \"aggregate_sampling_time_ms\": 1401, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 27\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.405000 (seconds)\t\t Rate: \t19.217082 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.040000 (seconds)\t\t Rate: \t750.000000 (tokens/second)\n",
            "\t\tGenerated 27 tokens:\t1.365000 (seconds)\t\t Rate: \t19.780220 (tokens/second)\n",
            "\tTime to first generated token:\t0.089000 (seconds)\n",
            "\tSampling time over 57 tokens:\t1.401000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 27, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876221218, \"token_encode_end_ms\": 1747876221220, \"model_execution_start_ms\": 1747876222570, \"model_execution_end_ms\": 1747876222618, \"inference_end_ms\": 1747876222618, \"prompt_eval_end_ms\": 1747876221267, \"first_token_ms\": 1747876221317, \"aggregate_sampling_time_ms\": 1384, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 27\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.400000 (seconds)\t\t Rate: \t19.285714 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.049000 (seconds)\t\t Rate: \t551.020408 (tokens/second)\n",
            "\t\tGenerated 27 tokens:\t1.351000 (seconds)\t\t Rate: \t19.985196 (tokens/second)\n",
            "\tTime to first generated token:\t0.099000 (seconds)\n",
            "\tSampling time over 54 tokens:\t1.384000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 17, \"generated_tokens\": 13, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876222627, \"token_encode_end_ms\": 1747876222628, \"model_execution_start_ms\": 1747876223263, \"model_execution_end_ms\": 1747876223310, \"inference_end_ms\": 1747876223311, \"prompt_eval_end_ms\": 1747876222664, \"first_token_ms\": 1747876222714, \"aggregate_sampling_time_ms\": 676, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 17 Generated Tokens: 13\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.684000 (seconds)\t\t Rate: \t19.005848 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.037000 (seconds)\t\t Rate: \t459.459459 (tokens/second)\n",
            "\t\tGenerated 13 tokens:\t0.647000 (seconds)\t\t Rate: \t20.092736 (tokens/second)\n",
            "\tTime to first generated token:\t0.087000 (seconds)\n",
            "\tSampling time over 30 tokens:\t0.676000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876223322, \"token_encode_end_ms\": 1747876223323, \"model_execution_start_ms\": 1747876224459, \"model_execution_end_ms\": 1747876224507, \"inference_end_ms\": 1747876224507, \"prompt_eval_end_ms\": 1747876223364, \"first_token_ms\": 1747876223411, \"aggregate_sampling_time_ms\": 1176, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.185000 (seconds)\t\t Rate: \t19.409283 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.042000 (seconds)\t\t Rate: \t690.476190 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.143000 (seconds)\t\t Rate: \t20.122485 (tokens/second)\n",
            "\tTime to first generated token:\t0.089000 (seconds)\n",
            "\tSampling time over 52 tokens:\t1.176000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 19, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876224517, \"token_encode_end_ms\": 1747876224517, \"model_execution_start_ms\": 1747876225295, \"model_execution_end_ms\": 1747876225341, \"inference_end_ms\": 1747876225341, \"prompt_eval_end_ms\": 1747876224551, \"first_token_ms\": 1747876224597, \"aggregate_sampling_time_ms\": 823, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 19 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.824000 (seconds)\t\t Rate: \t19.417476 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.034000 (seconds)\t\t Rate: \t558.823529 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.790000 (seconds)\t\t Rate: \t20.253165 (tokens/second)\n",
            "\tTime to first generated token:\t0.080000 (seconds)\n",
            "\tSampling time over 35 tokens:\t0.823000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 21, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876225354, \"token_encode_end_ms\": 1747876225354, \"model_execution_start_ms\": 1747876226501, \"model_execution_end_ms\": 1747876226548, \"inference_end_ms\": 1747876226548, \"prompt_eval_end_ms\": 1747876225386, \"first_token_ms\": 1747876225432, \"aggregate_sampling_time_ms\": 1186, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 21 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.194000 (seconds)\t\t Rate: \t19.262982 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.032000 (seconds)\t\t Rate: \t656.250000 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.162000 (seconds)\t\t Rate: \t19.793460 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 44 tokens:\t1.186000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 18, \"generated_tokens\": 8, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876226553, \"token_encode_end_ms\": 1747876226554, \"model_execution_start_ms\": 1747876226940, \"model_execution_end_ms\": 1747876226988, \"inference_end_ms\": 1747876226989, \"prompt_eval_end_ms\": 1747876226584, \"first_token_ms\": 1747876226641, \"aggregate_sampling_time_ms\": 434, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 18 Generated Tokens: 8\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.436000 (seconds)\t\t Rate: \t18.348624 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.031000 (seconds)\t\t Rate: \t580.645161 (tokens/second)\n",
            "\t\tGenerated 8 tokens:\t0.405000 (seconds)\t\t Rate: \t19.753086 (tokens/second)\n",
            "\tTime to first generated token:\t0.088000 (seconds)\n",
            "\tSampling time over 26 tokens:\t0.434000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 21, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876227000, \"token_encode_end_ms\": 1747876227001, \"model_execution_start_ms\": 1747876228044, \"model_execution_end_ms\": 1747876228091, \"inference_end_ms\": 1747876228092, \"prompt_eval_end_ms\": 1747876227043, \"first_token_ms\": 1747876227090, \"aggregate_sampling_time_ms\": 1083, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 21\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.092000 (seconds)\t\t Rate: \t19.230769 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t674.418605 (tokens/second)\n",
            "\t\tGenerated 21 tokens:\t1.049000 (seconds)\t\t Rate: \t20.019066 (tokens/second)\n",
            "\tTime to first generated token:\t0.090000 (seconds)\n",
            "\tSampling time over 50 tokens:\t1.083000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876228105, \"token_encode_end_ms\": 1747876228106, \"model_execution_start_ms\": 1747876229567, \"model_execution_end_ms\": 1747876229862, \"inference_end_ms\": 1747876229862, \"prompt_eval_end_ms\": 1747876228150, \"first_token_ms\": 1747876228197, \"aggregate_sampling_time_ms\": 1751, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.757000 (seconds)\t\t Rate: \t13.659647 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.045000 (seconds)\t\t Rate: \t688.888889 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.712000 (seconds)\t\t Rate: \t14.018692 (tokens/second)\n",
            "\tTime to first generated token:\t0.092000 (seconds)\n",
            "\tSampling time over 55 tokens:\t1.751000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 18, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876229872, \"token_encode_end_ms\": 1747876229873, \"model_execution_start_ms\": 1747876231759, \"model_execution_end_ms\": 1747876231806, \"inference_end_ms\": 1747876231806, \"prompt_eval_end_ms\": 1747876229940, \"first_token_ms\": 1747876230031, \"aggregate_sampling_time_ms\": 1929, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 18\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.934000 (seconds)\t\t Rate: \t9.307135 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.068000 (seconds)\t\t Rate: \t455.882353 (tokens/second)\n",
            "\t\tGenerated 18 tokens:\t1.866000 (seconds)\t\t Rate: \t9.646302 (tokens/second)\n",
            "\tTime to first generated token:\t0.159000 (seconds)\n",
            "\tSampling time over 49 tokens:\t1.929000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 46, \"generated_tokens\": 50, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876231810, \"token_encode_end_ms\": 1747876231811, \"model_execution_start_ms\": 1747876234410, \"model_execution_end_ms\": 1747876234460, \"inference_end_ms\": 1747876234460, \"prompt_eval_end_ms\": 1747876231872, \"first_token_ms\": 1747876231923, \"aggregate_sampling_time_ms\": 2633, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 46 Generated Tokens: 50\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.650000 (seconds)\t\t Rate: \t18.867925 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.062000 (seconds)\t\t Rate: \t741.935484 (tokens/second)\n",
            "\t\tGenerated 50 tokens:\t2.588000 (seconds)\t\t Rate: \t19.319938 (tokens/second)\n",
            "\tTime to first generated token:\t0.113000 (seconds)\n",
            "\tSampling time over 96 tokens:\t2.633000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 13, \"generated_tokens\": 12, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876234473, \"token_encode_end_ms\": 1747876234473, \"model_execution_start_ms\": 1747876235046, \"model_execution_end_ms\": 1747876235094, \"inference_end_ms\": 1747876235095, \"prompt_eval_end_ms\": 1747876234507, \"first_token_ms\": 1747876234562, \"aggregate_sampling_time_ms\": 618, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 13 Generated Tokens: 12\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.622000 (seconds)\t\t Rate: \t19.292605 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.034000 (seconds)\t\t Rate: \t382.352941 (tokens/second)\n",
            "\t\tGenerated 12 tokens:\t0.588000 (seconds)\t\t Rate: \t20.408163 (tokens/second)\n",
            "\tTime to first generated token:\t0.089000 (seconds)\n",
            "\tSampling time over 25 tokens:\t0.618000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 54, \"generated_tokens\": 38, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876235100, \"token_encode_end_ms\": 1747876235101, \"model_execution_start_ms\": 1747876237112, \"model_execution_end_ms\": 1747876237162, \"inference_end_ms\": 1747876237162, \"prompt_eval_end_ms\": 1747876235166, \"first_token_ms\": 1747876235217, \"aggregate_sampling_time_ms\": 2044, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 54 Generated Tokens: 38\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.062000 (seconds)\t\t Rate: \t18.428710 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.066000 (seconds)\t\t Rate: \t818.181818 (tokens/second)\n",
            "\t\tGenerated 38 tokens:\t1.996000 (seconds)\t\t Rate: \t19.038076 (tokens/second)\n",
            "\tTime to first generated token:\t0.117000 (seconds)\n",
            "\tSampling time over 92 tokens:\t2.044000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 17, \"generated_tokens\": 11, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876237171, \"token_encode_end_ms\": 1747876237171, \"model_execution_start_ms\": 1747876237711, \"model_execution_end_ms\": 1747876237758, \"inference_end_ms\": 1747876237758, \"prompt_eval_end_ms\": 1747876237206, \"first_token_ms\": 1747876237252, \"aggregate_sampling_time_ms\": 585, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 17 Generated Tokens: 11\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.587000 (seconds)\t\t Rate: \t18.739353 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.035000 (seconds)\t\t Rate: \t485.714286 (tokens/second)\n",
            "\t\tGenerated 11 tokens:\t0.552000 (seconds)\t\t Rate: \t19.927536 (tokens/second)\n",
            "\tTime to first generated token:\t0.081000 (seconds)\n",
            "\tSampling time over 28 tokens:\t0.585000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 48, \"generated_tokens\": 40, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876237763, \"token_encode_end_ms\": 1747876237764, \"model_execution_start_ms\": 1747876239842, \"model_execution_end_ms\": 1747876239892, \"inference_end_ms\": 1747876239892, \"prompt_eval_end_ms\": 1747876237822, \"first_token_ms\": 1747876237871, \"aggregate_sampling_time_ms\": 2118, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 48 Generated Tokens: 40\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.129000 (seconds)\t\t Rate: \t18.788163 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.059000 (seconds)\t\t Rate: \t813.559322 (tokens/second)\n",
            "\t\tGenerated 40 tokens:\t2.070000 (seconds)\t\t Rate: \t19.323671 (tokens/second)\n",
            "\tTime to first generated token:\t0.108000 (seconds)\n",
            "\tSampling time over 88 tokens:\t2.118000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 46, \"generated_tokens\": 49, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876239901, \"token_encode_end_ms\": 1747876239902, \"model_execution_start_ms\": 1747876243866, \"model_execution_end_ms\": 1747876243918, \"inference_end_ms\": 1747876243918, \"prompt_eval_end_ms\": 1747876239960, \"first_token_ms\": 1747876240010, \"aggregate_sampling_time_ms\": 4002, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 46 Generated Tokens: 49\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t4.017000 (seconds)\t\t Rate: \t12.198158 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.059000 (seconds)\t\t Rate: \t779.661017 (tokens/second)\n",
            "\t\tGenerated 49 tokens:\t3.958000 (seconds)\t\t Rate: \t12.379990 (tokens/second)\n",
            "\tTime to first generated token:\t0.109000 (seconds)\n",
            "\tSampling time over 95 tokens:\t4.002000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 16, \"generated_tokens\": 12, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876243928, \"token_encode_end_ms\": 1747876243930, \"model_execution_start_ms\": 1747876244515, \"model_execution_end_ms\": 1747876244562, \"inference_end_ms\": 1747876244562, \"prompt_eval_end_ms\": 1747876243965, \"first_token_ms\": 1747876244014, \"aggregate_sampling_time_ms\": 627, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 16 Generated Tokens: 12\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.634000 (seconds)\t\t Rate: \t18.927445 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.037000 (seconds)\t\t Rate: \t432.432432 (tokens/second)\n",
            "\t\tGenerated 12 tokens:\t0.597000 (seconds)\t\t Rate: \t20.100503 (tokens/second)\n",
            "\tTime to first generated token:\t0.086000 (seconds)\n",
            "\tSampling time over 28 tokens:\t0.627000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 46, \"generated_tokens\": 43, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876244574, \"token_encode_end_ms\": 1747876244574, \"model_execution_start_ms\": 1747876246800, \"model_execution_end_ms\": 1747876246849, \"inference_end_ms\": 1747876246849, \"prompt_eval_end_ms\": 1747876244629, \"first_token_ms\": 1747876244680, \"aggregate_sampling_time_ms\": 2255, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 46 Generated Tokens: 43\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.275000 (seconds)\t\t Rate: \t18.901099 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.055000 (seconds)\t\t Rate: \t836.363636 (tokens/second)\n",
            "\t\tGenerated 43 tokens:\t2.220000 (seconds)\t\t Rate: \t19.369369 (tokens/second)\n",
            "\tTime to first generated token:\t0.106000 (seconds)\n",
            "\tSampling time over 89 tokens:\t2.255000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 67, \"generated_tokens\": 57, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876246855, \"token_encode_end_ms\": 1747876246856, \"model_execution_start_ms\": 1747876249935, \"model_execution_end_ms\": 1747876249987, \"inference_end_ms\": 1747876249987, \"prompt_eval_end_ms\": 1747876246952, \"first_token_ms\": 1747876247003, \"aggregate_sampling_time_ms\": 3118, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 67 Generated Tokens: 57\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.132000 (seconds)\t\t Rate: \t18.199234 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.097000 (seconds)\t\t Rate: \t690.721649 (tokens/second)\n",
            "\t\tGenerated 57 tokens:\t3.035000 (seconds)\t\t Rate: \t18.780890 (tokens/second)\n",
            "\tTime to first generated token:\t0.148000 (seconds)\n",
            "\tSampling time over 124 tokens:\t3.118000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 25, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876249995, \"token_encode_end_ms\": 1747876249995, \"model_execution_start_ms\": 1747876251100, \"model_execution_end_ms\": 1747876251150, \"inference_end_ms\": 1747876251151, \"prompt_eval_end_ms\": 1747876250060, \"first_token_ms\": 1747876250108, \"aggregate_sampling_time_ms\": 1148, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 25 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.156000 (seconds)\t\t Rate: \t19.031142 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.065000 (seconds)\t\t Rate: \t384.615385 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.091000 (seconds)\t\t Rate: \t20.164986 (tokens/second)\n",
            "\tTime to first generated token:\t0.113000 (seconds)\n",
            "\tSampling time over 47 tokens:\t1.148000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 53, \"generated_tokens\": 48, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876251155, \"token_encode_end_ms\": 1747876251155, \"model_execution_start_ms\": 1747876253707, \"model_execution_end_ms\": 1747876253757, \"inference_end_ms\": 1747876253757, \"prompt_eval_end_ms\": 1747876251224, \"first_token_ms\": 1747876251274, \"aggregate_sampling_time_ms\": 2594, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 53 Generated Tokens: 48\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.602000 (seconds)\t\t Rate: \t18.447348 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.069000 (seconds)\t\t Rate: \t768.115942 (tokens/second)\n",
            "\t\tGenerated 48 tokens:\t2.533000 (seconds)\t\t Rate: \t18.949862 (tokens/second)\n",
            "\tTime to first generated token:\t0.119000 (seconds)\n",
            "\tSampling time over 101 tokens:\t2.594000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 35, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876253764, \"token_encode_end_ms\": 1747876253764, \"model_execution_start_ms\": 1747876257021, \"model_execution_end_ms\": 1747876257069, \"inference_end_ms\": 1747876257070, \"prompt_eval_end_ms\": 1747876253828, \"first_token_ms\": 1747876253917, \"aggregate_sampling_time_ms\": 3291, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 35\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.306000 (seconds)\t\t Rate: \t10.586812 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.064000 (seconds)\t\t Rate: \t515.625000 (tokens/second)\n",
            "\t\tGenerated 35 tokens:\t3.242000 (seconds)\t\t Rate: \t10.795805 (tokens/second)\n",
            "\tTime to first generated token:\t0.153000 (seconds)\n",
            "\tSampling time over 68 tokens:\t3.291000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 20, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876257075, \"token_encode_end_ms\": 1747876257085, \"model_execution_start_ms\": 1747876257865, \"model_execution_end_ms\": 1747876257911, \"inference_end_ms\": 1747876257911, \"prompt_eval_end_ms\": 1747876257123, \"first_token_ms\": 1747876257171, \"aggregate_sampling_time_ms\": 823, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 20 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.836000 (seconds)\t\t Rate: \t19.138756 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.048000 (seconds)\t\t Rate: \t416.666667 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.788000 (seconds)\t\t Rate: \t20.304569 (tokens/second)\n",
            "\tTime to first generated token:\t0.096000 (seconds)\n",
            "\tSampling time over 36 tokens:\t0.823000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 36, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876257923, \"token_encode_end_ms\": 1747876257924, \"model_execution_start_ms\": 1747876259396, \"model_execution_end_ms\": 1747876259447, \"inference_end_ms\": 1747876259447, \"prompt_eval_end_ms\": 1747876257972, \"first_token_ms\": 1747876258020, \"aggregate_sampling_time_ms\": 1510, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 36 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.524000 (seconds)\t\t Rate: \t19.028871 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.049000 (seconds)\t\t Rate: \t734.693878 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.475000 (seconds)\t\t Rate: \t19.661017 (tokens/second)\n",
            "\tTime to first generated token:\t0.097000 (seconds)\n",
            "\tSampling time over 65 tokens:\t1.510000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 37, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876259455, \"token_encode_end_ms\": 1747876259455, \"model_execution_start_ms\": 1747876260922, \"model_execution_end_ms\": 1747876260971, \"inference_end_ms\": 1747876260972, \"prompt_eval_end_ms\": 1747876259507, \"first_token_ms\": 1747876259556, \"aggregate_sampling_time_ms\": 1506, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 37 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.517000 (seconds)\t\t Rate: \t19.116678 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.052000 (seconds)\t\t Rate: \t711.538462 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.465000 (seconds)\t\t Rate: \t19.795222 (tokens/second)\n",
            "\tTime to first generated token:\t0.101000 (seconds)\n",
            "\tSampling time over 66 tokens:\t1.506000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 14, \"generated_tokens\": 11, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876260979, \"token_encode_end_ms\": 1747876260979, \"model_execution_start_ms\": 1747876261510, \"model_execution_end_ms\": 1747876261557, \"inference_end_ms\": 1747876261558, \"prompt_eval_end_ms\": 1747876261009, \"first_token_ms\": 1747876261055, \"aggregate_sampling_time_ms\": 576, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 14 Generated Tokens: 11\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.579000 (seconds)\t\t Rate: \t18.998273 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.030000 (seconds)\t\t Rate: \t466.666667 (tokens/second)\n",
            "\t\tGenerated 11 tokens:\t0.549000 (seconds)\t\t Rate: \t20.036430 (tokens/second)\n",
            "\tTime to first generated token:\t0.076000 (seconds)\n",
            "\tSampling time over 25 tokens:\t0.576000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 18, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876261566, \"token_encode_end_ms\": 1747876261566, \"model_execution_start_ms\": 1747876262327, \"model_execution_end_ms\": 1747876262373, \"inference_end_ms\": 1747876262374, \"prompt_eval_end_ms\": 1747876261601, \"first_token_ms\": 1747876261650, \"aggregate_sampling_time_ms\": 804, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 18 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.808000 (seconds)\t\t Rate: \t19.801980 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.035000 (seconds)\t\t Rate: \t514.285714 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.773000 (seconds)\t\t Rate: \t20.698577 (tokens/second)\n",
            "\tTime to first generated token:\t0.084000 (seconds)\n",
            "\tSampling time over 34 tokens:\t0.804000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 54, \"generated_tokens\": 51, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876262386, \"token_encode_end_ms\": 1747876262387, \"model_execution_start_ms\": 1747876265080, \"model_execution_end_ms\": 1747876265130, \"inference_end_ms\": 1747876265131, \"prompt_eval_end_ms\": 1747876262447, \"first_token_ms\": 1747876262519, \"aggregate_sampling_time_ms\": 2728, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 54 Generated Tokens: 51\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.745000 (seconds)\t\t Rate: \t18.579235 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t885.245902 (tokens/second)\n",
            "\t\tGenerated 51 tokens:\t2.684000 (seconds)\t\t Rate: \t19.001490 (tokens/second)\n",
            "\tTime to first generated token:\t0.133000 (seconds)\n",
            "\tSampling time over 105 tokens:\t2.728000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 19, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876265148, \"token_encode_end_ms\": 1747876265148, \"model_execution_start_ms\": 1747876266096, \"model_execution_end_ms\": 1747876266144, \"inference_end_ms\": 1747876266144, \"prompt_eval_end_ms\": 1747876265188, \"first_token_ms\": 1747876265241, \"aggregate_sampling_time_ms\": 989, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 19\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.996000 (seconds)\t\t Rate: \t19.076305 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.040000 (seconds)\t\t Rate: \t675.000000 (tokens/second)\n",
            "\t\tGenerated 19 tokens:\t0.956000 (seconds)\t\t Rate: \t19.874477 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 46 tokens:\t0.989000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 100, \"generated_tokens\": 77, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876266154, \"token_encode_end_ms\": 1747876266155, \"model_execution_start_ms\": 1747876272064, \"model_execution_end_ms\": 1747876272119, \"inference_end_ms\": 1747876272119, \"prompt_eval_end_ms\": 1747876266285, \"first_token_ms\": 1747876266399, \"aggregate_sampling_time_ms\": 5941, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 100 Generated Tokens: 77\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t5.965000 (seconds)\t\t Rate: \t12.908634 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.131000 (seconds)\t\t Rate: \t763.358779 (tokens/second)\n",
            "\t\tGenerated 77 tokens:\t5.834000 (seconds)\t\t Rate: \t13.198492 (tokens/second)\n",
            "\tTime to first generated token:\t0.245000 (seconds)\n",
            "\tSampling time over 177 tokens:\t5.941000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 45, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876272129, \"token_encode_end_ms\": 1747876272129, \"model_execution_start_ms\": 1747876274174, \"model_execution_end_ms\": 1747876274226, \"inference_end_ms\": 1747876274226, \"prompt_eval_end_ms\": 1747876272189, \"first_token_ms\": 1747876272243, \"aggregate_sampling_time_ms\": 2087, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 45 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.097000 (seconds)\t\t Rate: \t18.597997 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.060000 (seconds)\t\t Rate: \t750.000000 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t2.037000 (seconds)\t\t Rate: \t19.145803 (tokens/second)\n",
            "\tTime to first generated token:\t0.114000 (seconds)\n",
            "\tSampling time over 84 tokens:\t2.087000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876274232, \"token_encode_end_ms\": 1747876274233, \"model_execution_start_ms\": 1747876275769, \"model_execution_end_ms\": 1747876275818, \"inference_end_ms\": 1747876275818, \"prompt_eval_end_ms\": 1747876274295, \"first_token_ms\": 1747876274344, \"aggregate_sampling_time_ms\": 1574, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.586000 (seconds)\t\t Rate: \t18.915511 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.063000 (seconds)\t\t Rate: \t507.936508 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t1.523000 (seconds)\t\t Rate: \t19.697965 (tokens/second)\n",
            "\tTime to first generated token:\t0.112000 (seconds)\n",
            "\tSampling time over 62 tokens:\t1.574000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 51, \"generated_tokens\": 52, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876275823, \"token_encode_end_ms\": 1747876275832, \"model_execution_start_ms\": 1747876278727, \"model_execution_end_ms\": 1747876278836, \"inference_end_ms\": 1747876278836, \"prompt_eval_end_ms\": 1747876275891, \"first_token_ms\": 1747876275959, \"aggregate_sampling_time_ms\": 2991, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 51 Generated Tokens: 52\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.013000 (seconds)\t\t Rate: \t17.258546 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.068000 (seconds)\t\t Rate: \t750.000000 (tokens/second)\n",
            "\t\tGenerated 52 tokens:\t2.945000 (seconds)\t\t Rate: \t17.657046 (tokens/second)\n",
            "\tTime to first generated token:\t0.136000 (seconds)\n",
            "\tSampling time over 103 tokens:\t2.991000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 41, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876278845, \"token_encode_end_ms\": 1747876278846, \"model_execution_start_ms\": 1747876281671, \"model_execution_end_ms\": 1747876281724, \"inference_end_ms\": 1747876281724, \"prompt_eval_end_ms\": 1747876278946, \"first_token_ms\": 1747876279244, \"aggregate_sampling_time_ms\": 2869, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 41 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.879000 (seconds)\t\t Rate: \t10.420285 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.101000 (seconds)\t\t Rate: \t405.940594 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t2.778000 (seconds)\t\t Rate: \t10.799136 (tokens/second)\n",
            "\tTime to first generated token:\t0.399000 (seconds)\n",
            "\tSampling time over 71 tokens:\t2.869000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 42, \"generated_tokens\": 41, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876281737, \"token_encode_end_ms\": 1747876281738, \"model_execution_start_ms\": 1747876283846, \"model_execution_end_ms\": 1747876283894, \"inference_end_ms\": 1747876283895, \"prompt_eval_end_ms\": 1747876281789, \"first_token_ms\": 1747876281837, \"aggregate_sampling_time_ms\": 2142, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 42 Generated Tokens: 41\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.158000 (seconds)\t\t Rate: \t18.999073 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.052000 (seconds)\t\t Rate: \t807.692308 (tokens/second)\n",
            "\t\tGenerated 41 tokens:\t2.106000 (seconds)\t\t Rate: \t19.468186 (tokens/second)\n",
            "\tTime to first generated token:\t0.100000 (seconds)\n",
            "\tSampling time over 83 tokens:\t2.142000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 20, \"generated_tokens\": 15, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876283910, \"token_encode_end_ms\": 1747876283910, \"model_execution_start_ms\": 1747876284627, \"model_execution_end_ms\": 1747876284674, \"inference_end_ms\": 1747876284674, \"prompt_eval_end_ms\": 1747876283941, \"first_token_ms\": 1747876283988, \"aggregate_sampling_time_ms\": 760, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 20 Generated Tokens: 15\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.764000 (seconds)\t\t Rate: \t19.633508 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.031000 (seconds)\t\t Rate: \t645.161290 (tokens/second)\n",
            "\t\tGenerated 15 tokens:\t0.733000 (seconds)\t\t Rate: \t20.463847 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 35 tokens:\t0.760000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876284685, \"token_encode_end_ms\": 1747876284686, \"model_execution_start_ms\": 1747876285875, \"model_execution_end_ms\": 1747876285924, \"inference_end_ms\": 1747876285924, \"prompt_eval_end_ms\": 1747876284729, \"first_token_ms\": 1747876284776, \"aggregate_sampling_time_ms\": 1231, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.239000 (seconds)\t\t Rate: \t18.563358 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t704.545455 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.195000 (seconds)\t\t Rate: \t19.246862 (tokens/second)\n",
            "\tTime to first generated token:\t0.091000 (seconds)\n",
            "\tSampling time over 54 tokens:\t1.231000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 15, \"generated_tokens\": 11, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876285938, \"token_encode_end_ms\": 1747876285939, \"model_execution_start_ms\": 1747876286470, \"model_execution_end_ms\": 1747876286517, \"inference_end_ms\": 1747876286517, \"prompt_eval_end_ms\": 1747876285966, \"first_token_ms\": 1747876286013, \"aggregate_sampling_time_ms\": 573, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 15 Generated Tokens: 11\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.579000 (seconds)\t\t Rate: \t18.998273 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.028000 (seconds)\t\t Rate: \t535.714286 (tokens/second)\n",
            "\t\tGenerated 11 tokens:\t0.551000 (seconds)\t\t Rate: \t19.963702 (tokens/second)\n",
            "\tTime to first generated token:\t0.075000 (seconds)\n",
            "\tSampling time over 26 tokens:\t0.573000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 78, \"generated_tokens\": 79, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876286521, \"token_encode_end_ms\": 1747876286522, \"model_execution_start_ms\": 1747876290991, \"model_execution_end_ms\": 1747876291079, \"inference_end_ms\": 1747876291079, \"prompt_eval_end_ms\": 1747876286604, \"first_token_ms\": 1747876286656, \"aggregate_sampling_time_ms\": 4522, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 78 Generated Tokens: 79\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t4.558000 (seconds)\t\t Rate: \t17.332163 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.083000 (seconds)\t\t Rate: \t939.759036 (tokens/second)\n",
            "\t\tGenerated 79 tokens:\t4.475000 (seconds)\t\t Rate: \t17.653631 (tokens/second)\n",
            "\tTime to first generated token:\t0.135000 (seconds)\n",
            "\tSampling time over 157 tokens:\t4.522000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 60, \"generated_tokens\": 20, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876291090, \"token_encode_end_ms\": 1747876291090, \"model_execution_start_ms\": 1747876293502, \"model_execution_end_ms\": 1747876293553, \"inference_end_ms\": 1747876293553, \"prompt_eval_end_ms\": 1747876291203, \"first_token_ms\": 1747876291520, \"aggregate_sampling_time_ms\": 2459, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 60 Generated Tokens: 20\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.463000 (seconds)\t\t Rate: \t8.120179 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.113000 (seconds)\t\t Rate: \t530.973451 (tokens/second)\n",
            "\t\tGenerated 20 tokens:\t2.350000 (seconds)\t\t Rate: \t8.510638 (tokens/second)\n",
            "\tTime to first generated token:\t0.430000 (seconds)\n",
            "\tSampling time over 80 tokens:\t2.459000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 34, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876293566, \"token_encode_end_ms\": 1747876293567, \"model_execution_start_ms\": 1747876295061, \"model_execution_end_ms\": 1747876295113, \"inference_end_ms\": 1747876295113, \"prompt_eval_end_ms\": 1747876293620, \"first_token_ms\": 1747876293688, \"aggregate_sampling_time_ms\": 1537, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 34 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.547000 (seconds)\t\t Rate: \t18.745960 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.054000 (seconds)\t\t Rate: \t629.629630 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.493000 (seconds)\t\t Rate: \t19.423979 (tokens/second)\n",
            "\tTime to first generated token:\t0.122000 (seconds)\n",
            "\tSampling time over 63 tokens:\t1.537000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 28, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876295126, \"token_encode_end_ms\": 1747876295127, \"model_execution_start_ms\": 1747876296520, \"model_execution_end_ms\": 1747876296569, \"inference_end_ms\": 1747876296570, \"prompt_eval_end_ms\": 1747876295169, \"first_token_ms\": 1747876295218, \"aggregate_sampling_time_ms\": 1431, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 28\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.444000 (seconds)\t\t Rate: \t19.390582 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t674.418605 (tokens/second)\n",
            "\t\tGenerated 28 tokens:\t1.401000 (seconds)\t\t Rate: \t19.985724 (tokens/second)\n",
            "\tTime to first generated token:\t0.092000 (seconds)\n",
            "\tSampling time over 57 tokens:\t1.431000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 55, \"generated_tokens\": 40, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876296584, \"token_encode_end_ms\": 1747876296584, \"model_execution_start_ms\": 1747876298709, \"model_execution_end_ms\": 1747876298759, \"inference_end_ms\": 1747876298760, \"prompt_eval_end_ms\": 1747876296645, \"first_token_ms\": 1747876296701, \"aggregate_sampling_time_ms\": 2158, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 55 Generated Tokens: 40\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.176000 (seconds)\t\t Rate: \t18.382353 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t901.639344 (tokens/second)\n",
            "\t\tGenerated 40 tokens:\t2.115000 (seconds)\t\t Rate: \t18.912530 (tokens/second)\n",
            "\tTime to first generated token:\t0.117000 (seconds)\n",
            "\tSampling time over 95 tokens:\t2.158000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 37, \"generated_tokens\": 35, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876298774, \"token_encode_end_ms\": 1747876298775, \"model_execution_start_ms\": 1747876300551, \"model_execution_end_ms\": 1747876300599, \"inference_end_ms\": 1747876300599, \"prompt_eval_end_ms\": 1747876298846, \"first_token_ms\": 1747876298896, \"aggregate_sampling_time_ms\": 1816, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 37 Generated Tokens: 35\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.825000 (seconds)\t\t Rate: \t19.178082 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.072000 (seconds)\t\t Rate: \t513.888889 (tokens/second)\n",
            "\t\tGenerated 35 tokens:\t1.753000 (seconds)\t\t Rate: \t19.965773 (tokens/second)\n",
            "\tTime to first generated token:\t0.122000 (seconds)\n",
            "\tSampling time over 72 tokens:\t1.816000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 26, \"generated_tokens\": 28, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876300614, \"token_encode_end_ms\": 1747876300614, \"model_execution_start_ms\": 1747876302056, \"model_execution_end_ms\": 1747876302106, \"inference_end_ms\": 1747876302106, \"prompt_eval_end_ms\": 1747876300654, \"first_token_ms\": 1747876300703, \"aggregate_sampling_time_ms\": 1487, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 26 Generated Tokens: 28\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.492000 (seconds)\t\t Rate: \t18.766756 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.040000 (seconds)\t\t Rate: \t650.000000 (tokens/second)\n",
            "\t\tGenerated 28 tokens:\t1.452000 (seconds)\t\t Rate: \t19.283747 (tokens/second)\n",
            "\tTime to first generated token:\t0.089000 (seconds)\n",
            "\tSampling time over 54 tokens:\t1.487000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 12, \"generated_tokens\": 7, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876302113, \"token_encode_end_ms\": 1747876302113, \"model_execution_start_ms\": 1747876302446, \"model_execution_end_ms\": 1747876302496, \"inference_end_ms\": 1747876302496, \"prompt_eval_end_ms\": 1747876302145, \"first_token_ms\": 1747876302192, \"aggregate_sampling_time_ms\": 380, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 12 Generated Tokens: 7\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.383000 (seconds)\t\t Rate: \t18.276762 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.032000 (seconds)\t\t Rate: \t375.000000 (tokens/second)\n",
            "\t\tGenerated 7 tokens:\t0.351000 (seconds)\t\t Rate: \t19.943020 (tokens/second)\n",
            "\tTime to first generated token:\t0.079000 (seconds)\n",
            "\tSampling time over 19 tokens:\t0.380000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 25, \"generated_tokens\": 21, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876302507, \"token_encode_end_ms\": 1747876302508, \"model_execution_start_ms\": 1747876304173, \"model_execution_end_ms\": 1747876304270, \"inference_end_ms\": 1747876304270, \"prompt_eval_end_ms\": 1747876302546, \"first_token_ms\": 1747876302594, \"aggregate_sampling_time_ms\": 1755, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 25 Generated Tokens: 21\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.763000 (seconds)\t\t Rate: \t11.911514 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.039000 (seconds)\t\t Rate: \t641.025641 (tokens/second)\n",
            "\t\tGenerated 21 tokens:\t1.724000 (seconds)\t\t Rate: \t12.180974 (tokens/second)\n",
            "\tTime to first generated token:\t0.087000 (seconds)\n",
            "\tSampling time over 46 tokens:\t1.755000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 27, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876304281, \"token_encode_end_ms\": 1747876304282, \"model_execution_start_ms\": 1747876306439, \"model_execution_end_ms\": 1747876306487, \"inference_end_ms\": 1747876306488, \"prompt_eval_end_ms\": 1747876304440, \"first_token_ms\": 1747876304560, \"aggregate_sampling_time_ms\": 2197, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 27\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.207000 (seconds)\t\t Rate: \t12.233802 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.159000 (seconds)\t\t Rate: \t182.389937 (tokens/second)\n",
            "\t\tGenerated 27 tokens:\t2.048000 (seconds)\t\t Rate: \t13.183594 (tokens/second)\n",
            "\tTime to first generated token:\t0.279000 (seconds)\n",
            "\tSampling time over 56 tokens:\t2.197000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 20, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876306498, \"token_encode_end_ms\": 1747876306499, \"model_execution_start_ms\": 1747876307511, \"model_execution_end_ms\": 1747876307560, \"inference_end_ms\": 1747876307560, \"prompt_eval_end_ms\": 1747876306545, \"first_token_ms\": 1747876306593, \"aggregate_sampling_time_ms\": 1056, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 20\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.062000 (seconds)\t\t Rate: \t18.832392 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.047000 (seconds)\t\t Rate: \t659.574468 (tokens/second)\n",
            "\t\tGenerated 20 tokens:\t1.015000 (seconds)\t\t Rate: \t19.704433 (tokens/second)\n",
            "\tTime to first generated token:\t0.095000 (seconds)\n",
            "\tSampling time over 51 tokens:\t1.056000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 46, \"generated_tokens\": 43, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876307569, \"token_encode_end_ms\": 1747876307570, \"model_execution_start_ms\": 1747876309807, \"model_execution_end_ms\": 1747876309856, \"inference_end_ms\": 1747876309857, \"prompt_eval_end_ms\": 1747876307629, \"first_token_ms\": 1747876307680, \"aggregate_sampling_time_ms\": 2273, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 46 Generated Tokens: 43\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.288000 (seconds)\t\t Rate: \t18.793706 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.060000 (seconds)\t\t Rate: \t766.666667 (tokens/second)\n",
            "\t\tGenerated 43 tokens:\t2.228000 (seconds)\t\t Rate: \t19.299820 (tokens/second)\n",
            "\tTime to first generated token:\t0.111000 (seconds)\n",
            "\tSampling time over 89 tokens:\t2.273000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 97, \"generated_tokens\": 46, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876309870, \"token_encode_end_ms\": 1747876309871, \"model_execution_start_ms\": 1747876312539, \"model_execution_end_ms\": 1747876312594, \"inference_end_ms\": 1747876312595, \"prompt_eval_end_ms\": 1747876309968, \"first_token_ms\": 1747876310022, \"aggregate_sampling_time_ms\": 2710, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 97 Generated Tokens: 46\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.725000 (seconds)\t\t Rate: \t16.880734 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.098000 (seconds)\t\t Rate: \t989.795918 (tokens/second)\n",
            "\t\tGenerated 46 tokens:\t2.627000 (seconds)\t\t Rate: \t17.510468 (tokens/second)\n",
            "\tTime to first generated token:\t0.152000 (seconds)\n",
            "\tSampling time over 143 tokens:\t2.710000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 49, \"generated_tokens\": 50, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876312611, \"token_encode_end_ms\": 1747876312611, \"model_execution_start_ms\": 1747876315216, \"model_execution_end_ms\": 1747876315267, \"inference_end_ms\": 1747876315268, \"prompt_eval_end_ms\": 1747876312666, \"first_token_ms\": 1747876312719, \"aggregate_sampling_time_ms\": 2642, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 49 Generated Tokens: 50\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.657000 (seconds)\t\t Rate: \t18.818216 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.055000 (seconds)\t\t Rate: \t890.909091 (tokens/second)\n",
            "\t\tGenerated 50 tokens:\t2.602000 (seconds)\t\t Rate: \t19.215988 (tokens/second)\n",
            "\tTime to first generated token:\t0.108000 (seconds)\n",
            "\tSampling time over 99 tokens:\t2.642000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 21, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876315284, \"token_encode_end_ms\": 1747876315284, \"model_execution_start_ms\": 1747876317874, \"model_execution_end_ms\": 1747876317922, \"inference_end_ms\": 1747876317922, \"prompt_eval_end_ms\": 1747876315327, \"first_token_ms\": 1747876315378, \"aggregate_sampling_time_ms\": 2633, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 21\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.638000 (seconds)\t\t Rate: \t7.960576 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t674.418605 (tokens/second)\n",
            "\t\tGenerated 21 tokens:\t2.595000 (seconds)\t\t Rate: \t8.092486 (tokens/second)\n",
            "\tTime to first generated token:\t0.094000 (seconds)\n",
            "\tSampling time over 50 tokens:\t2.633000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 40, \"generated_tokens\": 37, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876317926, \"token_encode_end_ms\": 1747876317927, \"model_execution_start_ms\": 1747876319818, \"model_execution_end_ms\": 1747876319868, \"inference_end_ms\": 1747876319868, \"prompt_eval_end_ms\": 1747876317981, \"first_token_ms\": 1747876318032, \"aggregate_sampling_time_ms\": 1932, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 40 Generated Tokens: 37\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.942000 (seconds)\t\t Rate: \t19.052523 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.055000 (seconds)\t\t Rate: \t727.272727 (tokens/second)\n",
            "\t\tGenerated 37 tokens:\t1.887000 (seconds)\t\t Rate: \t19.607843 (tokens/second)\n",
            "\tTime to first generated token:\t0.106000 (seconds)\n",
            "\tSampling time over 77 tokens:\t1.932000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 41, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876319874, \"token_encode_end_ms\": 1747876319874, \"model_execution_start_ms\": 1747876321426, \"model_execution_end_ms\": 1747876321475, \"inference_end_ms\": 1747876321476, \"prompt_eval_end_ms\": 1747876319932, \"first_token_ms\": 1747876319982, \"aggregate_sampling_time_ms\": 1589, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 41 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.602000 (seconds)\t\t Rate: \t18.726592 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t706.896552 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t1.544000 (seconds)\t\t Rate: \t19.430052 (tokens/second)\n",
            "\tTime to first generated token:\t0.108000 (seconds)\n",
            "\tSampling time over 71 tokens:\t1.589000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 36, \"generated_tokens\": 34, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876321490, \"token_encode_end_ms\": 1747876321491, \"model_execution_start_ms\": 1747876323234, \"model_execution_end_ms\": 1747876323285, \"inference_end_ms\": 1747876323286, \"prompt_eval_end_ms\": 1747876321539, \"first_token_ms\": 1747876321588, \"aggregate_sampling_time_ms\": 1788, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 36 Generated Tokens: 34\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.796000 (seconds)\t\t Rate: \t18.930958 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.049000 (seconds)\t\t Rate: \t734.693878 (tokens/second)\n",
            "\t\tGenerated 34 tokens:\t1.747000 (seconds)\t\t Rate: \t19.461935 (tokens/second)\n",
            "\tTime to first generated token:\t0.098000 (seconds)\n",
            "\tSampling time over 70 tokens:\t1.788000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 24, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876323300, \"token_encode_end_ms\": 1747876323301, \"model_execution_start_ms\": 1747876324489, \"model_execution_end_ms\": 1747876324536, \"inference_end_ms\": 1747876324537, \"prompt_eval_end_ms\": 1747876323339, \"first_token_ms\": 1747876323389, \"aggregate_sampling_time_ms\": 1230, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 24 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.237000 (seconds)\t\t Rate: \t19.401778 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.039000 (seconds)\t\t Rate: \t615.384615 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.198000 (seconds)\t\t Rate: \t20.033389 (tokens/second)\n",
            "\tTime to first generated token:\t0.089000 (seconds)\n",
            "\tSampling time over 48 tokens:\t1.230000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876324551, \"token_encode_end_ms\": 1747876324552, \"model_execution_start_ms\": 1747876325741, \"model_execution_end_ms\": 1747876325808, \"inference_end_ms\": 1747876325808, \"prompt_eval_end_ms\": 1747876324591, \"first_token_ms\": 1747876324640, \"aggregate_sampling_time_ms\": 1250, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.257000 (seconds)\t\t Rate: \t19.093079 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.040000 (seconds)\t\t Rate: \t725.000000 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.217000 (seconds)\t\t Rate: \t19.720624 (tokens/second)\n",
            "\tTime to first generated token:\t0.089000 (seconds)\n",
            "\tSampling time over 53 tokens:\t1.250000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 17, \"generated_tokens\": 13, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876325822, \"token_encode_end_ms\": 1747876325822, \"model_execution_start_ms\": 1747876326439, \"model_execution_end_ms\": 1747876326485, \"inference_end_ms\": 1747876326485, \"prompt_eval_end_ms\": 1747876325853, \"first_token_ms\": 1747876325900, \"aggregate_sampling_time_ms\": 657, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 17 Generated Tokens: 13\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.663000 (seconds)\t\t Rate: \t19.607843 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.031000 (seconds)\t\t Rate: \t548.387097 (tokens/second)\n",
            "\t\tGenerated 13 tokens:\t0.632000 (seconds)\t\t Rate: \t20.569620 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 30 tokens:\t0.657000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 47, \"generated_tokens\": 40, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876326489, \"token_encode_end_ms\": 1747876326498, \"model_execution_start_ms\": 1747876329900, \"model_execution_end_ms\": 1747876330014, \"inference_end_ms\": 1747876330014, \"prompt_eval_end_ms\": 1747876326550, \"first_token_ms\": 1747876326600, \"aggregate_sampling_time_ms\": 3505, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 47 Generated Tokens: 40\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.525000 (seconds)\t\t Rate: \t11.347518 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t770.491803 (tokens/second)\n",
            "\t\tGenerated 40 tokens:\t3.464000 (seconds)\t\t Rate: \t11.547344 (tokens/second)\n",
            "\tTime to first generated token:\t0.111000 (seconds)\n",
            "\tSampling time over 87 tokens:\t3.505000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876330027, \"token_encode_end_ms\": 1747876330028, \"model_execution_start_ms\": 1747876331244, \"model_execution_end_ms\": 1747876331292, \"inference_end_ms\": 1747876331292, \"prompt_eval_end_ms\": 1747876330097, \"first_token_ms\": 1747876330184, \"aggregate_sampling_time_ms\": 1258, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.265000 (seconds)\t\t Rate: \t18.181818 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.070000 (seconds)\t\t Rate: \t428.571429 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.195000 (seconds)\t\t Rate: \t19.246862 (tokens/second)\n",
            "\tTime to first generated token:\t0.157000 (seconds)\n",
            "\tSampling time over 53 tokens:\t1.258000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 19, \"generated_tokens\": 15, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876331300, \"token_encode_end_ms\": 1747876331300, \"model_execution_start_ms\": 1747876332036, \"model_execution_end_ms\": 1747876332089, \"inference_end_ms\": 1747876332089, \"prompt_eval_end_ms\": 1747876331335, \"first_token_ms\": 1747876331381, \"aggregate_sampling_time_ms\": 785, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 19 Generated Tokens: 15\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.789000 (seconds)\t\t Rate: \t19.011407 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.035000 (seconds)\t\t Rate: \t542.857143 (tokens/second)\n",
            "\t\tGenerated 15 tokens:\t0.754000 (seconds)\t\t Rate: \t19.893899 (tokens/second)\n",
            "\tTime to first generated token:\t0.081000 (seconds)\n",
            "\tSampling time over 34 tokens:\t0.785000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 36, \"generated_tokens\": 38, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876332100, \"token_encode_end_ms\": 1747876332100, \"model_execution_start_ms\": 1747876334036, \"model_execution_end_ms\": 1747876334098, \"inference_end_ms\": 1747876334098, \"prompt_eval_end_ms\": 1747876332151, \"first_token_ms\": 1747876332201, \"aggregate_sampling_time_ms\": 1984, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 36 Generated Tokens: 38\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.998000 (seconds)\t\t Rate: \t19.019019 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.051000 (seconds)\t\t Rate: \t705.882353 (tokens/second)\n",
            "\t\tGenerated 38 tokens:\t1.947000 (seconds)\t\t Rate: \t19.517206 (tokens/second)\n",
            "\tTime to first generated token:\t0.101000 (seconds)\n",
            "\tSampling time over 74 tokens:\t1.984000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 40, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876334111, \"token_encode_end_ms\": 1747876334111, \"model_execution_start_ms\": 1747876335671, \"model_execution_end_ms\": 1747876335722, \"inference_end_ms\": 1747876335722, \"prompt_eval_end_ms\": 1747876334175, \"first_token_ms\": 1747876334225, \"aggregate_sampling_time_ms\": 1603, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 40 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.611000 (seconds)\t\t Rate: \t18.621974 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.064000 (seconds)\t\t Rate: \t625.000000 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t1.547000 (seconds)\t\t Rate: \t19.392372 (tokens/second)\n",
            "\tTime to first generated token:\t0.114000 (seconds)\n",
            "\tSampling time over 70 tokens:\t1.603000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 20, \"generated_tokens\": 17, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876335737, \"token_encode_end_ms\": 1747876335738, \"model_execution_start_ms\": 1747876336557, \"model_execution_end_ms\": 1747876336604, \"inference_end_ms\": 1747876336604, \"prompt_eval_end_ms\": 1747876335769, \"first_token_ms\": 1747876335816, \"aggregate_sampling_time_ms\": 860, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 20 Generated Tokens: 17\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.867000 (seconds)\t\t Rate: \t19.607843 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.032000 (seconds)\t\t Rate: \t625.000000 (tokens/second)\n",
            "\t\tGenerated 17 tokens:\t0.835000 (seconds)\t\t Rate: \t20.359281 (tokens/second)\n",
            "\tTime to first generated token:\t0.079000 (seconds)\n",
            "\tSampling time over 37 tokens:\t0.860000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876336611, \"token_encode_end_ms\": 1747876336611, \"model_execution_start_ms\": 1747876338059, \"model_execution_end_ms\": 1747876338109, \"inference_end_ms\": 1747876338110, \"prompt_eval_end_ms\": 1747876336661, \"first_token_ms\": 1747876336710, \"aggregate_sampling_time_ms\": 1479, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.499000 (seconds)\t\t Rate: \t19.346231 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.050000 (seconds)\t\t Rate: \t660.000000 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.449000 (seconds)\t\t Rate: \t20.013803 (tokens/second)\n",
            "\tTime to first generated token:\t0.099000 (seconds)\n",
            "\tSampling time over 62 tokens:\t1.479000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 31, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876338115, \"token_encode_end_ms\": 1747876338116, \"model_execution_start_ms\": 1747876339697, \"model_execution_end_ms\": 1747876339745, \"inference_end_ms\": 1747876339746, \"prompt_eval_end_ms\": 1747876338169, \"first_token_ms\": 1747876338218, \"aggregate_sampling_time_ms\": 1617, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 31\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.631000 (seconds)\t\t Rate: \t19.006744 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.054000 (seconds)\t\t Rate: \t611.111111 (tokens/second)\n",
            "\t\tGenerated 31 tokens:\t1.577000 (seconds)\t\t Rate: \t19.657578 (tokens/second)\n",
            "\tTime to first generated token:\t0.103000 (seconds)\n",
            "\tSampling time over 64 tokens:\t1.617000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 27, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876339750, \"token_encode_end_ms\": 1747876339751, \"model_execution_start_ms\": 1747876342573, \"model_execution_end_ms\": 1747876342623, \"inference_end_ms\": 1747876342624, \"prompt_eval_end_ms\": 1747876339804, \"first_token_ms\": 1747876339852, \"aggregate_sampling_time_ms\": 2868, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 27\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.874000 (seconds)\t\t Rate: \t9.394572 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.054000 (seconds)\t\t Rate: \t611.111111 (tokens/second)\n",
            "\t\tGenerated 27 tokens:\t2.820000 (seconds)\t\t Rate: \t9.574468 (tokens/second)\n",
            "\tTime to first generated token:\t0.102000 (seconds)\n",
            "\tSampling time over 60 tokens:\t2.868000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 41, \"generated_tokens\": 33, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876342630, \"token_encode_end_ms\": 1747876342630, \"model_execution_start_ms\": 1747876344321, \"model_execution_end_ms\": 1747876344369, \"inference_end_ms\": 1747876344369, \"prompt_eval_end_ms\": 1747876342688, \"first_token_ms\": 1747876342737, \"aggregate_sampling_time_ms\": 1725, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 41 Generated Tokens: 33\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.739000 (seconds)\t\t Rate: \t18.976423 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t706.896552 (tokens/second)\n",
            "\t\tGenerated 33 tokens:\t1.681000 (seconds)\t\t Rate: \t19.631172 (tokens/second)\n",
            "\tTime to first generated token:\t0.107000 (seconds)\n",
            "\tSampling time over 74 tokens:\t1.725000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 27, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876344381, \"token_encode_end_ms\": 1747876344382, \"model_execution_start_ms\": 1747876345779, \"model_execution_end_ms\": 1747876345827, \"inference_end_ms\": 1747876345827, \"prompt_eval_end_ms\": 1747876344418, \"first_token_ms\": 1747876344476, \"aggregate_sampling_time_ms\": 1435, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 27\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.446000 (seconds)\t\t Rate: \t18.672199 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.037000 (seconds)\t\t Rate: \t837.837838 (tokens/second)\n",
            "\t\tGenerated 27 tokens:\t1.409000 (seconds)\t\t Rate: \t19.162527 (tokens/second)\n",
            "\tTime to first generated token:\t0.095000 (seconds)\n",
            "\tSampling time over 58 tokens:\t1.435000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 64, \"generated_tokens\": 56, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876345842, \"token_encode_end_ms\": 1747876345843, \"model_execution_start_ms\": 1747876348879, \"model_execution_end_ms\": 1747876348929, \"inference_end_ms\": 1747876348929, \"prompt_eval_end_ms\": 1747876345907, \"first_token_ms\": 1747876345959, \"aggregate_sampling_time_ms\": 3071, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 64 Generated Tokens: 56\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.087000 (seconds)\t\t Rate: \t18.140590 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.065000 (seconds)\t\t Rate: \t984.615385 (tokens/second)\n",
            "\t\tGenerated 56 tokens:\t3.022000 (seconds)\t\t Rate: \t18.530774 (tokens/second)\n",
            "\tTime to first generated token:\t0.117000 (seconds)\n",
            "\tSampling time over 120 tokens:\t3.071000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 38, \"generated_tokens\": 36, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876348937, \"token_encode_end_ms\": 1747876348937, \"model_execution_start_ms\": 1747876350815, \"model_execution_end_ms\": 1747876350862, \"inference_end_ms\": 1747876350862, \"prompt_eval_end_ms\": 1747876348994, \"first_token_ms\": 1747876349044, \"aggregate_sampling_time_ms\": 1916, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 38 Generated Tokens: 36\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.925000 (seconds)\t\t Rate: \t18.701299 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.057000 (seconds)\t\t Rate: \t666.666667 (tokens/second)\n",
            "\t\tGenerated 36 tokens:\t1.868000 (seconds)\t\t Rate: \t19.271949 (tokens/second)\n",
            "\tTime to first generated token:\t0.107000 (seconds)\n",
            "\tSampling time over 74 tokens:\t1.916000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 36, \"generated_tokens\": 33, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876350867, \"token_encode_end_ms\": 1747876350868, \"model_execution_start_ms\": 1747876352843, \"model_execution_end_ms\": 1747876353083, \"inference_end_ms\": 1747876353083, \"prompt_eval_end_ms\": 1747876350905, \"first_token_ms\": 1747876350954, \"aggregate_sampling_time_ms\": 2200, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 36 Generated Tokens: 33\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.216000 (seconds)\t\t Rate: \t14.891697 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.038000 (seconds)\t\t Rate: \t947.368421 (tokens/second)\n",
            "\t\tGenerated 33 tokens:\t2.178000 (seconds)\t\t Rate: \t15.151515 (tokens/second)\n",
            "\tTime to first generated token:\t0.087000 (seconds)\n",
            "\tSampling time over 69 tokens:\t2.200000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 21, \"generated_tokens\": 17, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876353095, \"token_encode_end_ms\": 1747876353095, \"model_execution_start_ms\": 1747876354959, \"model_execution_end_ms\": 1747876355006, \"inference_end_ms\": 1747876355006, \"prompt_eval_end_ms\": 1747876353151, \"first_token_ms\": 1747876353255, \"aggregate_sampling_time_ms\": 1890, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 21 Generated Tokens: 17\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.911000 (seconds)\t\t Rate: \t8.895866 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.056000 (seconds)\t\t Rate: \t375.000000 (tokens/second)\n",
            "\t\tGenerated 17 tokens:\t1.855000 (seconds)\t\t Rate: \t9.164420 (tokens/second)\n",
            "\tTime to first generated token:\t0.160000 (seconds)\n",
            "\tSampling time over 38 tokens:\t1.890000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 28, \"generated_tokens\": 28, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876355018, \"token_encode_end_ms\": 1747876355019, \"model_execution_start_ms\": 1747876356427, \"model_execution_end_ms\": 1747876356475, \"inference_end_ms\": 1747876356475, \"prompt_eval_end_ms\": 1747876355061, \"first_token_ms\": 1747876355110, \"aggregate_sampling_time_ms\": 1452, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 28 Generated Tokens: 28\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.457000 (seconds)\t\t Rate: \t19.217570 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t651.162791 (tokens/second)\n",
            "\t\tGenerated 28 tokens:\t1.414000 (seconds)\t\t Rate: \t19.801980 (tokens/second)\n",
            "\tTime to first generated token:\t0.092000 (seconds)\n",
            "\tSampling time over 56 tokens:\t1.452000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 28, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876356483, \"token_encode_end_ms\": 1747876356484, \"model_execution_start_ms\": 1747876357867, \"model_execution_end_ms\": 1747876357915, \"inference_end_ms\": 1747876357916, \"prompt_eval_end_ms\": 1747876356531, \"first_token_ms\": 1747876356581, \"aggregate_sampling_time_ms\": 1423, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 28\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.433000 (seconds)\t\t Rate: \t19.539428 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.048000 (seconds)\t\t Rate: \t625.000000 (tokens/second)\n",
            "\t\tGenerated 28 tokens:\t1.385000 (seconds)\t\t Rate: \t20.216606 (tokens/second)\n",
            "\tTime to first generated token:\t0.098000 (seconds)\n",
            "\tSampling time over 58 tokens:\t1.423000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876357920, \"token_encode_end_ms\": 1747876357920, \"model_execution_start_ms\": 1747876359445, \"model_execution_end_ms\": 1747876359494, \"inference_end_ms\": 1747876359494, \"prompt_eval_end_ms\": 1747876357958, \"first_token_ms\": 1747876358037, \"aggregate_sampling_time_ms\": 1564, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.574000 (seconds)\t\t Rate: \t19.059720 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.038000 (seconds)\t\t Rate: \t789.473684 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t1.536000 (seconds)\t\t Rate: \t19.531250 (tokens/second)\n",
            "\tTime to first generated token:\t0.117000 (seconds)\n",
            "\tSampling time over 60 tokens:\t1.564000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 43, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876359508, \"token_encode_end_ms\": 1747876359509, \"model_execution_start_ms\": 1747876361504, \"model_execution_end_ms\": 1747876361557, \"inference_end_ms\": 1747876361557, \"prompt_eval_end_ms\": 1747876359566, \"first_token_ms\": 1747876359618, \"aggregate_sampling_time_ms\": 2029, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 43 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.049000 (seconds)\t\t Rate: \t19.033675 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t741.379310 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t1.991000 (seconds)\t\t Rate: \t19.588147 (tokens/second)\n",
            "\tTime to first generated token:\t0.110000 (seconds)\n",
            "\tSampling time over 82 tokens:\t2.029000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 70, \"generated_tokens\": 61, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876361566, \"token_encode_end_ms\": 1747876361567, \"model_execution_start_ms\": 1747876365378, \"model_execution_end_ms\": 1747876365529, \"inference_end_ms\": 1747876365529, \"prompt_eval_end_ms\": 1747876361646, \"first_token_ms\": 1747876361698, \"aggregate_sampling_time_ms\": 3940, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 70 Generated Tokens: 61\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.963000 (seconds)\t\t Rate: \t15.392380 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.080000 (seconds)\t\t Rate: \t875.000000 (tokens/second)\n",
            "\t\tGenerated 61 tokens:\t3.883000 (seconds)\t\t Rate: \t15.709503 (tokens/second)\n",
            "\tTime to first generated token:\t0.132000 (seconds)\n",
            "\tSampling time over 131 tokens:\t3.940000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 45, \"generated_tokens\": 34, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876365547, \"token_encode_end_ms\": 1747876365548, \"model_execution_start_ms\": 1747876368285, \"model_execution_end_ms\": 1747876368335, \"inference_end_ms\": 1747876368336, \"prompt_eval_end_ms\": 1747876365651, \"first_token_ms\": 1747876365909, \"aggregate_sampling_time_ms\": 2776, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 45 Generated Tokens: 34\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.789000 (seconds)\t\t Rate: \t12.190749 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.104000 (seconds)\t\t Rate: \t432.692308 (tokens/second)\n",
            "\t\tGenerated 34 tokens:\t2.685000 (seconds)\t\t Rate: \t12.662942 (tokens/second)\n",
            "\tTime to first generated token:\t0.362000 (seconds)\n",
            "\tSampling time over 79 tokens:\t2.776000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876368345, \"token_encode_end_ms\": 1747876368346, \"model_execution_start_ms\": 1747876369582, \"model_execution_end_ms\": 1747876369632, \"inference_end_ms\": 1747876369633, \"prompt_eval_end_ms\": 1747876368392, \"first_token_ms\": 1747876368462, \"aggregate_sampling_time_ms\": 1275, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.288000 (seconds)\t\t Rate: \t18.633540 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.047000 (seconds)\t\t Rate: \t638.297872 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.241000 (seconds)\t\t Rate: \t19.339243 (tokens/second)\n",
            "\tTime to first generated token:\t0.117000 (seconds)\n",
            "\tSampling time over 54 tokens:\t1.275000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 79, \"generated_tokens\": 59, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876369639, \"token_encode_end_ms\": 1747876369640, \"model_execution_start_ms\": 1747876372935, \"model_execution_end_ms\": 1747876372988, \"inference_end_ms\": 1747876372989, \"prompt_eval_end_ms\": 1747876369725, \"first_token_ms\": 1747876369777, \"aggregate_sampling_time_ms\": 3331, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 79 Generated Tokens: 59\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.350000 (seconds)\t\t Rate: \t17.611940 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.086000 (seconds)\t\t Rate: \t918.604651 (tokens/second)\n",
            "\t\tGenerated 59 tokens:\t3.264000 (seconds)\t\t Rate: \t18.075980 (tokens/second)\n",
            "\tTime to first generated token:\t0.138000 (seconds)\n",
            "\tSampling time over 138 tokens:\t3.331000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 49, \"generated_tokens\": 46, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876373006, \"token_encode_end_ms\": 1747876373007, \"model_execution_start_ms\": 1747876375435, \"model_execution_end_ms\": 1747876375486, \"inference_end_ms\": 1747876375486, \"prompt_eval_end_ms\": 1747876373073, \"first_token_ms\": 1747876373122, \"aggregate_sampling_time_ms\": 2464, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 49 Generated Tokens: 46\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.480000 (seconds)\t\t Rate: \t18.548387 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.067000 (seconds)\t\t Rate: \t731.343284 (tokens/second)\n",
            "\t\tGenerated 46 tokens:\t2.413000 (seconds)\t\t Rate: \t19.063407 (tokens/second)\n",
            "\tTime to first generated token:\t0.116000 (seconds)\n",
            "\tSampling time over 95 tokens:\t2.464000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 40, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876375502, \"token_encode_end_ms\": 1747876375502, \"model_execution_start_ms\": 1747876377669, \"model_execution_end_ms\": 1747876377787, \"inference_end_ms\": 1747876377788, \"prompt_eval_end_ms\": 1747876375552, \"first_token_ms\": 1747876375601, \"aggregate_sampling_time_ms\": 2276, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 40 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.286000 (seconds)\t\t Rate: \t13.123360 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.050000 (seconds)\t\t Rate: \t800.000000 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t2.236000 (seconds)\t\t Rate: \t13.416816 (tokens/second)\n",
            "\tTime to first generated token:\t0.099000 (seconds)\n",
            "\tSampling time over 70 tokens:\t2.276000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 49, \"generated_tokens\": 40, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876377793, \"token_encode_end_ms\": 1747876377794, \"model_execution_start_ms\": 1747876380755, \"model_execution_end_ms\": 1747876380804, \"inference_end_ms\": 1747876380804, \"prompt_eval_end_ms\": 1747876377882, \"first_token_ms\": 1747876378018, \"aggregate_sampling_time_ms\": 2991, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 49 Generated Tokens: 40\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.011000 (seconds)\t\t Rate: \t13.284623 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.089000 (seconds)\t\t Rate: \t550.561798 (tokens/second)\n",
            "\t\tGenerated 40 tokens:\t2.922000 (seconds)\t\t Rate: \t13.689254 (tokens/second)\n",
            "\tTime to first generated token:\t0.225000 (seconds)\n",
            "\tSampling time over 89 tokens:\t2.991000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 23, \"generated_tokens\": 17, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876380809, \"token_encode_end_ms\": 1747876380810, \"model_execution_start_ms\": 1747876381658, \"model_execution_end_ms\": 1747876381706, \"inference_end_ms\": 1747876381706, \"prompt_eval_end_ms\": 1747876380836, \"first_token_ms\": 1747876380917, \"aggregate_sampling_time_ms\": 890, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 23 Generated Tokens: 17\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.897000 (seconds)\t\t Rate: \t18.952062 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.027000 (seconds)\t\t Rate: \t851.851852 (tokens/second)\n",
            "\t\tGenerated 17 tokens:\t0.870000 (seconds)\t\t Rate: \t19.540230 (tokens/second)\n",
            "\tTime to first generated token:\t0.108000 (seconds)\n",
            "\tSampling time over 40 tokens:\t0.890000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 14, \"generated_tokens\": 9, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876381714, \"token_encode_end_ms\": 1747876381714, \"model_execution_start_ms\": 1747876382156, \"model_execution_end_ms\": 1747876382204, \"inference_end_ms\": 1747876382205, \"prompt_eval_end_ms\": 1747876381748, \"first_token_ms\": 1747876381795, \"aggregate_sampling_time_ms\": 488, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 14 Generated Tokens: 9\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.491000 (seconds)\t\t Rate: \t18.329939 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.034000 (seconds)\t\t Rate: \t411.764706 (tokens/second)\n",
            "\t\tGenerated 9 tokens:\t0.457000 (seconds)\t\t Rate: \t19.693654 (tokens/second)\n",
            "\tTime to first generated token:\t0.081000 (seconds)\n",
            "\tSampling time over 23 tokens:\t0.488000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 23, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876382212, \"token_encode_end_ms\": 1747876382213, \"model_execution_start_ms\": 1747876383627, \"model_execution_end_ms\": 1747876383681, \"inference_end_ms\": 1747876383682, \"prompt_eval_end_ms\": 1747876382252, \"first_token_ms\": 1747876382298, \"aggregate_sampling_time_ms\": 1457, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 23 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.470000 (seconds)\t\t Rate: \t19.727891 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.040000 (seconds)\t\t Rate: \t575.000000 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.430000 (seconds)\t\t Rate: \t20.279720 (tokens/second)\n",
            "\tTime to first generated token:\t0.086000 (seconds)\n",
            "\tSampling time over 52 tokens:\t1.457000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876383696, \"token_encode_end_ms\": 1747876383697, \"model_execution_start_ms\": 1747876384845, \"model_execution_end_ms\": 1747876384895, \"inference_end_ms\": 1747876384895, \"prompt_eval_end_ms\": 1747876383741, \"first_token_ms\": 1747876383789, \"aggregate_sampling_time_ms\": 1193, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.199000 (seconds)\t\t Rate: \t19.182652 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.045000 (seconds)\t\t Rate: \t600.000000 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.154000 (seconds)\t\t Rate: \t19.930676 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 50 tokens:\t1.193000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 36, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876384910, \"token_encode_end_ms\": 1747876384910, \"model_execution_start_ms\": 1747876386401, \"model_execution_end_ms\": 1747876386450, \"inference_end_ms\": 1747876386451, \"prompt_eval_end_ms\": 1747876384959, \"first_token_ms\": 1747876385008, \"aggregate_sampling_time_ms\": 1531, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 36 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.541000 (seconds)\t\t Rate: \t18.818949 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.049000 (seconds)\t\t Rate: \t734.693878 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.492000 (seconds)\t\t Rate: \t19.436997 (tokens/second)\n",
            "\tTime to first generated token:\t0.098000 (seconds)\n",
            "\tSampling time over 65 tokens:\t1.531000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 40, \"generated_tokens\": 42, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876386455, \"token_encode_end_ms\": 1747876386456, \"model_execution_start_ms\": 1747876388622, \"model_execution_end_ms\": 1747876388676, \"inference_end_ms\": 1747876388677, \"prompt_eval_end_ms\": 1747876386511, \"first_token_ms\": 1747876386561, \"aggregate_sampling_time_ms\": 2210, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 40 Generated Tokens: 42\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.222000 (seconds)\t\t Rate: \t18.901890 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.056000 (seconds)\t\t Rate: \t714.285714 (tokens/second)\n",
            "\t\tGenerated 42 tokens:\t2.166000 (seconds)\t\t Rate: \t19.390582 (tokens/second)\n",
            "\tTime to first generated token:\t0.106000 (seconds)\n",
            "\tSampling time over 82 tokens:\t2.210000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 23, \"generated_tokens\": 26, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876388689, \"token_encode_end_ms\": 1747876388689, \"model_execution_start_ms\": 1747876391463, \"model_execution_end_ms\": 1747876391510, \"inference_end_ms\": 1747876391511, \"prompt_eval_end_ms\": 1747876388730, \"first_token_ms\": 1747876388779, \"aggregate_sampling_time_ms\": 2814, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 23 Generated Tokens: 26\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.822000 (seconds)\t\t Rate: \t9.213324 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.041000 (seconds)\t\t Rate: \t560.975610 (tokens/second)\n",
            "\t\tGenerated 26 tokens:\t2.781000 (seconds)\t\t Rate: \t9.349155 (tokens/second)\n",
            "\tTime to first generated token:\t0.090000 (seconds)\n",
            "\tSampling time over 49 tokens:\t2.814000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 26, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876391524, \"token_encode_end_ms\": 1747876391524, \"model_execution_start_ms\": 1747876392650, \"model_execution_end_ms\": 1747876392702, \"inference_end_ms\": 1747876392703, \"prompt_eval_end_ms\": 1747876391564, \"first_token_ms\": 1747876391617, \"aggregate_sampling_time_ms\": 1172, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 26 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.179000 (seconds)\t\t Rate: \t18.659881 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.040000 (seconds)\t\t Rate: \t650.000000 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.139000 (seconds)\t\t Rate: \t19.315189 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 48 tokens:\t1.172000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 24, \"generated_tokens\": 13, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876392716, \"token_encode_end_ms\": 1747876392717, \"model_execution_start_ms\": 1747876393358, \"model_execution_end_ms\": 1747876393429, \"inference_end_ms\": 1747876393429, \"prompt_eval_end_ms\": 1747876392756, \"first_token_ms\": 1747876392804, \"aggregate_sampling_time_ms\": 709, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 24 Generated Tokens: 13\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.713000 (seconds)\t\t Rate: \t18.232819 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.040000 (seconds)\t\t Rate: \t600.000000 (tokens/second)\n",
            "\t\tGenerated 13 tokens:\t0.673000 (seconds)\t\t Rate: \t19.316493 (tokens/second)\n",
            "\tTime to first generated token:\t0.088000 (seconds)\n",
            "\tSampling time over 37 tokens:\t0.709000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 23, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876393439, \"token_encode_end_ms\": 1747876393440, \"model_execution_start_ms\": 1747876394213, \"model_execution_end_ms\": 1747876394262, \"inference_end_ms\": 1747876394262, \"prompt_eval_end_ms\": 1747876393477, \"first_token_ms\": 1747876393524, \"aggregate_sampling_time_ms\": 818, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 23 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.823000 (seconds)\t\t Rate: \t19.441069 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.038000 (seconds)\t\t Rate: \t605.263158 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.785000 (seconds)\t\t Rate: \t20.382166 (tokens/second)\n",
            "\tTime to first generated token:\t0.085000 (seconds)\n",
            "\tSampling time over 39 tokens:\t0.818000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 51, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876394274, \"token_encode_end_ms\": 1747876394275, \"model_execution_start_ms\": 1747876396355, \"model_execution_end_ms\": 1747876396405, \"inference_end_ms\": 1747876396405, \"prompt_eval_end_ms\": 1747876394336, \"first_token_ms\": 1747876394389, \"aggregate_sampling_time_ms\": 2116, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 51 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.131000 (seconds)\t\t Rate: \t18.301267 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.062000 (seconds)\t\t Rate: \t822.580645 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t2.069000 (seconds)\t\t Rate: \t18.849686 (tokens/second)\n",
            "\tTime to first generated token:\t0.115000 (seconds)\n",
            "\tSampling time over 90 tokens:\t2.116000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 35, \"generated_tokens\": 25, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876396411, \"token_encode_end_ms\": 1747876396415, \"model_execution_start_ms\": 1747876397705, \"model_execution_end_ms\": 1747876397755, \"inference_end_ms\": 1747876397755, \"prompt_eval_end_ms\": 1747876396470, \"first_token_ms\": 1747876396537, \"aggregate_sampling_time_ms\": 1337, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 35 Generated Tokens: 25\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.344000 (seconds)\t\t Rate: \t18.601190 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.059000 (seconds)\t\t Rate: \t593.220339 (tokens/second)\n",
            "\t\tGenerated 25 tokens:\t1.285000 (seconds)\t\t Rate: \t19.455253 (tokens/second)\n",
            "\tTime to first generated token:\t0.126000 (seconds)\n",
            "\tSampling time over 60 tokens:\t1.337000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876397760, \"token_encode_end_ms\": 1747876397760, \"model_execution_start_ms\": 1747876399278, \"model_execution_end_ms\": 1747876399328, \"inference_end_ms\": 1747876399328, \"prompt_eval_end_ms\": 1747876397813, \"first_token_ms\": 1747876397861, \"aggregate_sampling_time_ms\": 1560, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.568000 (seconds)\t\t Rate: \t19.132653 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t622.641509 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t1.515000 (seconds)\t\t Rate: \t19.801980 (tokens/second)\n",
            "\tTime to first generated token:\t0.101000 (seconds)\n",
            "\tSampling time over 63 tokens:\t1.560000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 21, \"generated_tokens\": 19, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876399333, \"token_encode_end_ms\": 1747876399333, \"model_execution_start_ms\": 1747876400291, \"model_execution_end_ms\": 1747876400339, \"inference_end_ms\": 1747876400340, \"prompt_eval_end_ms\": 1747876399375, \"first_token_ms\": 1747876399423, \"aggregate_sampling_time_ms\": 991, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 21 Generated Tokens: 19\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.007000 (seconds)\t\t Rate: \t18.867925 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.042000 (seconds)\t\t Rate: \t500.000000 (tokens/second)\n",
            "\t\tGenerated 19 tokens:\t0.965000 (seconds)\t\t Rate: \t19.689119 (tokens/second)\n",
            "\tTime to first generated token:\t0.090000 (seconds)\n",
            "\tSampling time over 40 tokens:\t0.991000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 37, \"generated_tokens\": 27, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876400344, \"token_encode_end_ms\": 1747876400353, \"model_execution_start_ms\": 1747876402227, \"model_execution_end_ms\": 1747876402325, \"inference_end_ms\": 1747876402325, \"prompt_eval_end_ms\": 1747876400400, \"first_token_ms\": 1747876400449, \"aggregate_sampling_time_ms\": 1963, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 37 Generated Tokens: 27\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.981000 (seconds)\t\t Rate: \t13.629480 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.056000 (seconds)\t\t Rate: \t660.714286 (tokens/second)\n",
            "\t\tGenerated 27 tokens:\t1.925000 (seconds)\t\t Rate: \t14.025974 (tokens/second)\n",
            "\tTime to first generated token:\t0.105000 (seconds)\n",
            "\tSampling time over 64 tokens:\t1.963000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 13, \"generated_tokens\": 7, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876402335, \"token_encode_end_ms\": 1747876402335, \"model_execution_start_ms\": 1747876403382, \"model_execution_end_ms\": 1747876403491, \"inference_end_ms\": 1747876403491, \"prompt_eval_end_ms\": 1747876402373, \"first_token_ms\": 1747876402471, \"aggregate_sampling_time_ms\": 1155, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 13 Generated Tokens: 7\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.156000 (seconds)\t\t Rate: \t6.055363 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.038000 (seconds)\t\t Rate: \t342.105263 (tokens/second)\n",
            "\t\tGenerated 7 tokens:\t1.118000 (seconds)\t\t Rate: \t6.261181 (tokens/second)\n",
            "\tTime to first generated token:\t0.136000 (seconds)\n",
            "\tSampling time over 20 tokens:\t1.155000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 61, \"generated_tokens\": 61, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876403498, \"token_encode_end_ms\": 1747876403499, \"model_execution_start_ms\": 1747876406995, \"model_execution_end_ms\": 1747876407048, \"inference_end_ms\": 1747876407048, \"prompt_eval_end_ms\": 1747876403647, \"first_token_ms\": 1747876403770, \"aggregate_sampling_time_ms\": 3529, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 61 Generated Tokens: 61\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.550000 (seconds)\t\t Rate: \t17.183099 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.149000 (seconds)\t\t Rate: \t409.395973 (tokens/second)\n",
            "\t\tGenerated 61 tokens:\t3.401000 (seconds)\t\t Rate: \t17.935901 (tokens/second)\n",
            "\tTime to first generated token:\t0.272000 (seconds)\n",
            "\tSampling time over 122 tokens:\t3.529000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 26, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876407056, \"token_encode_end_ms\": 1747876407057, \"model_execution_start_ms\": 1747876408253, \"model_execution_end_ms\": 1747876408300, \"inference_end_ms\": 1747876408300, \"prompt_eval_end_ms\": 1747876407103, \"first_token_ms\": 1747876407152, \"aggregate_sampling_time_ms\": 1237, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 26 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.244000 (seconds)\t\t Rate: \t19.292605 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.047000 (seconds)\t\t Rate: \t553.191489 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.197000 (seconds)\t\t Rate: \t20.050125 (tokens/second)\n",
            "\tTime to first generated token:\t0.096000 (seconds)\n",
            "\tSampling time over 50 tokens:\t1.237000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876408307, \"token_encode_end_ms\": 1747876408308, \"model_execution_start_ms\": 1747876409470, \"model_execution_end_ms\": 1747876409518, \"inference_end_ms\": 1747876409519, \"prompt_eval_end_ms\": 1747876408353, \"first_token_ms\": 1747876408400, \"aggregate_sampling_time_ms\": 1205, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.212000 (seconds)\t\t Rate: \t18.976898 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t652.173913 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.166000 (seconds)\t\t Rate: \t19.725557 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 53 tokens:\t1.205000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 40, \"generated_tokens\": 36, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876409532, \"token_encode_end_ms\": 1747876409533, \"model_execution_start_ms\": 1747876411405, \"model_execution_end_ms\": 1747876411454, \"inference_end_ms\": 1747876411454, \"prompt_eval_end_ms\": 1747876409582, \"first_token_ms\": 1747876409632, \"aggregate_sampling_time_ms\": 1910, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 40 Generated Tokens: 36\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.922000 (seconds)\t\t Rate: \t18.730489 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.050000 (seconds)\t\t Rate: \t800.000000 (tokens/second)\n",
            "\t\tGenerated 36 tokens:\t1.872000 (seconds)\t\t Rate: \t19.230769 (tokens/second)\n",
            "\tTime to first generated token:\t0.100000 (seconds)\n",
            "\tSampling time over 76 tokens:\t1.910000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 92, \"generated_tokens\": 74, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876411466, \"token_encode_end_ms\": 1747876411467, \"model_execution_start_ms\": 1747876417170, \"model_execution_end_ms\": 1747876417226, \"inference_end_ms\": 1747876417226, \"prompt_eval_end_ms\": 1747876411562, \"first_token_ms\": 1747876411617, \"aggregate_sampling_time_ms\": 5730, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 92 Generated Tokens: 74\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t5.760000 (seconds)\t\t Rate: \t12.847222 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.096000 (seconds)\t\t Rate: \t958.333333 (tokens/second)\n",
            "\t\tGenerated 74 tokens:\t5.664000 (seconds)\t\t Rate: \t13.064972 (tokens/second)\n",
            "\tTime to first generated token:\t0.151000 (seconds)\n",
            "\tSampling time over 166 tokens:\t5.730000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 18, \"generated_tokens\": 15, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876417243, \"token_encode_end_ms\": 1747876417244, \"model_execution_start_ms\": 1747876417995, \"model_execution_end_ms\": 1747876418042, \"inference_end_ms\": 1747876418043, \"prompt_eval_end_ms\": 1747876417269, \"first_token_ms\": 1747876417336, \"aggregate_sampling_time_ms\": 788, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 18 Generated Tokens: 15\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.800000 (seconds)\t\t Rate: \t18.750000 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.026000 (seconds)\t\t Rate: \t692.307692 (tokens/second)\n",
            "\t\tGenerated 15 tokens:\t0.774000 (seconds)\t\t Rate: \t19.379845 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 33 tokens:\t0.788000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 133, \"generated_tokens\": 84, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876418054, \"token_encode_end_ms\": 1747876418056, \"model_execution_start_ms\": 1747876423274, \"model_execution_end_ms\": 1747876423335, \"inference_end_ms\": 1747876423335, \"prompt_eval_end_ms\": 1747876418183, \"first_token_ms\": 1747876418242, \"aggregate_sampling_time_ms\": 5256, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 133 Generated Tokens: 84\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t5.281000 (seconds)\t\t Rate: \t15.906078 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.129000 (seconds)\t\t Rate: \t1031.007752 (tokens/second)\n",
            "\t\tGenerated 84 tokens:\t5.152000 (seconds)\t\t Rate: \t16.304348 (tokens/second)\n",
            "\tTime to first generated token:\t0.188000 (seconds)\n",
            "\tSampling time over 217 tokens:\t5.256000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 16, \"generated_tokens\": 12, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876423353, \"token_encode_end_ms\": 1747876423353, \"model_execution_start_ms\": 1747876423951, \"model_execution_end_ms\": 1747876423998, \"inference_end_ms\": 1747876423999, \"prompt_eval_end_ms\": 1747876423387, \"first_token_ms\": 1747876423434, \"aggregate_sampling_time_ms\": 641, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 16 Generated Tokens: 12\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.646000 (seconds)\t\t Rate: \t18.575851 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.034000 (seconds)\t\t Rate: \t470.588235 (tokens/second)\n",
            "\t\tGenerated 12 tokens:\t0.612000 (seconds)\t\t Rate: \t19.607843 (tokens/second)\n",
            "\tTime to first generated token:\t0.081000 (seconds)\n",
            "\tSampling time over 28 tokens:\t0.641000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 18, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876424007, \"token_encode_end_ms\": 1747876424007, \"model_execution_start_ms\": 1747876424921, \"model_execution_end_ms\": 1747876424975, \"inference_end_ms\": 1747876424976, \"prompt_eval_end_ms\": 1747876424051, \"first_token_ms\": 1747876424100, \"aggregate_sampling_time_ms\": 964, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 18\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.969000 (seconds)\t\t Rate: \t18.575851 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t681.818182 (tokens/second)\n",
            "\t\tGenerated 18 tokens:\t0.925000 (seconds)\t\t Rate: \t19.459459 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 48 tokens:\t0.964000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 27, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876424987, \"token_encode_end_ms\": 1747876424988, \"model_execution_start_ms\": 1747876426842, \"model_execution_end_ms\": 1747876426939, \"inference_end_ms\": 1747876426940, \"prompt_eval_end_ms\": 1747876425033, \"first_token_ms\": 1747876425082, \"aggregate_sampling_time_ms\": 1944, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 27\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.953000 (seconds)\t\t Rate: \t13.824885 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t695.652174 (tokens/second)\n",
            "\t\tGenerated 27 tokens:\t1.907000 (seconds)\t\t Rate: \t14.158364 (tokens/second)\n",
            "\tTime to first generated token:\t0.095000 (seconds)\n",
            "\tSampling time over 59 tokens:\t1.944000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 25, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876426951, \"token_encode_end_ms\": 1747876426951, \"model_execution_start_ms\": 1747876429138, \"model_execution_end_ms\": 1747876429187, \"inference_end_ms\": 1747876429187, \"prompt_eval_end_ms\": 1747876427036, \"first_token_ms\": 1747876427131, \"aggregate_sampling_time_ms\": 2225, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 25\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.236000 (seconds)\t\t Rate: \t11.180680 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.085000 (seconds)\t\t Rate: \t341.176471 (tokens/second)\n",
            "\t\tGenerated 25 tokens:\t2.151000 (seconds)\t\t Rate: \t11.622501 (tokens/second)\n",
            "\tTime to first generated token:\t0.180000 (seconds)\n",
            "\tSampling time over 54 tokens:\t2.225000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 12, \"generated_tokens\": 8, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876429202, \"token_encode_end_ms\": 1747876429203, \"model_execution_start_ms\": 1747876429574, \"model_execution_end_ms\": 1747876429621, \"inference_end_ms\": 1747876429621, \"prompt_eval_end_ms\": 1747876429227, \"first_token_ms\": 1747876429274, \"aggregate_sampling_time_ms\": 416, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 12 Generated Tokens: 8\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.419000 (seconds)\t\t Rate: \t19.093079 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.025000 (seconds)\t\t Rate: \t480.000000 (tokens/second)\n",
            "\t\tGenerated 8 tokens:\t0.394000 (seconds)\t\t Rate: \t20.304569 (tokens/second)\n",
            "\tTime to first generated token:\t0.072000 (seconds)\n",
            "\tSampling time over 20 tokens:\t0.416000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 17, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876429632, \"token_encode_end_ms\": 1747876429633, \"model_execution_start_ms\": 1747876430493, \"model_execution_end_ms\": 1747876430542, \"inference_end_ms\": 1747876430542, \"prompt_eval_end_ms\": 1747876429676, \"first_token_ms\": 1747876429725, \"aggregate_sampling_time_ms\": 904, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 17\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.910000 (seconds)\t\t Rate: \t18.681319 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t613.636364 (tokens/second)\n",
            "\t\tGenerated 17 tokens:\t0.866000 (seconds)\t\t Rate: \t19.630485 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 44 tokens:\t0.904000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 37, \"generated_tokens\": 41, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876430556, \"token_encode_end_ms\": 1747876430556, \"model_execution_start_ms\": 1747876432683, \"model_execution_end_ms\": 1747876432733, \"inference_end_ms\": 1747876432733, \"prompt_eval_end_ms\": 1747876430607, \"first_token_ms\": 1747876430657, \"aggregate_sampling_time_ms\": 2166, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 37 Generated Tokens: 41\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.177000 (seconds)\t\t Rate: \t18.833257 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.051000 (seconds)\t\t Rate: \t725.490196 (tokens/second)\n",
            "\t\tGenerated 41 tokens:\t2.126000 (seconds)\t\t Rate: \t19.285042 (tokens/second)\n",
            "\tTime to first generated token:\t0.101000 (seconds)\n",
            "\tSampling time over 78 tokens:\t2.166000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 17, \"generated_tokens\": 14, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876432747, \"token_encode_end_ms\": 1747876432748, \"model_execution_start_ms\": 1747876433446, \"model_execution_end_ms\": 1747876433493, \"inference_end_ms\": 1747876433493, \"prompt_eval_end_ms\": 1747876432778, \"first_token_ms\": 1747876432826, \"aggregate_sampling_time_ms\": 743, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 17 Generated Tokens: 14\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.746000 (seconds)\t\t Rate: \t18.766756 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.031000 (seconds)\t\t Rate: \t548.387097 (tokens/second)\n",
            "\t\tGenerated 14 tokens:\t0.715000 (seconds)\t\t Rate: \t19.580420 (tokens/second)\n",
            "\tTime to first generated token:\t0.079000 (seconds)\n",
            "\tSampling time over 31 tokens:\t0.743000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 75, \"generated_tokens\": 84, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876433499, \"token_encode_end_ms\": 1747876433500, \"model_execution_start_ms\": 1747876438153, \"model_execution_end_ms\": 1747876438206, \"inference_end_ms\": 1747876438206, \"prompt_eval_end_ms\": 1747876433579, \"first_token_ms\": 1747876433632, \"aggregate_sampling_time_ms\": 4684, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 75 Generated Tokens: 84\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t4.707000 (seconds)\t\t Rate: \t17.845762 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.080000 (seconds)\t\t Rate: \t937.500000 (tokens/second)\n",
            "\t\tGenerated 84 tokens:\t4.627000 (seconds)\t\t Rate: \t18.154312 (tokens/second)\n",
            "\tTime to first generated token:\t0.133000 (seconds)\n",
            "\tSampling time over 159 tokens:\t4.684000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 22, \"generated_tokens\": 14, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876438218, \"token_encode_end_ms\": 1747876438219, \"model_execution_start_ms\": 1747876439980, \"model_execution_end_ms\": 1747876440082, \"inference_end_ms\": 1747876440083, \"prompt_eval_end_ms\": 1747876438261, \"first_token_ms\": 1747876438308, \"aggregate_sampling_time_ms\": 1863, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 22 Generated Tokens: 14\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.865000 (seconds)\t\t Rate: \t7.506702 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t511.627907 (tokens/second)\n",
            "\t\tGenerated 14 tokens:\t1.822000 (seconds)\t\t Rate: \t7.683864 (tokens/second)\n",
            "\tTime to first generated token:\t0.090000 (seconds)\n",
            "\tSampling time over 36 tokens:\t1.863000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 68, \"generated_tokens\": 51, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876440093, \"token_encode_end_ms\": 1747876440094, \"model_execution_start_ms\": 1747876443204, \"model_execution_end_ms\": 1747876443256, \"inference_end_ms\": 1747876443256, \"prompt_eval_end_ms\": 1747876440245, \"first_token_ms\": 1747876440350, \"aggregate_sampling_time_ms\": 3148, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 68 Generated Tokens: 51\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.163000 (seconds)\t\t Rate: \t16.123933 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.152000 (seconds)\t\t Rate: \t447.368421 (tokens/second)\n",
            "\t\tGenerated 51 tokens:\t3.011000 (seconds)\t\t Rate: \t16.937894 (tokens/second)\n",
            "\tTime to first generated token:\t0.257000 (seconds)\n",
            "\tSampling time over 119 tokens:\t3.148000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 39, \"generated_tokens\": 33, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876443262, \"token_encode_end_ms\": 1747876443263, \"model_execution_start_ms\": 1747876444955, \"model_execution_end_ms\": 1747876445004, \"inference_end_ms\": 1747876445004, \"prompt_eval_end_ms\": 1747876443320, \"first_token_ms\": 1747876443388, \"aggregate_sampling_time_ms\": 1730, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 39 Generated Tokens: 33\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.742000 (seconds)\t\t Rate: \t18.943743 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t672.413793 (tokens/second)\n",
            "\t\tGenerated 33 tokens:\t1.684000 (seconds)\t\t Rate: \t19.596200 (tokens/second)\n",
            "\tTime to first generated token:\t0.126000 (seconds)\n",
            "\tSampling time over 72 tokens:\t1.730000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876445014, \"token_encode_end_ms\": 1747876445015, \"model_execution_start_ms\": 1747876446252, \"model_execution_end_ms\": 1747876446301, \"inference_end_ms\": 1747876446301, \"prompt_eval_end_ms\": 1747876445064, \"first_token_ms\": 1747876445112, \"aggregate_sampling_time_ms\": 1280, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.287000 (seconds)\t\t Rate: \t18.648019 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.050000 (seconds)\t\t Rate: \t620.000000 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.237000 (seconds)\t\t Rate: \t19.401778 (tokens/second)\n",
            "\tTime to first generated token:\t0.098000 (seconds)\n",
            "\tSampling time over 55 tokens:\t1.280000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 72, \"generated_tokens\": 71, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876446308, \"token_encode_end_ms\": 1747876446308, \"model_execution_start_ms\": 1747876450241, \"model_execution_end_ms\": 1747876450293, \"inference_end_ms\": 1747876450293, \"prompt_eval_end_ms\": 1747876446412, \"first_token_ms\": 1747876446464, \"aggregate_sampling_time_ms\": 3956, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 72 Generated Tokens: 71\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.985000 (seconds)\t\t Rate: \t17.816813 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.104000 (seconds)\t\t Rate: \t692.307692 (tokens/second)\n",
            "\t\tGenerated 71 tokens:\t3.881000 (seconds)\t\t Rate: \t18.294254 (tokens/second)\n",
            "\tTime to first generated token:\t0.156000 (seconds)\n",
            "\tSampling time over 143 tokens:\t3.956000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 26, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876450304, \"token_encode_end_ms\": 1747876450304, \"model_execution_start_ms\": 1747876453077, \"model_execution_end_ms\": 1747876453125, \"inference_end_ms\": 1747876453126, \"prompt_eval_end_ms\": 1747876450352, \"first_token_ms\": 1747876450399, \"aggregate_sampling_time_ms\": 2814, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 26\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.822000 (seconds)\t\t Rate: \t9.213324 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.048000 (seconds)\t\t Rate: \t604.166667 (tokens/second)\n",
            "\t\tGenerated 26 tokens:\t2.774000 (seconds)\t\t Rate: \t9.372747 (tokens/second)\n",
            "\tTime to first generated token:\t0.095000 (seconds)\n",
            "\tSampling time over 55 tokens:\t2.814000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 36, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876453130, \"token_encode_end_ms\": 1747876453141, \"model_execution_start_ms\": 1747876454695, \"model_execution_end_ms\": 1747876454764, \"inference_end_ms\": 1747876454764, \"prompt_eval_end_ms\": 1747876453188, \"first_token_ms\": 1747876453239, \"aggregate_sampling_time_ms\": 1613, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 36 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.634000 (seconds)\t\t Rate: \t18.359853 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t620.689655 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t1.576000 (seconds)\t\t Rate: \t19.035533 (tokens/second)\n",
            "\tTime to first generated token:\t0.109000 (seconds)\n",
            "\tSampling time over 66 tokens:\t1.613000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 22, \"generated_tokens\": 17, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876454769, \"token_encode_end_ms\": 1747876454770, \"model_execution_start_ms\": 1747876455619, \"model_execution_end_ms\": 1747876455668, \"inference_end_ms\": 1747876455669, \"prompt_eval_end_ms\": 1747876454813, \"first_token_ms\": 1747876454860, \"aggregate_sampling_time_ms\": 893, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 22 Generated Tokens: 17\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.900000 (seconds)\t\t Rate: \t18.888889 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t500.000000 (tokens/second)\n",
            "\t\tGenerated 17 tokens:\t0.856000 (seconds)\t\t Rate: \t19.859813 (tokens/second)\n",
            "\tTime to first generated token:\t0.091000 (seconds)\n",
            "\tSampling time over 39 tokens:\t0.893000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 41, \"generated_tokens\": 32, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876455673, \"token_encode_end_ms\": 1747876455673, \"model_execution_start_ms\": 1747876457339, \"model_execution_end_ms\": 1747876457390, \"inference_end_ms\": 1747876457391, \"prompt_eval_end_ms\": 1747876455736, \"first_token_ms\": 1747876455803, \"aggregate_sampling_time_ms\": 1706, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 41 Generated Tokens: 32\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.718000 (seconds)\t\t Rate: \t18.626310 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.063000 (seconds)\t\t Rate: \t650.793651 (tokens/second)\n",
            "\t\tGenerated 32 tokens:\t1.655000 (seconds)\t\t Rate: \t19.335347 (tokens/second)\n",
            "\tTime to first generated token:\t0.130000 (seconds)\n",
            "\tSampling time over 73 tokens:\t1.706000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 32, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876457405, \"token_encode_end_ms\": 1747876457406, \"model_execution_start_ms\": 1747876459027, \"model_execution_end_ms\": 1747876459075, \"inference_end_ms\": 1747876459075, \"prompt_eval_end_ms\": 1747876457451, \"first_token_ms\": 1747876457499, \"aggregate_sampling_time_ms\": 1660, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 32\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.670000 (seconds)\t\t Rate: \t19.161677 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t695.652174 (tokens/second)\n",
            "\t\tGenerated 32 tokens:\t1.624000 (seconds)\t\t Rate: \t19.704433 (tokens/second)\n",
            "\tTime to first generated token:\t0.094000 (seconds)\n",
            "\tSampling time over 64 tokens:\t1.660000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 44, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876459082, \"token_encode_end_ms\": 1747876459083, \"model_execution_start_ms\": 1747876461081, \"model_execution_end_ms\": 1747876461130, \"inference_end_ms\": 1747876461131, \"prompt_eval_end_ms\": 1747876459138, \"first_token_ms\": 1747876459187, \"aggregate_sampling_time_ms\": 2034, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 44 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.049000 (seconds)\t\t Rate: \t19.033675 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.056000 (seconds)\t\t Rate: \t785.714286 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t1.993000 (seconds)\t\t Rate: \t19.568490 (tokens/second)\n",
            "\tTime to first generated token:\t0.105000 (seconds)\n",
            "\tSampling time over 83 tokens:\t2.034000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 36, \"generated_tokens\": 36, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876461142, \"token_encode_end_ms\": 1747876461142, \"model_execution_start_ms\": 1747876462968, \"model_execution_end_ms\": 1747876463062, \"inference_end_ms\": 1747876463062, \"prompt_eval_end_ms\": 1747876461194, \"first_token_ms\": 1747876461245, \"aggregate_sampling_time_ms\": 1910, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 36 Generated Tokens: 36\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.920000 (seconds)\t\t Rate: \t18.750000 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.052000 (seconds)\t\t Rate: \t692.307692 (tokens/second)\n",
            "\t\tGenerated 36 tokens:\t1.868000 (seconds)\t\t Rate: \t19.271949 (tokens/second)\n",
            "\tTime to first generated token:\t0.103000 (seconds)\n",
            "\tSampling time over 72 tokens:\t1.910000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 23, \"generated_tokens\": 20, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876463072, \"token_encode_end_ms\": 1747876463072, \"model_execution_start_ms\": 1747876465481, \"model_execution_end_ms\": 1747876465528, \"inference_end_ms\": 1747876465528, \"prompt_eval_end_ms\": 1747876463141, \"first_token_ms\": 1747876463230, \"aggregate_sampling_time_ms\": 2450, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 23 Generated Tokens: 20\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.456000 (seconds)\t\t Rate: \t8.143322 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.069000 (seconds)\t\t Rate: \t333.333333 (tokens/second)\n",
            "\t\tGenerated 20 tokens:\t2.387000 (seconds)\t\t Rate: \t8.378718 (tokens/second)\n",
            "\tTime to first generated token:\t0.158000 (seconds)\n",
            "\tSampling time over 43 tokens:\t2.450000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 16, \"generated_tokens\": 10, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876465542, \"token_encode_end_ms\": 1747876465542, \"model_execution_start_ms\": 1747876466022, \"model_execution_end_ms\": 1747876466070, \"inference_end_ms\": 1747876466071, \"prompt_eval_end_ms\": 1747876465571, \"first_token_ms\": 1747876465619, \"aggregate_sampling_time_ms\": 525, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 16 Generated Tokens: 10\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.529000 (seconds)\t\t Rate: \t18.903592 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.029000 (seconds)\t\t Rate: \t551.724138 (tokens/second)\n",
            "\t\tGenerated 10 tokens:\t0.500000 (seconds)\t\t Rate: \t20.000000 (tokens/second)\n",
            "\tTime to first generated token:\t0.077000 (seconds)\n",
            "\tSampling time over 26 tokens:\t0.525000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 15, \"generated_tokens\": 9, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876466083, \"token_encode_end_ms\": 1747876466083, \"model_execution_start_ms\": 1747876466575, \"model_execution_end_ms\": 1747876466620, \"inference_end_ms\": 1747876466620, \"prompt_eval_end_ms\": 1747876466126, \"first_token_ms\": 1747876466197, \"aggregate_sampling_time_ms\": 534, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 15 Generated Tokens: 9\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.537000 (seconds)\t\t Rate: \t16.759777 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t348.837209 (tokens/second)\n",
            "\t\tGenerated 9 tokens:\t0.494000 (seconds)\t\t Rate: \t18.218623 (tokens/second)\n",
            "\tTime to first generated token:\t0.114000 (seconds)\n",
            "\tSampling time over 24 tokens:\t0.534000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 42, \"generated_tokens\": 36, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876466633, \"token_encode_end_ms\": 1747876466633, \"model_execution_start_ms\": 1747876468505, \"model_execution_end_ms\": 1747876468554, \"inference_end_ms\": 1747876468555, \"prompt_eval_end_ms\": 1747876466686, \"first_token_ms\": 1747876466735, \"aggregate_sampling_time_ms\": 1912, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 42 Generated Tokens: 36\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.922000 (seconds)\t\t Rate: \t18.730489 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t792.452830 (tokens/second)\n",
            "\t\tGenerated 36 tokens:\t1.869000 (seconds)\t\t Rate: \t19.261637 (tokens/second)\n",
            "\tTime to first generated token:\t0.102000 (seconds)\n",
            "\tSampling time over 78 tokens:\t1.912000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 17, \"generated_tokens\": 13, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876468569, \"token_encode_end_ms\": 1747876468569, \"model_execution_start_ms\": 1747876469186, \"model_execution_end_ms\": 1747876469234, \"inference_end_ms\": 1747876469235, \"prompt_eval_end_ms\": 1747876468599, \"first_token_ms\": 1747876468647, \"aggregate_sampling_time_ms\": 663, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 17 Generated Tokens: 13\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.666000 (seconds)\t\t Rate: \t19.519520 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.030000 (seconds)\t\t Rate: \t566.666667 (tokens/second)\n",
            "\t\tGenerated 13 tokens:\t0.636000 (seconds)\t\t Rate: \t20.440252 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 30 tokens:\t0.663000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 43, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876469238, \"token_encode_end_ms\": 1747876469244, \"model_execution_start_ms\": 1747876471272, \"model_execution_end_ms\": 1747876471321, \"inference_end_ms\": 1747876471321, \"prompt_eval_end_ms\": 1747876469320, \"first_token_ms\": 1747876469369, \"aggregate_sampling_time_ms\": 2064, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 43 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.083000 (seconds)\t\t Rate: \t18.722996 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.082000 (seconds)\t\t Rate: \t524.390244 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t2.001000 (seconds)\t\t Rate: \t19.490255 (tokens/second)\n",
            "\tTime to first generated token:\t0.131000 (seconds)\n",
            "\tSampling time over 82 tokens:\t2.064000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 22, \"generated_tokens\": 18, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876471335, \"token_encode_end_ms\": 1747876471335, \"model_execution_start_ms\": 1747876472227, \"model_execution_end_ms\": 1747876472274, \"inference_end_ms\": 1747876472274, \"prompt_eval_end_ms\": 1747876471392, \"first_token_ms\": 1747876471441, \"aggregate_sampling_time_ms\": 934, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 22 Generated Tokens: 18\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.939000 (seconds)\t\t Rate: \t19.169329 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.057000 (seconds)\t\t Rate: \t385.964912 (tokens/second)\n",
            "\t\tGenerated 18 tokens:\t0.882000 (seconds)\t\t Rate: \t20.408163 (tokens/second)\n",
            "\tTime to first generated token:\t0.106000 (seconds)\n",
            "\tSampling time over 40 tokens:\t0.934000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 22, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876472286, \"token_encode_end_ms\": 1747876472287, \"model_execution_start_ms\": 1747876473093, \"model_execution_end_ms\": 1747876473141, \"inference_end_ms\": 1747876473141, \"prompt_eval_end_ms\": 1747876472323, \"first_token_ms\": 1747876472370, \"aggregate_sampling_time_ms\": 849, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 22 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.855000 (seconds)\t\t Rate: \t18.713450 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.037000 (seconds)\t\t Rate: \t594.594595 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.818000 (seconds)\t\t Rate: \t19.559902 (tokens/second)\n",
            "\tTime to first generated token:\t0.084000 (seconds)\n",
            "\tSampling time over 38 tokens:\t0.849000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876473147, \"token_encode_end_ms\": 1747876473148, \"model_execution_start_ms\": 1747876474346, \"model_execution_end_ms\": 1747876474395, \"inference_end_ms\": 1747876474396, \"prompt_eval_end_ms\": 1747876473192, \"first_token_ms\": 1747876473240, \"aggregate_sampling_time_ms\": 1239, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.249000 (seconds)\t\t Rate: \t19.215372 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.045000 (seconds)\t\t Rate: \t600.000000 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.204000 (seconds)\t\t Rate: \t19.933555 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 51 tokens:\t1.239000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 21, \"generated_tokens\": 15, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876474407, \"token_encode_end_ms\": 1747876474408, \"model_execution_start_ms\": 1747876475168, \"model_execution_end_ms\": 1747876475216, \"inference_end_ms\": 1747876475216, \"prompt_eval_end_ms\": 1747876474444, \"first_token_ms\": 1747876474511, \"aggregate_sampling_time_ms\": 803, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 21 Generated Tokens: 15\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.809000 (seconds)\t\t Rate: \t18.541409 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.037000 (seconds)\t\t Rate: \t567.567568 (tokens/second)\n",
            "\t\tGenerated 15 tokens:\t0.772000 (seconds)\t\t Rate: \t19.430052 (tokens/second)\n",
            "\tTime to first generated token:\t0.104000 (seconds)\n",
            "\tSampling time over 36 tokens:\t0.803000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 51, \"generated_tokens\": 46, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876475228, \"token_encode_end_ms\": 1747876475229, \"model_execution_start_ms\": 1747876479160, \"model_execution_end_ms\": 1747876479211, \"inference_end_ms\": 1747876479211, \"prompt_eval_end_ms\": 1747876475289, \"first_token_ms\": 1747876475339, \"aggregate_sampling_time_ms\": 3970, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 51 Generated Tokens: 46\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.983000 (seconds)\t\t Rate: \t11.549084 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t836.065574 (tokens/second)\n",
            "\t\tGenerated 46 tokens:\t3.922000 (seconds)\t\t Rate: \t11.728710 (tokens/second)\n",
            "\tTime to first generated token:\t0.111000 (seconds)\n",
            "\tSampling time over 97 tokens:\t3.970000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 37, \"generated_tokens\": 31, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876479218, \"token_encode_end_ms\": 1747876479219, \"model_execution_start_ms\": 1747876480818, \"model_execution_end_ms\": 1747876480865, \"inference_end_ms\": 1747876480866, \"prompt_eval_end_ms\": 1747876479275, \"first_token_ms\": 1747876479324, \"aggregate_sampling_time_ms\": 1637, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 37 Generated Tokens: 31\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.648000 (seconds)\t\t Rate: \t18.810680 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.057000 (seconds)\t\t Rate: \t649.122807 (tokens/second)\n",
            "\t\tGenerated 31 tokens:\t1.591000 (seconds)\t\t Rate: \t19.484601 (tokens/second)\n",
            "\tTime to first generated token:\t0.106000 (seconds)\n",
            "\tSampling time over 68 tokens:\t1.637000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 60, \"generated_tokens\": 49, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876480879, \"token_encode_end_ms\": 1747876480880, \"model_execution_start_ms\": 1747876483453, \"model_execution_end_ms\": 1747876483504, \"inference_end_ms\": 1747876483504, \"prompt_eval_end_ms\": 1747876480941, \"first_token_ms\": 1747876480992, \"aggregate_sampling_time_ms\": 2615, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 60 Generated Tokens: 49\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.625000 (seconds)\t\t Rate: \t18.666667 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.062000 (seconds)\t\t Rate: \t967.741935 (tokens/second)\n",
            "\t\tGenerated 49 tokens:\t2.563000 (seconds)\t\t Rate: \t19.118221 (tokens/second)\n",
            "\tTime to first generated token:\t0.113000 (seconds)\n",
            "\tSampling time over 109 tokens:\t2.615000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 21, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876483519, \"token_encode_end_ms\": 1747876483520, \"model_execution_start_ms\": 1747876484578, \"model_execution_end_ms\": 1747876484627, \"inference_end_ms\": 1747876484627, \"prompt_eval_end_ms\": 1747876483565, \"first_token_ms\": 1747876483614, \"aggregate_sampling_time_ms\": 1104, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 21\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.108000 (seconds)\t\t Rate: \t18.953069 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t695.652174 (tokens/second)\n",
            "\t\tGenerated 21 tokens:\t1.062000 (seconds)\t\t Rate: \t19.774011 (tokens/second)\n",
            "\tTime to first generated token:\t0.095000 (seconds)\n",
            "\tSampling time over 53 tokens:\t1.104000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 20, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876484640, \"token_encode_end_ms\": 1747876484641, \"model_execution_start_ms\": 1747876485648, \"model_execution_end_ms\": 1747876485697, \"inference_end_ms\": 1747876485698, \"prompt_eval_end_ms\": 1747876484684, \"first_token_ms\": 1747876484733, \"aggregate_sampling_time_ms\": 1051, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 20\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.058000 (seconds)\t\t Rate: \t18.903592 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t613.636364 (tokens/second)\n",
            "\t\tGenerated 20 tokens:\t1.014000 (seconds)\t\t Rate: \t19.723866 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 47 tokens:\t1.051000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 35, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876485711, \"token_encode_end_ms\": 1747876485711, \"model_execution_start_ms\": 1747876487239, \"model_execution_end_ms\": 1747876487287, \"inference_end_ms\": 1747876487288, \"prompt_eval_end_ms\": 1747876485755, \"first_token_ms\": 1747876485802, \"aggregate_sampling_time_ms\": 1570, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 35 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.577000 (seconds)\t\t Rate: \t19.023462 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t795.454545 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t1.533000 (seconds)\t\t Rate: \t19.569472 (tokens/second)\n",
            "\tTime to first generated token:\t0.091000 (seconds)\n",
            "\tSampling time over 65 tokens:\t1.570000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 13, \"generated_tokens\": 9, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876487295, \"token_encode_end_ms\": 1747876487295, \"model_execution_start_ms\": 1747876487908, \"model_execution_end_ms\": 1747876488018, \"inference_end_ms\": 1747876488018, \"prompt_eval_end_ms\": 1747876487329, \"first_token_ms\": 1747876487374, \"aggregate_sampling_time_ms\": 714, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 13 Generated Tokens: 9\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.723000 (seconds)\t\t Rate: \t12.448133 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.034000 (seconds)\t\t Rate: \t382.352941 (tokens/second)\n",
            "\t\tGenerated 9 tokens:\t0.689000 (seconds)\t\t Rate: \t13.062409 (tokens/second)\n",
            "\tTime to first generated token:\t0.079000 (seconds)\n",
            "\tSampling time over 22 tokens:\t0.714000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 21, \"generated_tokens\": 14, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876488025, \"token_encode_end_ms\": 1747876488025, \"model_execution_start_ms\": 1747876489937, \"model_execution_end_ms\": 1747876489985, \"inference_end_ms\": 1747876489985, \"prompt_eval_end_ms\": 1747876488096, \"first_token_ms\": 1747876488280, \"aggregate_sampling_time_ms\": 1954, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 21 Generated Tokens: 14\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.960000 (seconds)\t\t Rate: \t7.142857 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.071000 (seconds)\t\t Rate: \t295.774648 (tokens/second)\n",
            "\t\tGenerated 14 tokens:\t1.889000 (seconds)\t\t Rate: \t7.411329 (tokens/second)\n",
            "\tTime to first generated token:\t0.255000 (seconds)\n",
            "\tSampling time over 35 tokens:\t1.954000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 14, \"generated_tokens\": 8, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876489990, \"token_encode_end_ms\": 1747876489990, \"model_execution_start_ms\": 1747876490385, \"model_execution_end_ms\": 1747876490433, \"inference_end_ms\": 1747876490434, \"prompt_eval_end_ms\": 1747876490028, \"first_token_ms\": 1747876490092, \"aggregate_sampling_time_ms\": 441, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 14 Generated Tokens: 8\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.444000 (seconds)\t\t Rate: \t18.018018 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.038000 (seconds)\t\t Rate: \t368.421053 (tokens/second)\n",
            "\t\tGenerated 8 tokens:\t0.406000 (seconds)\t\t Rate: \t19.704433 (tokens/second)\n",
            "\tTime to first generated token:\t0.102000 (seconds)\n",
            "\tSampling time over 22 tokens:\t0.441000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 13, \"generated_tokens\": 10, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876490443, \"token_encode_end_ms\": 1747876490443, \"model_execution_start_ms\": 1747876490910, \"model_execution_end_ms\": 1747876490957, \"inference_end_ms\": 1747876490957, \"prompt_eval_end_ms\": 1747876490475, \"first_token_ms\": 1747876490521, \"aggregate_sampling_time_ms\": 511, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 13 Generated Tokens: 10\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.514000 (seconds)\t\t Rate: \t19.455253 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.032000 (seconds)\t\t Rate: \t406.250000 (tokens/second)\n",
            "\t\tGenerated 10 tokens:\t0.482000 (seconds)\t\t Rate: \t20.746888 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 23 tokens:\t0.511000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 16, \"generated_tokens\": 12, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876490963, \"token_encode_end_ms\": 1747876490963, \"model_execution_start_ms\": 1747876491555, \"model_execution_end_ms\": 1747876491602, \"inference_end_ms\": 1747876491603, \"prompt_eval_end_ms\": 1747876490997, \"first_token_ms\": 1747876491046, \"aggregate_sampling_time_ms\": 636, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 16 Generated Tokens: 12\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.640000 (seconds)\t\t Rate: \t18.750000 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.034000 (seconds)\t\t Rate: \t470.588235 (tokens/second)\n",
            "\t\tGenerated 12 tokens:\t0.606000 (seconds)\t\t Rate: \t19.801980 (tokens/second)\n",
            "\tTime to first generated token:\t0.083000 (seconds)\n",
            "\tSampling time over 28 tokens:\t0.636000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 36, \"generated_tokens\": 35, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876491608, \"token_encode_end_ms\": 1747876491609, \"model_execution_start_ms\": 1747876493394, \"model_execution_end_ms\": 1747876493446, \"inference_end_ms\": 1747876493446, \"prompt_eval_end_ms\": 1747876491660, \"first_token_ms\": 1747876491708, \"aggregate_sampling_time_ms\": 1831, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 36 Generated Tokens: 35\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.838000 (seconds)\t\t Rate: \t19.042437 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.052000 (seconds)\t\t Rate: \t692.307692 (tokens/second)\n",
            "\t\tGenerated 35 tokens:\t1.786000 (seconds)\t\t Rate: \t19.596865 (tokens/second)\n",
            "\tTime to first generated token:\t0.100000 (seconds)\n",
            "\tSampling time over 71 tokens:\t1.831000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 14, \"generated_tokens\": 10, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876493454, \"token_encode_end_ms\": 1747876493455, \"model_execution_start_ms\": 1747876493921, \"model_execution_end_ms\": 1747876493968, \"inference_end_ms\": 1747876493968, \"prompt_eval_end_ms\": 1747876493485, \"first_token_ms\": 1747876493532, \"aggregate_sampling_time_ms\": 511, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 14 Generated Tokens: 10\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.514000 (seconds)\t\t Rate: \t19.455253 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.031000 (seconds)\t\t Rate: \t451.612903 (tokens/second)\n",
            "\t\tGenerated 10 tokens:\t0.483000 (seconds)\t\t Rate: \t20.703934 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 24 tokens:\t0.511000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876493977, \"token_encode_end_ms\": 1747876493978, \"model_execution_start_ms\": 1747876495183, \"model_execution_end_ms\": 1747876495237, \"inference_end_ms\": 1747876495238, \"prompt_eval_end_ms\": 1747876494024, \"first_token_ms\": 1747876494074, \"aggregate_sampling_time_ms\": 1248, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.261000 (seconds)\t\t Rate: \t19.032514 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.047000 (seconds)\t\t Rate: \t702.127660 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.214000 (seconds)\t\t Rate: \t19.769357 (tokens/second)\n",
            "\tTime to first generated token:\t0.097000 (seconds)\n",
            "\tSampling time over 57 tokens:\t1.248000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 44, \"generated_tokens\": 40, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876495249, \"token_encode_end_ms\": 1747876495250, \"model_execution_start_ms\": 1747876497354, \"model_execution_end_ms\": 1747876497403, \"inference_end_ms\": 1747876497403, \"prompt_eval_end_ms\": 1747876495310, \"first_token_ms\": 1747876495359, \"aggregate_sampling_time_ms\": 2140, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 44 Generated Tokens: 40\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.154000 (seconds)\t\t Rate: \t18.570102 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t721.311475 (tokens/second)\n",
            "\t\tGenerated 40 tokens:\t2.093000 (seconds)\t\t Rate: \t19.111323 (tokens/second)\n",
            "\tTime to first generated token:\t0.110000 (seconds)\n",
            "\tSampling time over 84 tokens:\t2.140000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 21, \"generated_tokens\": 19, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876497417, \"token_encode_end_ms\": 1747876497418, \"model_execution_start_ms\": 1747876498334, \"model_execution_end_ms\": 1747876498402, \"inference_end_ms\": 1747876498403, \"prompt_eval_end_ms\": 1747876497454, \"first_token_ms\": 1747876497502, \"aggregate_sampling_time_ms\": 980, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 21 Generated Tokens: 19\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.986000 (seconds)\t\t Rate: \t19.269777 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.037000 (seconds)\t\t Rate: \t567.567568 (tokens/second)\n",
            "\t\tGenerated 19 tokens:\t0.949000 (seconds)\t\t Rate: \t20.021075 (tokens/second)\n",
            "\tTime to first generated token:\t0.085000 (seconds)\n",
            "\tSampling time over 40 tokens:\t0.980000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 32, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876498409, \"token_encode_end_ms\": 1747876498410, \"model_execution_start_ms\": 1747876500225, \"model_execution_end_ms\": 1747876500432, \"inference_end_ms\": 1747876500432, \"prompt_eval_end_ms\": 1747876498460, \"first_token_ms\": 1747876498507, \"aggregate_sampling_time_ms\": 2015, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 32\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.023000 (seconds)\t\t Rate: \t15.818092 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.051000 (seconds)\t\t Rate: \t647.058824 (tokens/second)\n",
            "\t\tGenerated 32 tokens:\t1.972000 (seconds)\t\t Rate: \t16.227181 (tokens/second)\n",
            "\tTime to first generated token:\t0.098000 (seconds)\n",
            "\tSampling time over 65 tokens:\t2.015000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876500444, \"token_encode_end_ms\": 1747876500445, \"model_execution_start_ms\": 1747876502725, \"model_execution_end_ms\": 1747876502772, \"inference_end_ms\": 1747876502772, \"prompt_eval_end_ms\": 1747876500509, \"first_token_ms\": 1747876500600, \"aggregate_sampling_time_ms\": 2320, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.328000 (seconds)\t\t Rate: \t10.309278 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.065000 (seconds)\t\t Rate: \t446.153846 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t2.263000 (seconds)\t\t Rate: \t10.605391 (tokens/second)\n",
            "\tTime to first generated token:\t0.156000 (seconds)\n",
            "\tSampling time over 53 tokens:\t2.320000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 43, \"generated_tokens\": 32, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876502778, \"token_encode_end_ms\": 1747876502778, \"model_execution_start_ms\": 1747876504421, \"model_execution_end_ms\": 1747876504472, \"inference_end_ms\": 1747876504472, \"prompt_eval_end_ms\": 1747876502836, \"first_token_ms\": 1747876502885, \"aggregate_sampling_time_ms\": 1686, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 43 Generated Tokens: 32\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.694000 (seconds)\t\t Rate: \t18.890201 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t741.379310 (tokens/second)\n",
            "\t\tGenerated 32 tokens:\t1.636000 (seconds)\t\t Rate: \t19.559902 (tokens/second)\n",
            "\tTime to first generated token:\t0.107000 (seconds)\n",
            "\tSampling time over 75 tokens:\t1.686000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 19, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876504484, \"token_encode_end_ms\": 1747876504485, \"model_execution_start_ms\": 1747876505431, \"model_execution_end_ms\": 1747876505479, \"inference_end_ms\": 1747876505480, \"prompt_eval_end_ms\": 1747876504527, \"first_token_ms\": 1747876504584, \"aggregate_sampling_time_ms\": 989, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 19\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.996000 (seconds)\t\t Rate: \t19.076305 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t674.418605 (tokens/second)\n",
            "\t\tGenerated 19 tokens:\t0.953000 (seconds)\t\t Rate: \t19.937041 (tokens/second)\n",
            "\tTime to first generated token:\t0.100000 (seconds)\n",
            "\tSampling time over 48 tokens:\t0.989000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876505493, \"token_encode_end_ms\": 1747876505494, \"model_execution_start_ms\": 1747876506958, \"model_execution_end_ms\": 1747876507007, \"inference_end_ms\": 1747876507007, \"prompt_eval_end_ms\": 1747876505538, \"first_token_ms\": 1747876505585, \"aggregate_sampling_time_ms\": 1505, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.514000 (seconds)\t\t Rate: \t19.154557 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.045000 (seconds)\t\t Rate: \t733.333333 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.469000 (seconds)\t\t Rate: \t19.741321 (tokens/second)\n",
            "\tTime to first generated token:\t0.092000 (seconds)\n",
            "\tSampling time over 62 tokens:\t1.505000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 23, \"generated_tokens\": 17, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876507022, \"token_encode_end_ms\": 1747876507022, \"model_execution_start_ms\": 1747876507859, \"model_execution_end_ms\": 1747876507906, \"inference_end_ms\": 1747876507906, \"prompt_eval_end_ms\": 1747876507057, \"first_token_ms\": 1747876507105, \"aggregate_sampling_time_ms\": 877, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 23 Generated Tokens: 17\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.884000 (seconds)\t\t Rate: \t19.230769 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.035000 (seconds)\t\t Rate: \t657.142857 (tokens/second)\n",
            "\t\tGenerated 17 tokens:\t0.849000 (seconds)\t\t Rate: \t20.023557 (tokens/second)\n",
            "\tTime to first generated token:\t0.083000 (seconds)\n",
            "\tSampling time over 40 tokens:\t0.877000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 13, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876507918, \"token_encode_end_ms\": 1747876507919, \"model_execution_start_ms\": 1747876508561, \"model_execution_end_ms\": 1747876508608, \"inference_end_ms\": 1747876508609, \"prompt_eval_end_ms\": 1747876507959, \"first_token_ms\": 1747876508006, \"aggregate_sampling_time_ms\": 686, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 13\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.691000 (seconds)\t\t Rate: \t18.813314 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.041000 (seconds)\t\t Rate: \t658.536585 (tokens/second)\n",
            "\t\tGenerated 13 tokens:\t0.650000 (seconds)\t\t Rate: \t20.000000 (tokens/second)\n",
            "\tTime to first generated token:\t0.088000 (seconds)\n",
            "\tSampling time over 40 tokens:\t0.686000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876508621, \"token_encode_end_ms\": 1747876508622, \"model_execution_start_ms\": 1747876509870, \"model_execution_end_ms\": 1747876509918, \"inference_end_ms\": 1747876509919, \"prompt_eval_end_ms\": 1747876508668, \"first_token_ms\": 1747876508736, \"aggregate_sampling_time_ms\": 1288, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.298000 (seconds)\t\t Rate: \t18.489985 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.047000 (seconds)\t\t Rate: \t659.574468 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.251000 (seconds)\t\t Rate: \t19.184652 (tokens/second)\n",
            "\tTime to first generated token:\t0.115000 (seconds)\n",
            "\tSampling time over 55 tokens:\t1.288000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 35, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876509933, \"token_encode_end_ms\": 1747876509933, \"model_execution_start_ms\": 1747876511711, \"model_execution_end_ms\": 1747876511760, \"inference_end_ms\": 1747876511760, \"prompt_eval_end_ms\": 1747876509978, \"first_token_ms\": 1747876510028, \"aggregate_sampling_time_ms\": 1818, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 35\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.827000 (seconds)\t\t Rate: \t19.157088 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.045000 (seconds)\t\t Rate: \t711.111111 (tokens/second)\n",
            "\t\tGenerated 35 tokens:\t1.782000 (seconds)\t\t Rate: \t19.640853 (tokens/second)\n",
            "\tTime to first generated token:\t0.095000 (seconds)\n",
            "\tSampling time over 67 tokens:\t1.818000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 39, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876511771, \"token_encode_end_ms\": 1747876511772, \"model_execution_start_ms\": 1747876515354, \"model_execution_end_ms\": 1747876515403, \"inference_end_ms\": 1747876515404, \"prompt_eval_end_ms\": 1747876511844, \"first_token_ms\": 1747876511901, \"aggregate_sampling_time_ms\": 3621, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 39 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.633000 (seconds)\t\t Rate: \t10.734930 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.073000 (seconds)\t\t Rate: \t534.246575 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t3.560000 (seconds)\t\t Rate: \t10.955056 (tokens/second)\n",
            "\tTime to first generated token:\t0.130000 (seconds)\n",
            "\tSampling time over 78 tokens:\t3.621000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 19, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876515418, \"token_encode_end_ms\": 1747876515418, \"model_execution_start_ms\": 1747876516388, \"model_execution_end_ms\": 1747876516436, \"inference_end_ms\": 1747876516436, \"prompt_eval_end_ms\": 1747876515464, \"first_token_ms\": 1747876515515, \"aggregate_sampling_time_ms\": 1011, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 19\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.018000 (seconds)\t\t Rate: \t18.664047 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t586.956522 (tokens/second)\n",
            "\t\tGenerated 19 tokens:\t0.972000 (seconds)\t\t Rate: \t19.547325 (tokens/second)\n",
            "\tTime to first generated token:\t0.097000 (seconds)\n",
            "\tSampling time over 46 tokens:\t1.011000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876516450, \"token_encode_end_ms\": 1747876516451, \"model_execution_start_ms\": 1747876517918, \"model_execution_end_ms\": 1747876517966, \"inference_end_ms\": 1747876517967, \"prompt_eval_end_ms\": 1747876516496, \"first_token_ms\": 1747876516544, \"aggregate_sampling_time_ms\": 1504, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.517000 (seconds)\t\t Rate: \t19.116678 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t695.652174 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.471000 (seconds)\t\t Rate: \t19.714480 (tokens/second)\n",
            "\tTime to first generated token:\t0.094000 (seconds)\n",
            "\tSampling time over 61 tokens:\t1.504000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 26, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876517980, \"token_encode_end_ms\": 1747876517981, \"model_execution_start_ms\": 1747876519309, \"model_execution_end_ms\": 1747876519358, \"inference_end_ms\": 1747876519358, \"prompt_eval_end_ms\": 1747876518025, \"first_token_ms\": 1747876518079, \"aggregate_sampling_time_ms\": 1369, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 26\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.378000 (seconds)\t\t Rate: \t18.867925 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.045000 (seconds)\t\t Rate: \t733.333333 (tokens/second)\n",
            "\t\tGenerated 26 tokens:\t1.333000 (seconds)\t\t Rate: \t19.504876 (tokens/second)\n",
            "\tTime to first generated token:\t0.099000 (seconds)\n",
            "\tSampling time over 59 tokens:\t1.369000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 34, \"generated_tokens\": 31, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876519362, \"token_encode_end_ms\": 1747876519364, \"model_execution_start_ms\": 1747876520933, \"model_execution_end_ms\": 1747876520981, \"inference_end_ms\": 1747876520981, \"prompt_eval_end_ms\": 1747876519415, \"first_token_ms\": 1747876519462, \"aggregate_sampling_time_ms\": 1610, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 34 Generated Tokens: 31\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.619000 (seconds)\t\t Rate: \t19.147622 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t641.509434 (tokens/second)\n",
            "\t\tGenerated 31 tokens:\t1.566000 (seconds)\t\t Rate: \t19.795658 (tokens/second)\n",
            "\tTime to first generated token:\t0.100000 (seconds)\n",
            "\tSampling time over 65 tokens:\t1.610000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 52, \"generated_tokens\": 43, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876520989, \"token_encode_end_ms\": 1747876520989, \"model_execution_start_ms\": 1747876523260, \"model_execution_end_ms\": 1747876523330, \"inference_end_ms\": 1747876523331, \"prompt_eval_end_ms\": 1747876521054, \"first_token_ms\": 1747876521105, \"aggregate_sampling_time_ms\": 2326, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 52 Generated Tokens: 43\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.342000 (seconds)\t\t Rate: \t18.360376 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.065000 (seconds)\t\t Rate: \t800.000000 (tokens/second)\n",
            "\t\tGenerated 43 tokens:\t2.277000 (seconds)\t\t Rate: \t18.884497 (tokens/second)\n",
            "\tTime to first generated token:\t0.116000 (seconds)\n",
            "\tSampling time over 95 tokens:\t2.326000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 34, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876523341, \"token_encode_end_ms\": 1747876523343, \"model_execution_start_ms\": 1747876525525, \"model_execution_end_ms\": 1747876525652, \"inference_end_ms\": 1747876525652, \"prompt_eval_end_ms\": 1747876523389, \"first_token_ms\": 1747876523437, \"aggregate_sampling_time_ms\": 2302, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 34 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.311000 (seconds)\t\t Rate: \t12.981393 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.048000 (seconds)\t\t Rate: \t708.333333 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t2.263000 (seconds)\t\t Rate: \t13.256739 (tokens/second)\n",
            "\tTime to first generated token:\t0.096000 (seconds)\n",
            "\tSampling time over 64 tokens:\t2.302000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 34, \"generated_tokens\": 27, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876525665, \"token_encode_end_ms\": 1747876525666, \"model_execution_start_ms\": 1747876527789, \"model_execution_end_ms\": 1747876527838, \"inference_end_ms\": 1747876527838, \"prompt_eval_end_ms\": 1747876525778, \"first_token_ms\": 1747876526174, \"aggregate_sampling_time_ms\": 2167, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 34 Generated Tokens: 27\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.173000 (seconds)\t\t Rate: \t12.425219 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.113000 (seconds)\t\t Rate: \t300.884956 (tokens/second)\n",
            "\t\tGenerated 27 tokens:\t2.060000 (seconds)\t\t Rate: \t13.106796 (tokens/second)\n",
            "\tTime to first generated token:\t0.509000 (seconds)\n",
            "\tSampling time over 61 tokens:\t2.167000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 20, \"generated_tokens\": 19, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876527851, \"token_encode_end_ms\": 1747876527852, \"model_execution_start_ms\": 1747876528778, \"model_execution_end_ms\": 1747876528824, \"inference_end_ms\": 1747876528824, \"prompt_eval_end_ms\": 1747876527885, \"first_token_ms\": 1747876527933, \"aggregate_sampling_time_ms\": 966, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 20 Generated Tokens: 19\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.973000 (seconds)\t\t Rate: \t19.527235 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.034000 (seconds)\t\t Rate: \t588.235294 (tokens/second)\n",
            "\t\tGenerated 19 tokens:\t0.939000 (seconds)\t\t Rate: \t20.234292 (tokens/second)\n",
            "\tTime to first generated token:\t0.082000 (seconds)\n",
            "\tSampling time over 39 tokens:\t0.966000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 25, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876528837, \"token_encode_end_ms\": 1747876528837, \"model_execution_start_ms\": 1747876530076, \"model_execution_end_ms\": 1747876530124, \"inference_end_ms\": 1747876530125, \"prompt_eval_end_ms\": 1747876528881, \"first_token_ms\": 1747876528928, \"aggregate_sampling_time_ms\": 1281, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 25\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.288000 (seconds)\t\t Rate: \t19.409938 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t750.000000 (tokens/second)\n",
            "\t\tGenerated 25 tokens:\t1.244000 (seconds)\t\t Rate: \t20.096463 (tokens/second)\n",
            "\tTime to first generated token:\t0.091000 (seconds)\n",
            "\tSampling time over 58 tokens:\t1.281000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 28, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876530137, \"token_encode_end_ms\": 1747876530138, \"model_execution_start_ms\": 1747876531343, \"model_execution_end_ms\": 1747876531392, \"inference_end_ms\": 1747876531392, \"prompt_eval_end_ms\": 1747876530181, \"first_token_ms\": 1747876530230, \"aggregate_sampling_time_ms\": 1249, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 28 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.255000 (seconds)\t\t Rate: \t19.123506 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t636.363636 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.211000 (seconds)\t\t Rate: \t19.818332 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 52 tokens:\t1.249000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 28, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876531406, \"token_encode_end_ms\": 1747876531406, \"model_execution_start_ms\": 1747876532597, \"model_execution_end_ms\": 1747876532665, \"inference_end_ms\": 1747876532665, \"prompt_eval_end_ms\": 1747876531448, \"first_token_ms\": 1747876531496, \"aggregate_sampling_time_ms\": 1246, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 28 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.259000 (seconds)\t\t Rate: \t19.062748 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.042000 (seconds)\t\t Rate: \t666.666667 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.217000 (seconds)\t\t Rate: \t19.720624 (tokens/second)\n",
            "\tTime to first generated token:\t0.090000 (seconds)\n",
            "\tSampling time over 52 tokens:\t1.246000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 14, \"generated_tokens\": 13, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876532678, \"token_encode_end_ms\": 1747876532679, \"model_execution_start_ms\": 1747876533293, \"model_execution_end_ms\": 1747876533339, \"inference_end_ms\": 1747876533340, \"prompt_eval_end_ms\": 1747876532709, \"first_token_ms\": 1747876532755, \"aggregate_sampling_time_ms\": 655, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 14 Generated Tokens: 13\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.662000 (seconds)\t\t Rate: \t19.637462 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.031000 (seconds)\t\t Rate: \t451.612903 (tokens/second)\n",
            "\t\tGenerated 13 tokens:\t0.631000 (seconds)\t\t Rate: \t20.602219 (tokens/second)\n",
            "\tTime to first generated token:\t0.077000 (seconds)\n",
            "\tSampling time over 27 tokens:\t0.655000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 63, \"generated_tokens\": 56, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876533345, \"token_encode_end_ms\": 1747876533346, \"model_execution_start_ms\": 1747876536407, \"model_execution_end_ms\": 1747876536458, \"inference_end_ms\": 1747876536458, \"prompt_eval_end_ms\": 1747876533418, \"first_token_ms\": 1747876533470, \"aggregate_sampling_time_ms\": 3098, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 63 Generated Tokens: 56\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.113000 (seconds)\t\t Rate: \t17.989078 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.073000 (seconds)\t\t Rate: \t863.013699 (tokens/second)\n",
            "\t\tGenerated 56 tokens:\t3.040000 (seconds)\t\t Rate: \t18.421053 (tokens/second)\n",
            "\tTime to first generated token:\t0.125000 (seconds)\n",
            "\tSampling time over 119 tokens:\t3.098000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 49, \"generated_tokens\": 44, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876536468, \"token_encode_end_ms\": 1747876536469, \"model_execution_start_ms\": 1747876540309, \"model_execution_end_ms\": 1747876540358, \"inference_end_ms\": 1747876540358, \"prompt_eval_end_ms\": 1747876536529, \"first_token_ms\": 1747876536579, \"aggregate_sampling_time_ms\": 3873, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 49 Generated Tokens: 44\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.890000 (seconds)\t\t Rate: \t11.311054 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t803.278689 (tokens/second)\n",
            "\t\tGenerated 44 tokens:\t3.829000 (seconds)\t\t Rate: \t11.491251 (tokens/second)\n",
            "\tTime to first generated token:\t0.111000 (seconds)\n",
            "\tSampling time over 93 tokens:\t3.873000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 20, \"generated_tokens\": 15, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876540367, \"token_encode_end_ms\": 1747876540368, \"model_execution_start_ms\": 1747876541098, \"model_execution_end_ms\": 1747876541146, \"inference_end_ms\": 1747876541146, \"prompt_eval_end_ms\": 1747876540404, \"first_token_ms\": 1747876540450, \"aggregate_sampling_time_ms\": 774, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 20 Generated Tokens: 15\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.779000 (seconds)\t\t Rate: \t19.255456 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.037000 (seconds)\t\t Rate: \t540.540541 (tokens/second)\n",
            "\t\tGenerated 15 tokens:\t0.742000 (seconds)\t\t Rate: \t20.215633 (tokens/second)\n",
            "\tTime to first generated token:\t0.083000 (seconds)\n",
            "\tSampling time over 35 tokens:\t0.774000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 37, \"generated_tokens\": 33, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876541151, \"token_encode_end_ms\": 1747876541152, \"model_execution_start_ms\": 1747876542842, \"model_execution_end_ms\": 1747876542891, \"inference_end_ms\": 1747876542891, \"prompt_eval_end_ms\": 1747876541204, \"first_token_ms\": 1747876541255, \"aggregate_sampling_time_ms\": 1734, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 37 Generated Tokens: 33\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.740000 (seconds)\t\t Rate: \t18.965517 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t698.113208 (tokens/second)\n",
            "\t\tGenerated 33 tokens:\t1.687000 (seconds)\t\t Rate: \t19.561352 (tokens/second)\n",
            "\tTime to first generated token:\t0.104000 (seconds)\n",
            "\tSampling time over 70 tokens:\t1.734000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 14, \"generated_tokens\": 7, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876542899, \"token_encode_end_ms\": 1747876542900, \"model_execution_start_ms\": 1747876543250, \"model_execution_end_ms\": 1747876543297, \"inference_end_ms\": 1747876543297, \"prompt_eval_end_ms\": 1747876542931, \"first_token_ms\": 1747876542977, \"aggregate_sampling_time_ms\": 395, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 14 Generated Tokens: 7\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.398000 (seconds)\t\t Rate: \t17.587940 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.032000 (seconds)\t\t Rate: \t437.500000 (tokens/second)\n",
            "\t\tGenerated 7 tokens:\t0.366000 (seconds)\t\t Rate: \t19.125683 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 21 tokens:\t0.395000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 22, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876543304, \"token_encode_end_ms\": 1747876543304, \"model_execution_start_ms\": 1747876544397, \"model_execution_end_ms\": 1747876544444, \"inference_end_ms\": 1747876544445, \"prompt_eval_end_ms\": 1747876543350, \"first_token_ms\": 1747876543396, \"aggregate_sampling_time_ms\": 1134, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 22 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.141000 (seconds)\t\t Rate: \t19.281332 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t478.260870 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.095000 (seconds)\t\t Rate: \t20.091324 (tokens/second)\n",
            "\tTime to first generated token:\t0.092000 (seconds)\n",
            "\tSampling time over 44 tokens:\t1.134000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 46, \"generated_tokens\": 40, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876544452, \"token_encode_end_ms\": 1747876544452, \"model_execution_start_ms\": 1747876546561, \"model_execution_end_ms\": 1747876546612, \"inference_end_ms\": 1747876546612, \"prompt_eval_end_ms\": 1747876544512, \"first_token_ms\": 1747876544565, \"aggregate_sampling_time_ms\": 2151, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 46 Generated Tokens: 40\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.160000 (seconds)\t\t Rate: \t18.518519 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.060000 (seconds)\t\t Rate: \t766.666667 (tokens/second)\n",
            "\t\tGenerated 40 tokens:\t2.100000 (seconds)\t\t Rate: \t19.047619 (tokens/second)\n",
            "\tTime to first generated token:\t0.113000 (seconds)\n",
            "\tSampling time over 86 tokens:\t2.151000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 14, \"generated_tokens\": 11, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876546621, \"token_encode_end_ms\": 1747876546622, \"model_execution_start_ms\": 1747876547138, \"model_execution_end_ms\": 1747876547207, \"inference_end_ms\": 1747876547207, \"prompt_eval_end_ms\": 1747876546654, \"first_token_ms\": 1747876546702, \"aggregate_sampling_time_ms\": 584, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 14 Generated Tokens: 11\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.586000 (seconds)\t\t Rate: \t18.771331 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.033000 (seconds)\t\t Rate: \t424.242424 (tokens/second)\n",
            "\t\tGenerated 11 tokens:\t0.553000 (seconds)\t\t Rate: \t19.891501 (tokens/second)\n",
            "\tTime to first generated token:\t0.081000 (seconds)\n",
            "\tSampling time over 25 tokens:\t0.584000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 19, \"generated_tokens\": 15, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876547212, \"token_encode_end_ms\": 1747876547213, \"model_execution_start_ms\": 1747876547930, \"model_execution_end_ms\": 1747876547976, \"inference_end_ms\": 1747876547976, \"prompt_eval_end_ms\": 1747876547252, \"first_token_ms\": 1747876547300, \"aggregate_sampling_time_ms\": 761, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 19 Generated Tokens: 15\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.764000 (seconds)\t\t Rate: \t19.633508 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.040000 (seconds)\t\t Rate: \t475.000000 (tokens/second)\n",
            "\t\tGenerated 15 tokens:\t0.724000 (seconds)\t\t Rate: \t20.718232 (tokens/second)\n",
            "\tTime to first generated token:\t0.088000 (seconds)\n",
            "\tSampling time over 34 tokens:\t0.761000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876547982, \"token_encode_end_ms\": 1747876547982, \"model_execution_start_ms\": 1747876550044, \"model_execution_end_ms\": 1747876550137, \"inference_end_ms\": 1747876550137, \"prompt_eval_end_ms\": 1747876548029, \"first_token_ms\": 1747876548077, \"aggregate_sampling_time_ms\": 2142, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.155000 (seconds)\t\t Rate: \t13.457077 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.047000 (seconds)\t\t Rate: \t638.297872 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t2.108000 (seconds)\t\t Rate: \t13.757116 (tokens/second)\n",
            "\tTime to first generated token:\t0.095000 (seconds)\n",
            "\tSampling time over 59 tokens:\t2.142000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 53, \"generated_tokens\": 26, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876550142, \"token_encode_end_ms\": 1747876550142, \"model_execution_start_ms\": 1747876552315, \"model_execution_end_ms\": 1747876552366, \"inference_end_ms\": 1747876552366, \"prompt_eval_end_ms\": 1747876550269, \"first_token_ms\": 1747876550388, \"aggregate_sampling_time_ms\": 2217, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 53 Generated Tokens: 26\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.224000 (seconds)\t\t Rate: \t11.690647 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.127000 (seconds)\t\t Rate: \t417.322835 (tokens/second)\n",
            "\t\tGenerated 26 tokens:\t2.097000 (seconds)\t\t Rate: \t12.398665 (tokens/second)\n",
            "\tTime to first generated token:\t0.246000 (seconds)\n",
            "\tSampling time over 79 tokens:\t2.217000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876552371, \"token_encode_end_ms\": 1747876552372, \"model_execution_start_ms\": 1747876553510, \"model_execution_end_ms\": 1747876553561, \"inference_end_ms\": 1747876553561, \"prompt_eval_end_ms\": 1747876552444, \"first_token_ms\": 1747876552493, \"aggregate_sampling_time_ms\": 1185, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.190000 (seconds)\t\t Rate: \t18.487395 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.073000 (seconds)\t\t Rate: \t410.958904 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.117000 (seconds)\t\t Rate: \t19.695613 (tokens/second)\n",
            "\tTime to first generated token:\t0.122000 (seconds)\n",
            "\tSampling time over 52 tokens:\t1.185000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876553568, \"token_encode_end_ms\": 1747876553568, \"model_execution_start_ms\": 1747876554690, \"model_execution_end_ms\": 1747876554739, \"inference_end_ms\": 1747876554739, \"prompt_eval_end_ms\": 1747876553617, \"first_token_ms\": 1747876553666, \"aggregate_sampling_time_ms\": 1167, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.171000 (seconds)\t\t Rate: \t18.787361 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.049000 (seconds)\t\t Rate: \t591.836735 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.122000 (seconds)\t\t Rate: \t19.607843 (tokens/second)\n",
            "\tTime to first generated token:\t0.098000 (seconds)\n",
            "\tSampling time over 51 tokens:\t1.167000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 15, \"generated_tokens\": 10, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876554745, \"token_encode_end_ms\": 1747876554746, \"model_execution_start_ms\": 1747876555222, \"model_execution_end_ms\": 1747876555271, \"inference_end_ms\": 1747876555271, \"prompt_eval_end_ms\": 1747876554777, \"first_token_ms\": 1747876554823, \"aggregate_sampling_time_ms\": 522, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 15 Generated Tokens: 10\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.526000 (seconds)\t\t Rate: \t19.011407 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.032000 (seconds)\t\t Rate: \t468.750000 (tokens/second)\n",
            "\t\tGenerated 10 tokens:\t0.494000 (seconds)\t\t Rate: \t20.242915 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 25 tokens:\t0.522000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 14, \"generated_tokens\": 11, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876555278, \"token_encode_end_ms\": 1747876555278, \"model_execution_start_ms\": 1747876555830, \"model_execution_end_ms\": 1747876555876, \"inference_end_ms\": 1747876555877, \"prompt_eval_end_ms\": 1747876555311, \"first_token_ms\": 1747876555359, \"aggregate_sampling_time_ms\": 595, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 14 Generated Tokens: 11\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.599000 (seconds)\t\t Rate: \t18.363940 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.033000 (seconds)\t\t Rate: \t424.242424 (tokens/second)\n",
            "\t\tGenerated 11 tokens:\t0.566000 (seconds)\t\t Rate: \t19.434629 (tokens/second)\n",
            "\tTime to first generated token:\t0.081000 (seconds)\n",
            "\tSampling time over 25 tokens:\t0.595000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 25, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876555888, \"token_encode_end_ms\": 1747876555889, \"model_execution_start_ms\": 1747876557043, \"model_execution_end_ms\": 1747876557091, \"inference_end_ms\": 1747876557092, \"prompt_eval_end_ms\": 1747876555926, \"first_token_ms\": 1747876555972, \"aggregate_sampling_time_ms\": 1194, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 25 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.204000 (seconds)\t\t Rate: \t18.272425 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.038000 (seconds)\t\t Rate: \t657.894737 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.166000 (seconds)\t\t Rate: \t18.867925 (tokens/second)\n",
            "\tTime to first generated token:\t0.084000 (seconds)\n",
            "\tSampling time over 47 tokens:\t1.194000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 39, \"generated_tokens\": 37, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876557106, \"token_encode_end_ms\": 1747876557107, \"model_execution_start_ms\": 1747876559008, \"model_execution_end_ms\": 1747876559057, \"inference_end_ms\": 1747876559057, \"prompt_eval_end_ms\": 1747876557156, \"first_token_ms\": 1747876557205, \"aggregate_sampling_time_ms\": 1938, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 39 Generated Tokens: 37\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.951000 (seconds)\t\t Rate: \t18.964634 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.050000 (seconds)\t\t Rate: \t780.000000 (tokens/second)\n",
            "\t\tGenerated 37 tokens:\t1.901000 (seconds)\t\t Rate: \t19.463440 (tokens/second)\n",
            "\tTime to first generated token:\t0.099000 (seconds)\n",
            "\tSampling time over 76 tokens:\t1.938000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 39, \"generated_tokens\": 41, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876559062, \"token_encode_end_ms\": 1747876559063, \"model_execution_start_ms\": 1747876561189, \"model_execution_end_ms\": 1747876561238, \"inference_end_ms\": 1747876561239, \"prompt_eval_end_ms\": 1747876559108, \"first_token_ms\": 1747876559177, \"aggregate_sampling_time_ms\": 2164, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 39 Generated Tokens: 41\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.177000 (seconds)\t\t Rate: \t18.833257 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t847.826087 (tokens/second)\n",
            "\t\tGenerated 41 tokens:\t2.131000 (seconds)\t\t Rate: \t19.239794 (tokens/second)\n",
            "\tTime to first generated token:\t0.115000 (seconds)\n",
            "\tSampling time over 80 tokens:\t2.164000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876561247, \"token_encode_end_ms\": 1747876561247, \"model_execution_start_ms\": 1747876563855, \"model_execution_end_ms\": 1747876563921, \"inference_end_ms\": 1747876563921, \"prompt_eval_end_ms\": 1747876561301, \"first_token_ms\": 1747876561348, \"aggregate_sampling_time_ms\": 2666, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.674000 (seconds)\t\t Rate: \t8.601346 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.054000 (seconds)\t\t Rate: \t574.074074 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t2.620000 (seconds)\t\t Rate: \t8.778626 (tokens/second)\n",
            "\tTime to first generated token:\t0.101000 (seconds)\n",
            "\tSampling time over 54 tokens:\t2.666000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 14, \"generated_tokens\": 10, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876563925, \"token_encode_end_ms\": 1747876563925, \"model_execution_start_ms\": 1747876564400, \"model_execution_end_ms\": 1747876564449, \"inference_end_ms\": 1747876564449, \"prompt_eval_end_ms\": 1747876563952, \"first_token_ms\": 1747876564004, \"aggregate_sampling_time_ms\": 521, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 14 Generated Tokens: 10\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.524000 (seconds)\t\t Rate: \t19.083969 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.027000 (seconds)\t\t Rate: \t518.518519 (tokens/second)\n",
            "\t\tGenerated 10 tokens:\t0.497000 (seconds)\t\t Rate: \t20.120724 (tokens/second)\n",
            "\tTime to first generated token:\t0.079000 (seconds)\n",
            "\tSampling time over 24 tokens:\t0.521000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 23, \"generated_tokens\": 17, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876564452, \"token_encode_end_ms\": 1747876564453, \"model_execution_start_ms\": 1747876565310, \"model_execution_end_ms\": 1747876565358, \"inference_end_ms\": 1747876565358, \"prompt_eval_end_ms\": 1747876564496, \"first_token_ms\": 1747876564543, \"aggregate_sampling_time_ms\": 903, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 23 Generated Tokens: 17\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.906000 (seconds)\t\t Rate: \t18.763797 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t522.727273 (tokens/second)\n",
            "\t\tGenerated 17 tokens:\t0.862000 (seconds)\t\t Rate: \t19.721578 (tokens/second)\n",
            "\tTime to first generated token:\t0.091000 (seconds)\n",
            "\tSampling time over 40 tokens:\t0.903000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 39, \"generated_tokens\": 33, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876565362, \"token_encode_end_ms\": 1747876565362, \"model_execution_start_ms\": 1747876567063, \"model_execution_end_ms\": 1747876567112, \"inference_end_ms\": 1747876567113, \"prompt_eval_end_ms\": 1747876565420, \"first_token_ms\": 1747876565469, \"aggregate_sampling_time_ms\": 1736, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 39 Generated Tokens: 33\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.751000 (seconds)\t\t Rate: \t18.846374 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t672.413793 (tokens/second)\n",
            "\t\tGenerated 33 tokens:\t1.693000 (seconds)\t\t Rate: \t19.492026 (tokens/second)\n",
            "\tTime to first generated token:\t0.107000 (seconds)\n",
            "\tSampling time over 72 tokens:\t1.736000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 68, \"generated_tokens\": 50, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876567120, \"token_encode_end_ms\": 1747876567121, \"model_execution_start_ms\": 1747876569830, \"model_execution_end_ms\": 1747876569881, \"inference_end_ms\": 1747876569881, \"prompt_eval_end_ms\": 1747876567195, \"first_token_ms\": 1747876567248, \"aggregate_sampling_time_ms\": 2748, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 68 Generated Tokens: 50\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.761000 (seconds)\t\t Rate: \t18.109381 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.075000 (seconds)\t\t Rate: \t906.666667 (tokens/second)\n",
            "\t\tGenerated 50 tokens:\t2.686000 (seconds)\t\t Rate: \t18.615041 (tokens/second)\n",
            "\tTime to first generated token:\t0.128000 (seconds)\n",
            "\tSampling time over 118 tokens:\t2.748000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 63, \"generated_tokens\": 45, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876569896, \"token_encode_end_ms\": 1747876569897, \"model_execution_start_ms\": 1747876572331, \"model_execution_end_ms\": 1747876572383, \"inference_end_ms\": 1747876572383, \"prompt_eval_end_ms\": 1747876569963, \"first_token_ms\": 1747876570014, \"aggregate_sampling_time_ms\": 2474, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 63 Generated Tokens: 45\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.487000 (seconds)\t\t Rate: \t18.094089 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.067000 (seconds)\t\t Rate: \t940.298507 (tokens/second)\n",
            "\t\tGenerated 45 tokens:\t2.420000 (seconds)\t\t Rate: \t18.595041 (tokens/second)\n",
            "\tTime to first generated token:\t0.118000 (seconds)\n",
            "\tSampling time over 108 tokens:\t2.474000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 42, \"generated_tokens\": 37, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876572391, \"token_encode_end_ms\": 1747876572392, \"model_execution_start_ms\": 1747876575710, \"model_execution_end_ms\": 1747876575793, \"inference_end_ms\": 1747876575793, \"prompt_eval_end_ms\": 1747876572444, \"first_token_ms\": 1747876572502, \"aggregate_sampling_time_ms\": 3386, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 42 Generated Tokens: 37\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.402000 (seconds)\t\t Rate: \t10.875955 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t792.452830 (tokens/second)\n",
            "\t\tGenerated 37 tokens:\t3.349000 (seconds)\t\t Rate: \t11.048074 (tokens/second)\n",
            "\tTime to first generated token:\t0.111000 (seconds)\n",
            "\tSampling time over 79 tokens:\t3.386000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 71, \"generated_tokens\": 78, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876575809, \"token_encode_end_ms\": 1747876575810, \"model_execution_start_ms\": 1747876580124, \"model_execution_end_ms\": 1747876580178, \"inference_end_ms\": 1747876580178, \"prompt_eval_end_ms\": 1747876575885, \"first_token_ms\": 1747876575937, \"aggregate_sampling_time_ms\": 4347, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 71 Generated Tokens: 78\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t4.369000 (seconds)\t\t Rate: \t17.853056 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.076000 (seconds)\t\t Rate: \t934.210526 (tokens/second)\n",
            "\t\tGenerated 78 tokens:\t4.293000 (seconds)\t\t Rate: \t18.169113 (tokens/second)\n",
            "\tTime to first generated token:\t0.128000 (seconds)\n",
            "\tSampling time over 149 tokens:\t4.347000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 34, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876580191, \"token_encode_end_ms\": 1747876580192, \"model_execution_start_ms\": 1747876581678, \"model_execution_end_ms\": 1747876581727, \"inference_end_ms\": 1747876581727, \"prompt_eval_end_ms\": 1747876580240, \"first_token_ms\": 1747876580287, \"aggregate_sampling_time_ms\": 1524, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 34 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.536000 (seconds)\t\t Rate: \t18.880208 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.049000 (seconds)\t\t Rate: \t693.877551 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.487000 (seconds)\t\t Rate: \t19.502354 (tokens/second)\n",
            "\tTime to first generated token:\t0.096000 (seconds)\n",
            "\tSampling time over 63 tokens:\t1.524000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 47, \"generated_tokens\": 35, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876581740, \"token_encode_end_ms\": 1747876581741, \"model_execution_start_ms\": 1747876583537, \"model_execution_end_ms\": 1747876583587, \"inference_end_ms\": 1747876583587, \"prompt_eval_end_ms\": 1747876581798, \"first_token_ms\": 1747876581847, \"aggregate_sampling_time_ms\": 1836, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 47 Generated Tokens: 35\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.847000 (seconds)\t\t Rate: \t18.949648 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t810.344828 (tokens/second)\n",
            "\t\tGenerated 35 tokens:\t1.789000 (seconds)\t\t Rate: \t19.564002 (tokens/second)\n",
            "\tTime to first generated token:\t0.107000 (seconds)\n",
            "\tSampling time over 82 tokens:\t1.836000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876583598, \"token_encode_end_ms\": 1747876583599, \"model_execution_start_ms\": 1747876584404, \"model_execution_end_ms\": 1747876584452, \"inference_end_ms\": 1747876584452, \"prompt_eval_end_ms\": 1747876583664, \"first_token_ms\": 1747876583715, \"aggregate_sampling_time_ms\": 846, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.854000 (seconds)\t\t Rate: \t18.735363 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.066000 (seconds)\t\t Rate: \t409.090909 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.788000 (seconds)\t\t Rate: \t20.304569 (tokens/second)\n",
            "\tTime to first generated token:\t0.117000 (seconds)\n",
            "\tSampling time over 43 tokens:\t0.846000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876584464, \"token_encode_end_ms\": 1747876584465, \"model_execution_start_ms\": 1747876585628, \"model_execution_end_ms\": 1747876585678, \"inference_end_ms\": 1747876585679, \"prompt_eval_end_ms\": 1747876584509, \"first_token_ms\": 1747876584558, \"aggregate_sampling_time_ms\": 1206, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.215000 (seconds)\t\t Rate: \t18.930041 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.045000 (seconds)\t\t Rate: \t688.888889 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.170000 (seconds)\t\t Rate: \t19.658120 (tokens/second)\n",
            "\tTime to first generated token:\t0.094000 (seconds)\n",
            "\tSampling time over 54 tokens:\t1.206000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 28, \"generated_tokens\": 26, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876585691, \"token_encode_end_ms\": 1747876585692, \"model_execution_start_ms\": 1747876588476, \"model_execution_end_ms\": 1747876588523, \"inference_end_ms\": 1747876588524, \"prompt_eval_end_ms\": 1747876585754, \"first_token_ms\": 1747876585840, \"aggregate_sampling_time_ms\": 2820, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 28 Generated Tokens: 26\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.833000 (seconds)\t\t Rate: \t9.177550 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.063000 (seconds)\t\t Rate: \t444.444444 (tokens/second)\n",
            "\t\tGenerated 26 tokens:\t2.770000 (seconds)\t\t Rate: \t9.386282 (tokens/second)\n",
            "\tTime to first generated token:\t0.149000 (seconds)\n",
            "\tSampling time over 54 tokens:\t2.820000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 13, \"generated_tokens\": 12, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876588529, \"token_encode_end_ms\": 1747876588529, \"model_execution_start_ms\": 1747876589124, \"model_execution_end_ms\": 1747876589172, \"inference_end_ms\": 1747876589173, \"prompt_eval_end_ms\": 1747876588562, \"first_token_ms\": 1747876588608, \"aggregate_sampling_time_ms\": 641, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 13 Generated Tokens: 12\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.644000 (seconds)\t\t Rate: \t18.633540 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.033000 (seconds)\t\t Rate: \t393.939394 (tokens/second)\n",
            "\t\tGenerated 12 tokens:\t0.611000 (seconds)\t\t Rate: \t19.639935 (tokens/second)\n",
            "\tTime to first generated token:\t0.079000 (seconds)\n",
            "\tSampling time over 25 tokens:\t0.641000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876589176, \"token_encode_end_ms\": 1747876589176, \"model_execution_start_ms\": 1747876590352, \"model_execution_end_ms\": 1747876590403, \"inference_end_ms\": 1747876590403, \"prompt_eval_end_ms\": 1747876589234, \"first_token_ms\": 1747876589283, \"aggregate_sampling_time_ms\": 1220, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.227000 (seconds)\t\t Rate: \t18.744906 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t534.482759 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.169000 (seconds)\t\t Rate: \t19.674936 (tokens/second)\n",
            "\tTime to first generated token:\t0.107000 (seconds)\n",
            "\tSampling time over 54 tokens:\t1.220000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 41, \"generated_tokens\": 38, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876590408, \"token_encode_end_ms\": 1747876590408, \"model_execution_start_ms\": 1747876592393, \"model_execution_end_ms\": 1747876592443, \"inference_end_ms\": 1747876592443, \"prompt_eval_end_ms\": 1747876590467, \"first_token_ms\": 1747876590515, \"aggregate_sampling_time_ms\": 2016, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 41 Generated Tokens: 38\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.035000 (seconds)\t\t Rate: \t18.673219 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.059000 (seconds)\t\t Rate: \t694.915254 (tokens/second)\n",
            "\t\tGenerated 38 tokens:\t1.976000 (seconds)\t\t Rate: \t19.230769 (tokens/second)\n",
            "\tTime to first generated token:\t0.107000 (seconds)\n",
            "\tSampling time over 79 tokens:\t2.016000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 22, \"generated_tokens\": 17, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876592452, \"token_encode_end_ms\": 1747876592452, \"model_execution_start_ms\": 1747876593297, \"model_execution_end_ms\": 1747876593344, \"inference_end_ms\": 1747876593344, \"prompt_eval_end_ms\": 1747876592492, \"first_token_ms\": 1747876592539, \"aggregate_sampling_time_ms\": 888, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 22 Generated Tokens: 17\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.892000 (seconds)\t\t Rate: \t19.058296 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.040000 (seconds)\t\t Rate: \t550.000000 (tokens/second)\n",
            "\t\tGenerated 17 tokens:\t0.852000 (seconds)\t\t Rate: \t19.953052 (tokens/second)\n",
            "\tTime to first generated token:\t0.087000 (seconds)\n",
            "\tSampling time over 39 tokens:\t0.888000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 32, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876593356, \"token_encode_end_ms\": 1747876593357, \"model_execution_start_ms\": 1747876594956, \"model_execution_end_ms\": 1747876595005, \"inference_end_ms\": 1747876595005, \"prompt_eval_end_ms\": 1747876593399, \"first_token_ms\": 1747876593449, \"aggregate_sampling_time_ms\": 1639, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 32\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.649000 (seconds)\t\t Rate: \t19.405700 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t744.186047 (tokens/second)\n",
            "\t\tGenerated 32 tokens:\t1.606000 (seconds)\t\t Rate: \t19.925280 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 64 tokens:\t1.639000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 41, \"generated_tokens\": 37, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876595020, \"token_encode_end_ms\": 1747876595021, \"model_execution_start_ms\": 1747876596932, \"model_execution_end_ms\": 1747876596985, \"inference_end_ms\": 1747876596985, \"prompt_eval_end_ms\": 1747876595091, \"first_token_ms\": 1747876595140, \"aggregate_sampling_time_ms\": 1955, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 41 Generated Tokens: 37\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.965000 (seconds)\t\t Rate: \t18.829517 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.071000 (seconds)\t\t Rate: \t577.464789 (tokens/second)\n",
            "\t\tGenerated 37 tokens:\t1.894000 (seconds)\t\t Rate: \t19.535375 (tokens/second)\n",
            "\tTime to first generated token:\t0.120000 (seconds)\n",
            "\tSampling time over 78 tokens:\t1.955000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 64, \"generated_tokens\": 53, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876596999, \"token_encode_end_ms\": 1747876597000, \"model_execution_start_ms\": 1747876601327, \"model_execution_end_ms\": 1747876601378, \"inference_end_ms\": 1747876601378, \"prompt_eval_end_ms\": 1747876597066, \"first_token_ms\": 1747876597122, \"aggregate_sampling_time_ms\": 4364, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 64 Generated Tokens: 53\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t4.379000 (seconds)\t\t Rate: \t12.103220 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.067000 (seconds)\t\t Rate: \t955.223881 (tokens/second)\n",
            "\t\tGenerated 53 tokens:\t4.312000 (seconds)\t\t Rate: \t12.291280 (tokens/second)\n",
            "\tTime to first generated token:\t0.123000 (seconds)\n",
            "\tSampling time over 117 tokens:\t4.364000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 46, \"generated_tokens\": 41, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876601393, \"token_encode_end_ms\": 1747876601394, \"model_execution_start_ms\": 1747876603552, \"model_execution_end_ms\": 1747876603601, \"inference_end_ms\": 1747876603602, \"prompt_eval_end_ms\": 1747876601454, \"first_token_ms\": 1747876601504, \"aggregate_sampling_time_ms\": 2196, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 46 Generated Tokens: 41\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.209000 (seconds)\t\t Rate: \t18.560435 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t754.098361 (tokens/second)\n",
            "\t\tGenerated 41 tokens:\t2.148000 (seconds)\t\t Rate: \t19.087523 (tokens/second)\n",
            "\tTime to first generated token:\t0.111000 (seconds)\n",
            "\tSampling time over 87 tokens:\t2.196000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 71, \"generated_tokens\": 65, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876603616, \"token_encode_end_ms\": 1747876603617, \"model_execution_start_ms\": 1747876607188, \"model_execution_end_ms\": 1747876607241, \"inference_end_ms\": 1747876607241, \"prompt_eval_end_ms\": 1747876603695, \"first_token_ms\": 1747876603747, \"aggregate_sampling_time_ms\": 3610, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 71 Generated Tokens: 65\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.625000 (seconds)\t\t Rate: \t17.931034 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.079000 (seconds)\t\t Rate: \t898.734177 (tokens/second)\n",
            "\t\tGenerated 65 tokens:\t3.546000 (seconds)\t\t Rate: \t18.330513 (tokens/second)\n",
            "\tTime to first generated token:\t0.131000 (seconds)\n",
            "\tSampling time over 136 tokens:\t3.610000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876607250, \"token_encode_end_ms\": 1747876607251, \"model_execution_start_ms\": 1747876608347, \"model_execution_end_ms\": 1747876608396, \"inference_end_ms\": 1747876608396, \"prompt_eval_end_ms\": 1747876607298, \"first_token_ms\": 1747876607345, \"aggregate_sampling_time_ms\": 1135, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.146000 (seconds)\t\t Rate: \t19.197208 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.048000 (seconds)\t\t Rate: \t604.166667 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.098000 (seconds)\t\t Rate: \t20.036430 (tokens/second)\n",
            "\tTime to first generated token:\t0.095000 (seconds)\n",
            "\tSampling time over 51 tokens:\t1.135000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876608410, \"token_encode_end_ms\": 1747876608410, \"model_execution_start_ms\": 1747876609546, \"model_execution_end_ms\": 1747876609609, \"inference_end_ms\": 1747876609610, \"prompt_eval_end_ms\": 1747876608455, \"first_token_ms\": 1747876608504, \"aggregate_sampling_time_ms\": 1192, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.200000 (seconds)\t\t Rate: \t19.166667 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.045000 (seconds)\t\t Rate: \t733.333333 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.155000 (seconds)\t\t Rate: \t19.913420 (tokens/second)\n",
            "\tTime to first generated token:\t0.094000 (seconds)\n",
            "\tSampling time over 56 tokens:\t1.192000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 28, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876609616, \"token_encode_end_ms\": 1747876609617, \"model_execution_start_ms\": 1747876611165, \"model_execution_end_ms\": 1747876611250, \"inference_end_ms\": 1747876611250, \"prompt_eval_end_ms\": 1747876609664, \"first_token_ms\": 1747876609714, \"aggregate_sampling_time_ms\": 1631, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 28 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.634000 (seconds)\t\t Rate: \t13.463892 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.048000 (seconds)\t\t Rate: \t583.333333 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.586000 (seconds)\t\t Rate: \t13.871375 (tokens/second)\n",
            "\tTime to first generated token:\t0.098000 (seconds)\n",
            "\tSampling time over 50 tokens:\t1.631000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 47, \"generated_tokens\": 45, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876611261, \"token_encode_end_ms\": 1747876611262, \"model_execution_start_ms\": 1747876614544, \"model_execution_end_ms\": 1747876614595, \"inference_end_ms\": 1747876614595, \"prompt_eval_end_ms\": 1747876611352, \"first_token_ms\": 1747876611475, \"aggregate_sampling_time_ms\": 3314, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 47 Generated Tokens: 45\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.334000 (seconds)\t\t Rate: \t13.497301 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.091000 (seconds)\t\t Rate: \t516.483516 (tokens/second)\n",
            "\t\tGenerated 45 tokens:\t3.243000 (seconds)\t\t Rate: \t13.876041 (tokens/second)\n",
            "\tTime to first generated token:\t0.214000 (seconds)\n",
            "\tSampling time over 92 tokens:\t3.314000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 22, \"generated_tokens\": 21, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876614608, \"token_encode_end_ms\": 1747876614609, \"model_execution_start_ms\": 1747876615635, \"model_execution_end_ms\": 1747876615684, \"inference_end_ms\": 1747876615684, \"prompt_eval_end_ms\": 1747876614658, \"first_token_ms\": 1747876614708, \"aggregate_sampling_time_ms\": 1067, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 22 Generated Tokens: 21\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.076000 (seconds)\t\t Rate: \t19.516729 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.050000 (seconds)\t\t Rate: \t440.000000 (tokens/second)\n",
            "\t\tGenerated 21 tokens:\t1.026000 (seconds)\t\t Rate: \t20.467836 (tokens/second)\n",
            "\tTime to first generated token:\t0.100000 (seconds)\n",
            "\tSampling time over 43 tokens:\t1.067000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 42, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876615691, \"token_encode_end_ms\": 1747876615692, \"model_execution_start_ms\": 1747876617747, \"model_execution_end_ms\": 1747876617796, \"inference_end_ms\": 1747876617796, \"prompt_eval_end_ms\": 1747876615747, \"first_token_ms\": 1747876615795, \"aggregate_sampling_time_ms\": 2090, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 42 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.105000 (seconds)\t\t Rate: \t18.527316 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.056000 (seconds)\t\t Rate: \t750.000000 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t2.049000 (seconds)\t\t Rate: \t19.033675 (tokens/second)\n",
            "\tTime to first generated token:\t0.104000 (seconds)\n",
            "\tSampling time over 81 tokens:\t2.090000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 26, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876617810, \"token_encode_end_ms\": 1747876617811, \"model_execution_start_ms\": 1747876618971, \"model_execution_end_ms\": 1747876619018, \"inference_end_ms\": 1747876619019, \"prompt_eval_end_ms\": 1747876617852, \"first_token_ms\": 1747876617918, \"aggregate_sampling_time_ms\": 1201, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 26 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.209000 (seconds)\t\t Rate: \t19.023987 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.042000 (seconds)\t\t Rate: \t619.047619 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.167000 (seconds)\t\t Rate: \t19.708655 (tokens/second)\n",
            "\tTime to first generated token:\t0.108000 (seconds)\n",
            "\tSampling time over 49 tokens:\t1.201000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 56, \"generated_tokens\": 40, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876619031, \"token_encode_end_ms\": 1747876619032, \"model_execution_start_ms\": 1747876621169, \"model_execution_end_ms\": 1747876621219, \"inference_end_ms\": 1747876621219, \"prompt_eval_end_ms\": 1747876619092, \"first_token_ms\": 1747876619143, \"aggregate_sampling_time_ms\": 2176, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 56 Generated Tokens: 40\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.188000 (seconds)\t\t Rate: \t18.281536 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t918.032787 (tokens/second)\n",
            "\t\tGenerated 40 tokens:\t2.127000 (seconds)\t\t Rate: \t18.805830 (tokens/second)\n",
            "\tTime to first generated token:\t0.112000 (seconds)\n",
            "\tSampling time over 96 tokens:\t2.176000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 19, \"generated_tokens\": 9, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876621233, \"token_encode_end_ms\": 1747876621233, \"model_execution_start_ms\": 1747876621668, \"model_execution_end_ms\": 1747876621721, \"inference_end_ms\": 1747876621721, \"prompt_eval_end_ms\": 1747876621264, \"first_token_ms\": 1747876621311, \"aggregate_sampling_time_ms\": 488, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 19 Generated Tokens: 9\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.488000 (seconds)\t\t Rate: \t18.442623 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.031000 (seconds)\t\t Rate: \t612.903226 (tokens/second)\n",
            "\t\tGenerated 9 tokens:\t0.457000 (seconds)\t\t Rate: \t19.693654 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 28 tokens:\t0.488000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 38, \"generated_tokens\": 36, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876621727, \"token_encode_end_ms\": 1747876621728, \"model_execution_start_ms\": 1747876625083, \"model_execution_end_ms\": 1747876625137, \"inference_end_ms\": 1747876625138, \"prompt_eval_end_ms\": 1747876621780, \"first_token_ms\": 1747876621828, \"aggregate_sampling_time_ms\": 3397, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 38 Generated Tokens: 36\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.411000 (seconds)\t\t Rate: \t10.554090 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t716.981132 (tokens/second)\n",
            "\t\tGenerated 36 tokens:\t3.358000 (seconds)\t\t Rate: \t10.720667 (tokens/second)\n",
            "\tTime to first generated token:\t0.101000 (seconds)\n",
            "\tSampling time over 74 tokens:\t3.397000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 35, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876625149, \"token_encode_end_ms\": 1747876625149, \"model_execution_start_ms\": 1747876626375, \"model_execution_end_ms\": 1747876626423, \"inference_end_ms\": 1747876626424, \"prompt_eval_end_ms\": 1747876625208, \"first_token_ms\": 1747876625257, \"aggregate_sampling_time_ms\": 1268, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 35 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.275000 (seconds)\t\t Rate: \t18.823529 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.059000 (seconds)\t\t Rate: \t593.220339 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.216000 (seconds)\t\t Rate: \t19.736842 (tokens/second)\n",
            "\tTime to first generated token:\t0.108000 (seconds)\n",
            "\tSampling time over 59 tokens:\t1.268000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 9, \"generated_tokens\": 7, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876626436, \"token_encode_end_ms\": 1747876626437, \"model_execution_start_ms\": 1747876626758, \"model_execution_end_ms\": 1747876626804, \"inference_end_ms\": 1747876626805, \"prompt_eval_end_ms\": 1747876626459, \"first_token_ms\": 1747876626505, \"aggregate_sampling_time_ms\": 367, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 9 Generated Tokens: 7\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.369000 (seconds)\t\t Rate: \t18.970190 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.023000 (seconds)\t\t Rate: \t391.304348 (tokens/second)\n",
            "\t\tGenerated 7 tokens:\t0.346000 (seconds)\t\t Rate: \t20.231214 (tokens/second)\n",
            "\tTime to first generated token:\t0.069000 (seconds)\n",
            "\tSampling time over 16 tokens:\t0.367000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 38, \"generated_tokens\": 21, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876626815, \"token_encode_end_ms\": 1747876626816, \"model_execution_start_ms\": 1747876627889, \"model_execution_end_ms\": 1747876627938, \"inference_end_ms\": 1747876627938, \"prompt_eval_end_ms\": 1747876626865, \"first_token_ms\": 1747876626914, \"aggregate_sampling_time_ms\": 1113, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 38 Generated Tokens: 21\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.123000 (seconds)\t\t Rate: \t18.699911 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.050000 (seconds)\t\t Rate: \t760.000000 (tokens/second)\n",
            "\t\tGenerated 21 tokens:\t1.073000 (seconds)\t\t Rate: \t19.571295 (tokens/second)\n",
            "\tTime to first generated token:\t0.099000 (seconds)\n",
            "\tSampling time over 59 tokens:\t1.113000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 21, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876627950, \"token_encode_end_ms\": 1747876627951, \"model_execution_start_ms\": 1747876628999, \"model_execution_end_ms\": 1747876629047, \"inference_end_ms\": 1747876629047, \"prompt_eval_end_ms\": 1747876627991, \"first_token_ms\": 1747876628038, \"aggregate_sampling_time_ms\": 1090, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 21\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.097000 (seconds)\t\t Rate: \t19.143118 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.041000 (seconds)\t\t Rate: \t658.536585 (tokens/second)\n",
            "\t\tGenerated 21 tokens:\t1.056000 (seconds)\t\t Rate: \t19.886364 (tokens/second)\n",
            "\tTime to first generated token:\t0.088000 (seconds)\n",
            "\tSampling time over 48 tokens:\t1.090000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 51, \"generated_tokens\": 54, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876629054, \"token_encode_end_ms\": 1747876629055, \"model_execution_start_ms\": 1747876631914, \"model_execution_end_ms\": 1747876631963, \"inference_end_ms\": 1747876631964, \"prompt_eval_end_ms\": 1747876629131, \"first_token_ms\": 1747876629182, \"aggregate_sampling_time_ms\": 2899, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 51 Generated Tokens: 54\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.910000 (seconds)\t\t Rate: \t18.556701 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.077000 (seconds)\t\t Rate: \t662.337662 (tokens/second)\n",
            "\t\tGenerated 54 tokens:\t2.833000 (seconds)\t\t Rate: \t19.061066 (tokens/second)\n",
            "\tTime to first generated token:\t0.128000 (seconds)\n",
            "\tSampling time over 105 tokens:\t2.899000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876631973, \"token_encode_end_ms\": 1747876631973, \"model_execution_start_ms\": 1747876633144, \"model_execution_end_ms\": 1747876633193, \"inference_end_ms\": 1747876633194, \"prompt_eval_end_ms\": 1747876632022, \"first_token_ms\": 1747876632071, \"aggregate_sampling_time_ms\": 1216, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.221000 (seconds)\t\t Rate: \t18.837019 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.049000 (seconds)\t\t Rate: \t673.469388 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.172000 (seconds)\t\t Rate: \t19.624573 (tokens/second)\n",
            "\tTime to first generated token:\t0.098000 (seconds)\n",
            "\tSampling time over 56 tokens:\t1.216000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 12, \"generated_tokens\": 7, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876633207, \"token_encode_end_ms\": 1747876633207, \"model_execution_start_ms\": 1747876633544, \"model_execution_end_ms\": 1747876633592, \"inference_end_ms\": 1747876633592, \"prompt_eval_end_ms\": 1747876633232, \"first_token_ms\": 1747876633279, \"aggregate_sampling_time_ms\": 383, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 12 Generated Tokens: 7\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.385000 (seconds)\t\t Rate: \t18.181818 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.025000 (seconds)\t\t Rate: \t480.000000 (tokens/second)\n",
            "\t\tGenerated 7 tokens:\t0.360000 (seconds)\t\t Rate: \t19.444444 (tokens/second)\n",
            "\tTime to first generated token:\t0.072000 (seconds)\n",
            "\tSampling time over 19 tokens:\t0.383000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 36, \"generated_tokens\": 34, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876633602, \"token_encode_end_ms\": 1747876633602, \"model_execution_start_ms\": 1747876635983, \"model_execution_end_ms\": 1747876636093, \"inference_end_ms\": 1747876636093, \"prompt_eval_end_ms\": 1747876633655, \"first_token_ms\": 1747876633704, \"aggregate_sampling_time_ms\": 2475, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 36 Generated Tokens: 34\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.491000 (seconds)\t\t Rate: \t13.649137 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t679.245283 (tokens/second)\n",
            "\t\tGenerated 34 tokens:\t2.438000 (seconds)\t\t Rate: \t13.945857 (tokens/second)\n",
            "\tTime to first generated token:\t0.102000 (seconds)\n",
            "\tSampling time over 70 tokens:\t2.475000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 9, \"generated_tokens\": 5, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876636098, \"token_encode_end_ms\": 1747876636102, \"model_execution_start_ms\": 1747876636989, \"model_execution_end_ms\": 1747876637097, \"inference_end_ms\": 1747876637097, \"prompt_eval_end_ms\": 1747876636143, \"first_token_ms\": 1747876636254, \"aggregate_sampling_time_ms\": 994, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 9 Generated Tokens: 5\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.999000 (seconds)\t\t Rate: \t5.005005 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.045000 (seconds)\t\t Rate: \t200.000000 (tokens/second)\n",
            "\t\tGenerated 5 tokens:\t0.954000 (seconds)\t\t Rate: \t5.241090 (tokens/second)\n",
            "\tTime to first generated token:\t0.156000 (seconds)\n",
            "\tSampling time over 14 tokens:\t0.994000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 40, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876637107, \"token_encode_end_ms\": 1747876637107, \"model_execution_start_ms\": 1747876639156, \"model_execution_end_ms\": 1747876639205, \"inference_end_ms\": 1747876639205, \"prompt_eval_end_ms\": 1747876637199, \"first_token_ms\": 1747876637267, \"aggregate_sampling_time_ms\": 2085, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 40 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.098000 (seconds)\t\t Rate: \t18.589133 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.092000 (seconds)\t\t Rate: \t434.782609 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t2.006000 (seconds)\t\t Rate: \t19.441675 (tokens/second)\n",
            "\tTime to first generated token:\t0.160000 (seconds)\n",
            "\tSampling time over 79 tokens:\t2.085000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 17, \"generated_tokens\": 12, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876639213, \"token_encode_end_ms\": 1747876639213, \"model_execution_start_ms\": 1747876639818, \"model_execution_end_ms\": 1747876639865, \"inference_end_ms\": 1747876639865, \"prompt_eval_end_ms\": 1747876639252, \"first_token_ms\": 1747876639299, \"aggregate_sampling_time_ms\": 646, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 17 Generated Tokens: 12\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.652000 (seconds)\t\t Rate: \t18.404908 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.039000 (seconds)\t\t Rate: \t435.897436 (tokens/second)\n",
            "\t\tGenerated 12 tokens:\t0.613000 (seconds)\t\t Rate: \t19.575856 (tokens/second)\n",
            "\tTime to first generated token:\t0.086000 (seconds)\n",
            "\tSampling time over 29 tokens:\t0.646000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876639874, \"token_encode_end_ms\": 1747876639875, \"model_execution_start_ms\": 1747876641083, \"model_execution_end_ms\": 1747876641132, \"inference_end_ms\": 1747876641132, \"prompt_eval_end_ms\": 1747876639921, \"first_token_ms\": 1747876639968, \"aggregate_sampling_time_ms\": 1251, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.258000 (seconds)\t\t Rate: \t19.077901 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.047000 (seconds)\t\t Rate: \t680.851064 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.211000 (seconds)\t\t Rate: \t19.818332 (tokens/second)\n",
            "\tTime to first generated token:\t0.094000 (seconds)\n",
            "\tSampling time over 56 tokens:\t1.251000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 39, \"generated_tokens\": 32, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876641138, \"token_encode_end_ms\": 1747876641139, \"model_execution_start_ms\": 1747876642759, \"model_execution_end_ms\": 1747876642827, \"inference_end_ms\": 1747876642827, \"prompt_eval_end_ms\": 1747876641192, \"first_token_ms\": 1747876641242, \"aggregate_sampling_time_ms\": 1678, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 39 Generated Tokens: 32\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.689000 (seconds)\t\t Rate: \t18.946122 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.054000 (seconds)\t\t Rate: \t722.222222 (tokens/second)\n",
            "\t\tGenerated 32 tokens:\t1.635000 (seconds)\t\t Rate: \t19.571865 (tokens/second)\n",
            "\tTime to first generated token:\t0.104000 (seconds)\n",
            "\tSampling time over 71 tokens:\t1.678000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 18, \"generated_tokens\": 9, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876642839, \"token_encode_end_ms\": 1747876642840, \"model_execution_start_ms\": 1747876643264, \"model_execution_end_ms\": 1747876643312, \"inference_end_ms\": 1747876643312, \"prompt_eval_end_ms\": 1747876642871, \"first_token_ms\": 1747876642917, \"aggregate_sampling_time_ms\": 470, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 18 Generated Tokens: 9\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.473000 (seconds)\t\t Rate: \t19.027484 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.032000 (seconds)\t\t Rate: \t562.500000 (tokens/second)\n",
            "\t\tGenerated 9 tokens:\t0.441000 (seconds)\t\t Rate: \t20.408163 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 27 tokens:\t0.470000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 26, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876643317, \"token_encode_end_ms\": 1747876643318, \"model_execution_start_ms\": 1747876644617, \"model_execution_end_ms\": 1747876644665, \"inference_end_ms\": 1747876644665, \"prompt_eval_end_ms\": 1747876643365, \"first_token_ms\": 1747876643413, \"aggregate_sampling_time_ms\": 1336, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 26\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.348000 (seconds)\t\t Rate: \t19.287834 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.048000 (seconds)\t\t Rate: \t625.000000 (tokens/second)\n",
            "\t\tGenerated 26 tokens:\t1.300000 (seconds)\t\t Rate: \t20.000000 (tokens/second)\n",
            "\tTime to first generated token:\t0.096000 (seconds)\n",
            "\tSampling time over 56 tokens:\t1.336000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 16, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876644676, \"token_encode_end_ms\": 1747876644677, \"model_execution_start_ms\": 1747876645460, \"model_execution_end_ms\": 1747876645507, \"inference_end_ms\": 1747876645508, \"prompt_eval_end_ms\": 1747876644709, \"first_token_ms\": 1747876644756, \"aggregate_sampling_time_ms\": 827, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 16 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.832000 (seconds)\t\t Rate: \t19.230769 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.033000 (seconds)\t\t Rate: \t484.848485 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.799000 (seconds)\t\t Rate: \t20.025031 (tokens/second)\n",
            "\tTime to first generated token:\t0.080000 (seconds)\n",
            "\tSampling time over 32 tokens:\t0.827000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 41, \"generated_tokens\": 32, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876645521, \"token_encode_end_ms\": 1747876645521, \"model_execution_start_ms\": 1747876647244, \"model_execution_end_ms\": 1747876647350, \"inference_end_ms\": 1747876647351, \"prompt_eval_end_ms\": 1747876645574, \"first_token_ms\": 1747876645626, \"aggregate_sampling_time_ms\": 1819, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 41 Generated Tokens: 32\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.830000 (seconds)\t\t Rate: \t17.486339 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t773.584906 (tokens/second)\n",
            "\t\tGenerated 32 tokens:\t1.777000 (seconds)\t\t Rate: \t18.007878 (tokens/second)\n",
            "\tTime to first generated token:\t0.105000 (seconds)\n",
            "\tSampling time over 73 tokens:\t1.819000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 26, \"generated_tokens\": 17, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876647367, \"token_encode_end_ms\": 1747876647370, \"model_execution_start_ms\": 1747876649646, \"model_execution_end_ms\": 1747876649696, \"inference_end_ms\": 1747876649697, \"prompt_eval_end_ms\": 1747876647454, \"first_token_ms\": 1747876647573, \"aggregate_sampling_time_ms\": 2313, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 26 Generated Tokens: 17\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.330000 (seconds)\t\t Rate: \t7.296137 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.087000 (seconds)\t\t Rate: \t298.850575 (tokens/second)\n",
            "\t\tGenerated 17 tokens:\t2.243000 (seconds)\t\t Rate: \t7.579135 (tokens/second)\n",
            "\tTime to first generated token:\t0.206000 (seconds)\n",
            "\tSampling time over 43 tokens:\t2.313000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 18, \"generated_tokens\": 13, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876649708, \"token_encode_end_ms\": 1747876649708, \"model_execution_start_ms\": 1747876650354, \"model_execution_end_ms\": 1747876650401, \"inference_end_ms\": 1747876650401, \"prompt_eval_end_ms\": 1747876649743, \"first_token_ms\": 1747876649791, \"aggregate_sampling_time_ms\": 689, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 18 Generated Tokens: 13\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.693000 (seconds)\t\t Rate: \t18.759019 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.035000 (seconds)\t\t Rate: \t514.285714 (tokens/second)\n",
            "\t\tGenerated 13 tokens:\t0.658000 (seconds)\t\t Rate: \t19.756839 (tokens/second)\n",
            "\tTime to first generated token:\t0.083000 (seconds)\n",
            "\tSampling time over 31 tokens:\t0.689000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 36, \"generated_tokens\": 33, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876650413, \"token_encode_end_ms\": 1747876650414, \"model_execution_start_ms\": 1747876652087, \"model_execution_end_ms\": 1747876652152, \"inference_end_ms\": 1747876652153, \"prompt_eval_end_ms\": 1747876650463, \"first_token_ms\": 1747876650512, \"aggregate_sampling_time_ms\": 1733, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 36 Generated Tokens: 33\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.740000 (seconds)\t\t Rate: \t18.965517 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.050000 (seconds)\t\t Rate: \t720.000000 (tokens/second)\n",
            "\t\tGenerated 33 tokens:\t1.690000 (seconds)\t\t Rate: \t19.526627 (tokens/second)\n",
            "\tTime to first generated token:\t0.099000 (seconds)\n",
            "\tSampling time over 69 tokens:\t1.733000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 28, \"generated_tokens\": 18, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876652166, \"token_encode_end_ms\": 1747876652166, \"model_execution_start_ms\": 1747876653047, \"model_execution_end_ms\": 1747876653095, \"inference_end_ms\": 1747876653095, \"prompt_eval_end_ms\": 1747876652205, \"first_token_ms\": 1747876652253, \"aggregate_sampling_time_ms\": 921, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 28 Generated Tokens: 18\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.929000 (seconds)\t\t Rate: \t19.375673 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.039000 (seconds)\t\t Rate: \t717.948718 (tokens/second)\n",
            "\t\tGenerated 18 tokens:\t0.890000 (seconds)\t\t Rate: \t20.224719 (tokens/second)\n",
            "\tTime to first generated token:\t0.087000 (seconds)\n",
            "\tSampling time over 46 tokens:\t0.921000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 24, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876653098, \"token_encode_end_ms\": 1747876653099, \"model_execution_start_ms\": 1747876654200, \"model_execution_end_ms\": 1747876654258, \"inference_end_ms\": 1747876654258, \"prompt_eval_end_ms\": 1747876653125, \"first_token_ms\": 1747876653192, \"aggregate_sampling_time_ms\": 1145, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 24 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.160000 (seconds)\t\t Rate: \t18.965517 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.027000 (seconds)\t\t Rate: \t888.888889 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.133000 (seconds)\t\t Rate: \t19.417476 (tokens/second)\n",
            "\tTime to first generated token:\t0.094000 (seconds)\n",
            "\tSampling time over 46 tokens:\t1.145000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 28, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876654265, \"token_encode_end_ms\": 1747876654265, \"model_execution_start_ms\": 1747876655454, \"model_execution_end_ms\": 1747876655504, \"inference_end_ms\": 1747876655505, \"prompt_eval_end_ms\": 1747876654312, \"first_token_ms\": 1747876654359, \"aggregate_sampling_time_ms\": 1231, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 28 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.240000 (seconds)\t\t Rate: \t19.354839 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.047000 (seconds)\t\t Rate: \t595.744681 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.193000 (seconds)\t\t Rate: \t20.117351 (tokens/second)\n",
            "\tTime to first generated token:\t0.094000 (seconds)\n",
            "\tSampling time over 52 tokens:\t1.231000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 28, \"generated_tokens\": 21, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876655510, \"token_encode_end_ms\": 1747876655511, \"model_execution_start_ms\": 1747876656588, \"model_execution_end_ms\": 1747876656635, \"inference_end_ms\": 1747876656636, \"prompt_eval_end_ms\": 1747876655560, \"first_token_ms\": 1747876655611, \"aggregate_sampling_time_ms\": 1121, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 28 Generated Tokens: 21\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.126000 (seconds)\t\t Rate: \t18.650089 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.050000 (seconds)\t\t Rate: \t560.000000 (tokens/second)\n",
            "\t\tGenerated 21 tokens:\t1.076000 (seconds)\t\t Rate: \t19.516729 (tokens/second)\n",
            "\tTime to first generated token:\t0.101000 (seconds)\n",
            "\tSampling time over 49 tokens:\t1.121000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 44, \"generated_tokens\": 43, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876656650, \"token_encode_end_ms\": 1747876656650, \"model_execution_start_ms\": 1747876658863, \"model_execution_end_ms\": 1747876658912, \"inference_end_ms\": 1747876658912, \"prompt_eval_end_ms\": 1747876656703, \"first_token_ms\": 1747876656751, \"aggregate_sampling_time_ms\": 2254, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 44 Generated Tokens: 43\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.262000 (seconds)\t\t Rate: \t19.009726 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t830.188679 (tokens/second)\n",
            "\t\tGenerated 43 tokens:\t2.209000 (seconds)\t\t Rate: \t19.465822 (tokens/second)\n",
            "\tTime to first generated token:\t0.101000 (seconds)\n",
            "\tSampling time over 87 tokens:\t2.254000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 52, \"generated_tokens\": 50, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876658920, \"token_encode_end_ms\": 1747876658921, \"model_execution_start_ms\": 1747876663045, \"model_execution_end_ms\": 1747876663096, \"inference_end_ms\": 1747876663096, \"prompt_eval_end_ms\": 1747876658986, \"first_token_ms\": 1747876659036, \"aggregate_sampling_time_ms\": 4160, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 52 Generated Tokens: 50\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t4.176000 (seconds)\t\t Rate: \t11.973180 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.066000 (seconds)\t\t Rate: \t787.878788 (tokens/second)\n",
            "\t\tGenerated 50 tokens:\t4.110000 (seconds)\t\t Rate: \t12.165450 (tokens/second)\n",
            "\tTime to first generated token:\t0.116000 (seconds)\n",
            "\tSampling time over 102 tokens:\t4.160000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 64, \"generated_tokens\": 57, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876663112, \"token_encode_end_ms\": 1747876663113, \"model_execution_start_ms\": 1747876666224, \"model_execution_end_ms\": 1747876666276, \"inference_end_ms\": 1747876666277, \"prompt_eval_end_ms\": 1747876663179, \"first_token_ms\": 1747876663231, \"aggregate_sampling_time_ms\": 3148, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 64 Generated Tokens: 57\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.165000 (seconds)\t\t Rate: \t18.009479 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.067000 (seconds)\t\t Rate: \t955.223881 (tokens/second)\n",
            "\t\tGenerated 57 tokens:\t3.098000 (seconds)\t\t Rate: \t18.398967 (tokens/second)\n",
            "\tTime to first generated token:\t0.119000 (seconds)\n",
            "\tSampling time over 121 tokens:\t3.148000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 26, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876666287, \"token_encode_end_ms\": 1747876666287, \"model_execution_start_ms\": 1747876667574, \"model_execution_end_ms\": 1747876667624, \"inference_end_ms\": 1747876667624, \"prompt_eval_end_ms\": 1747876666335, \"first_token_ms\": 1747876666382, \"aggregate_sampling_time_ms\": 1330, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 26\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.337000 (seconds)\t\t Rate: \t19.446522 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.048000 (seconds)\t\t Rate: \t625.000000 (tokens/second)\n",
            "\t\tGenerated 26 tokens:\t1.289000 (seconds)\t\t Rate: \t20.170675 (tokens/second)\n",
            "\tTime to first generated token:\t0.095000 (seconds)\n",
            "\tSampling time over 56 tokens:\t1.330000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 37, \"generated_tokens\": 33, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876667631, \"token_encode_end_ms\": 1747876667632, \"model_execution_start_ms\": 1747876669350, \"model_execution_end_ms\": 1747876669398, \"inference_end_ms\": 1747876669399, \"prompt_eval_end_ms\": 1747876667712, \"first_token_ms\": 1747876667761, \"aggregate_sampling_time_ms\": 1761, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 37 Generated Tokens: 33\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.768000 (seconds)\t\t Rate: \t18.665158 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.081000 (seconds)\t\t Rate: \t456.790123 (tokens/second)\n",
            "\t\tGenerated 33 tokens:\t1.687000 (seconds)\t\t Rate: \t19.561352 (tokens/second)\n",
            "\tTime to first generated token:\t0.130000 (seconds)\n",
            "\tSampling time over 70 tokens:\t1.761000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 25, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876669405, \"token_encode_end_ms\": 1747876669406, \"model_execution_start_ms\": 1747876670694, \"model_execution_end_ms\": 1747876670745, \"inference_end_ms\": 1747876670745, \"prompt_eval_end_ms\": 1747876669456, \"first_token_ms\": 1747876669504, \"aggregate_sampling_time_ms\": 1336, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 25\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.340000 (seconds)\t\t Rate: \t18.656716 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.051000 (seconds)\t\t Rate: \t647.058824 (tokens/second)\n",
            "\t\tGenerated 25 tokens:\t1.289000 (seconds)\t\t Rate: \t19.394880 (tokens/second)\n",
            "\tTime to first generated token:\t0.099000 (seconds)\n",
            "\tSampling time over 58 tokens:\t1.336000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 26, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876670751, \"token_encode_end_ms\": 1747876670751, \"model_execution_start_ms\": 1747876672294, \"model_execution_end_ms\": 1747876672603, \"inference_end_ms\": 1747876672604, \"prompt_eval_end_ms\": 1747876670818, \"first_token_ms\": 1747876670866, \"aggregate_sampling_time_ms\": 1835, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 26\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.853000 (seconds)\t\t Rate: \t14.031301 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.067000 (seconds)\t\t Rate: \t447.761194 (tokens/second)\n",
            "\t\tGenerated 26 tokens:\t1.786000 (seconds)\t\t Rate: \t14.557671 (tokens/second)\n",
            "\tTime to first generated token:\t0.115000 (seconds)\n",
            "\tSampling time over 56 tokens:\t1.835000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 18, \"generated_tokens\": 7, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876672619, \"token_encode_end_ms\": 1747876672619, \"model_execution_start_ms\": 1747876673623, \"model_execution_end_ms\": 1747876673729, \"inference_end_ms\": 1747876673729, \"prompt_eval_end_ms\": 1747876672676, \"first_token_ms\": 1747876672782, \"aggregate_sampling_time_ms\": 1109, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 18 Generated Tokens: 7\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.110000 (seconds)\t\t Rate: \t6.306306 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.057000 (seconds)\t\t Rate: \t315.789474 (tokens/second)\n",
            "\t\tGenerated 7 tokens:\t1.053000 (seconds)\t\t Rate: \t6.647673 (tokens/second)\n",
            "\tTime to first generated token:\t0.163000 (seconds)\n",
            "\tSampling time over 25 tokens:\t1.109000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 15, \"generated_tokens\": 9, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876673735, \"token_encode_end_ms\": 1747876673735, \"model_execution_start_ms\": 1747876674394, \"model_execution_end_ms\": 1747876674440, \"inference_end_ms\": 1747876674441, \"prompt_eval_end_ms\": 1747876673776, \"first_token_ms\": 1747876673863, \"aggregate_sampling_time_ms\": 697, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 15 Generated Tokens: 9\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.706000 (seconds)\t\t Rate: \t12.747875 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.041000 (seconds)\t\t Rate: \t365.853659 (tokens/second)\n",
            "\t\tGenerated 9 tokens:\t0.665000 (seconds)\t\t Rate: \t13.533835 (tokens/second)\n",
            "\tTime to first generated token:\t0.128000 (seconds)\n",
            "\tSampling time over 24 tokens:\t0.697000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 46, \"generated_tokens\": 41, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876674451, \"token_encode_end_ms\": 1747876674452, \"model_execution_start_ms\": 1747876676588, \"model_execution_end_ms\": 1747876676639, \"inference_end_ms\": 1747876676639, \"prompt_eval_end_ms\": 1747876674509, \"first_token_ms\": 1747876674559, \"aggregate_sampling_time_ms\": 2178, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 46 Generated Tokens: 41\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.188000 (seconds)\t\t Rate: \t18.738574 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t793.103448 (tokens/second)\n",
            "\t\tGenerated 41 tokens:\t2.130000 (seconds)\t\t Rate: \t19.248826 (tokens/second)\n",
            "\tTime to first generated token:\t0.108000 (seconds)\n",
            "\tSampling time over 87 tokens:\t2.178000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 25, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876676646, \"token_encode_end_ms\": 1747876676647, \"model_execution_start_ms\": 1747876677785, \"model_execution_end_ms\": 1747876677834, \"inference_end_ms\": 1747876677834, \"prompt_eval_end_ms\": 1747876676694, \"first_token_ms\": 1747876676743, \"aggregate_sampling_time_ms\": 1179, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 25 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.188000 (seconds)\t\t Rate: \t18.518519 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.048000 (seconds)\t\t Rate: \t520.833333 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.140000 (seconds)\t\t Rate: \t19.298246 (tokens/second)\n",
            "\tTime to first generated token:\t0.097000 (seconds)\n",
            "\tSampling time over 47 tokens:\t1.179000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 45, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876677848, \"token_encode_end_ms\": 1747876677848, \"model_execution_start_ms\": 1747876679856, \"model_execution_end_ms\": 1747876679907, \"inference_end_ms\": 1747876679907, \"prompt_eval_end_ms\": 1747876677890, \"first_token_ms\": 1747876677939, \"aggregate_sampling_time_ms\": 2046, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 45 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.059000 (seconds)\t\t Rate: \t18.941234 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.042000 (seconds)\t\t Rate: \t1071.428571 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t2.017000 (seconds)\t\t Rate: \t19.335647 (tokens/second)\n",
            "\tTime to first generated token:\t0.091000 (seconds)\n",
            "\tSampling time over 84 tokens:\t2.046000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876679913, \"token_encode_end_ms\": 1747876679917, \"model_execution_start_ms\": 1747876681072, \"model_execution_end_ms\": 1747876681125, \"inference_end_ms\": 1747876681125, \"prompt_eval_end_ms\": 1747876679966, \"first_token_ms\": 1747876680015, \"aggregate_sampling_time_ms\": 1201, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.212000 (seconds)\t\t Rate: \t18.976898 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.053000 (seconds)\t\t Rate: \t584.905660 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.159000 (seconds)\t\t Rate: \t19.844694 (tokens/second)\n",
            "\tTime to first generated token:\t0.102000 (seconds)\n",
            "\tSampling time over 54 tokens:\t1.201000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 25, \"generated_tokens\": 14, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876681139, \"token_encode_end_ms\": 1747876681139, \"model_execution_start_ms\": 1747876681844, \"model_execution_end_ms\": 1747876681891, \"inference_end_ms\": 1747876681891, \"prompt_eval_end_ms\": 1747876681177, \"first_token_ms\": 1747876681244, \"aggregate_sampling_time_ms\": 749, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 25 Generated Tokens: 14\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.752000 (seconds)\t\t Rate: \t18.617021 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.038000 (seconds)\t\t Rate: \t657.894737 (tokens/second)\n",
            "\t\tGenerated 14 tokens:\t0.714000 (seconds)\t\t Rate: \t19.607843 (tokens/second)\n",
            "\tTime to first generated token:\t0.105000 (seconds)\n",
            "\tSampling time over 39 tokens:\t0.749000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 79, \"generated_tokens\": 80, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876681897, \"token_encode_end_ms\": 1747876681898, \"model_execution_start_ms\": 1747876687787, \"model_execution_end_ms\": 1747876687840, \"inference_end_ms\": 1747876687841, \"prompt_eval_end_ms\": 1747876681978, \"first_token_ms\": 1747876682030, \"aggregate_sampling_time_ms\": 5914, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 79 Generated Tokens: 80\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t5.944000 (seconds)\t\t Rate: \t13.458950 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.081000 (seconds)\t\t Rate: \t975.308642 (tokens/second)\n",
            "\t\tGenerated 80 tokens:\t5.863000 (seconds)\t\t Rate: \t13.644892 (tokens/second)\n",
            "\tTime to first generated token:\t0.133000 (seconds)\n",
            "\tSampling time over 159 tokens:\t5.914000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 21, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876687854, \"token_encode_end_ms\": 1747876687855, \"model_execution_start_ms\": 1747876688917, \"model_execution_end_ms\": 1747876688964, \"inference_end_ms\": 1747876688964, \"prompt_eval_end_ms\": 1747876687892, \"first_token_ms\": 1747876687948, \"aggregate_sampling_time_ms\": 1104, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 21\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.110000 (seconds)\t\t Rate: \t18.918919 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.038000 (seconds)\t\t Rate: \t710.526316 (tokens/second)\n",
            "\t\tGenerated 21 tokens:\t1.072000 (seconds)\t\t Rate: \t19.589552 (tokens/second)\n",
            "\tTime to first generated token:\t0.094000 (seconds)\n",
            "\tSampling time over 48 tokens:\t1.104000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 46, \"generated_tokens\": 38, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876688971, \"token_encode_end_ms\": 1747876688972, \"model_execution_start_ms\": 1747876690982, \"model_execution_end_ms\": 1747876691032, \"inference_end_ms\": 1747876691033, \"prompt_eval_end_ms\": 1747876689030, \"first_token_ms\": 1747876689079, \"aggregate_sampling_time_ms\": 2049, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 46 Generated Tokens: 38\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.062000 (seconds)\t\t Rate: \t18.428710 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.059000 (seconds)\t\t Rate: \t779.661017 (tokens/second)\n",
            "\t\tGenerated 38 tokens:\t2.003000 (seconds)\t\t Rate: \t18.971543 (tokens/second)\n",
            "\tTime to first generated token:\t0.108000 (seconds)\n",
            "\tSampling time over 84 tokens:\t2.049000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 18, \"generated_tokens\": 13, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876691040, \"token_encode_end_ms\": 1747876691042, \"model_execution_start_ms\": 1747876691684, \"model_execution_end_ms\": 1747876691730, \"inference_end_ms\": 1747876691730, \"prompt_eval_end_ms\": 1747876691076, \"first_token_ms\": 1747876691122, \"aggregate_sampling_time_ms\": 685, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 18 Generated Tokens: 13\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.690000 (seconds)\t\t Rate: \t18.840580 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.036000 (seconds)\t\t Rate: \t500.000000 (tokens/second)\n",
            "\t\tGenerated 13 tokens:\t0.654000 (seconds)\t\t Rate: \t19.877676 (tokens/second)\n",
            "\tTime to first generated token:\t0.082000 (seconds)\n",
            "\tSampling time over 31 tokens:\t0.685000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 21, \"generated_tokens\": 15, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876691733, \"token_encode_end_ms\": 1747876691733, \"model_execution_start_ms\": 1747876692475, \"model_execution_end_ms\": 1747876692522, \"inference_end_ms\": 1747876692522, \"prompt_eval_end_ms\": 1747876691758, \"first_token_ms\": 1747876691826, \"aggregate_sampling_time_ms\": 785, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 21 Generated Tokens: 15\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.789000 (seconds)\t\t Rate: \t19.011407 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.025000 (seconds)\t\t Rate: \t840.000000 (tokens/second)\n",
            "\t\tGenerated 15 tokens:\t0.764000 (seconds)\t\t Rate: \t19.633508 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 36 tokens:\t0.785000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 45, \"generated_tokens\": 48, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876692537, \"token_encode_end_ms\": 1747876692538, \"model_execution_start_ms\": 1747876695030, \"model_execution_end_ms\": 1747876695080, \"inference_end_ms\": 1747876695080, \"prompt_eval_end_ms\": 1747876692596, \"first_token_ms\": 1747876692665, \"aggregate_sampling_time_ms\": 2530, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 45 Generated Tokens: 48\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.543000 (seconds)\t\t Rate: \t18.875344 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.059000 (seconds)\t\t Rate: \t762.711864 (tokens/second)\n",
            "\t\tGenerated 48 tokens:\t2.484000 (seconds)\t\t Rate: \t19.323671 (tokens/second)\n",
            "\tTime to first generated token:\t0.128000 (seconds)\n",
            "\tSampling time over 93 tokens:\t2.530000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 15, \"generated_tokens\": 12, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876695096, \"token_encode_end_ms\": 1747876695096, \"model_execution_start_ms\": 1747876695674, \"model_execution_end_ms\": 1747876695738, \"inference_end_ms\": 1747876695739, \"prompt_eval_end_ms\": 1747876695128, \"first_token_ms\": 1747876695176, \"aggregate_sampling_time_ms\": 639, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 15 Generated Tokens: 12\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.643000 (seconds)\t\t Rate: \t18.662519 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.032000 (seconds)\t\t Rate: \t468.750000 (tokens/second)\n",
            "\t\tGenerated 12 tokens:\t0.611000 (seconds)\t\t Rate: \t19.639935 (tokens/second)\n",
            "\tTime to first generated token:\t0.080000 (seconds)\n",
            "\tSampling time over 27 tokens:\t0.639000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 31, \"generated_tokens\": 25, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876695745, \"token_encode_end_ms\": 1747876695746, \"model_execution_start_ms\": 1747876698219, \"model_execution_end_ms\": 1747876698331, \"inference_end_ms\": 1747876698331, \"prompt_eval_end_ms\": 1747876695801, \"first_token_ms\": 1747876695850, \"aggregate_sampling_time_ms\": 2581, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 31 Generated Tokens: 25\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.586000 (seconds)\t\t Rate: \t9.667440 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.056000 (seconds)\t\t Rate: \t553.571429 (tokens/second)\n",
            "\t\tGenerated 25 tokens:\t2.530000 (seconds)\t\t Rate: \t9.881423 (tokens/second)\n",
            "\tTime to first generated token:\t0.105000 (seconds)\n",
            "\tSampling time over 56 tokens:\t2.581000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 20, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876698348, \"token_encode_end_ms\": 1747876698349, \"model_execution_start_ms\": 1747876699342, \"model_execution_end_ms\": 1747876699389, \"inference_end_ms\": 1747876699389, \"prompt_eval_end_ms\": 1747876698420, \"first_token_ms\": 1747876698504, \"aggregate_sampling_time_ms\": 1034, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 20 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.041000 (seconds)\t\t Rate: \t15.369837 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.072000 (seconds)\t\t Rate: \t277.777778 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.969000 (seconds)\t\t Rate: \t16.511868 (tokens/second)\n",
            "\tTime to first generated token:\t0.156000 (seconds)\n",
            "\tSampling time over 36 tokens:\t1.034000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 40, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876699402, \"token_encode_end_ms\": 1747876699402, \"model_execution_start_ms\": 1747876700921, \"model_execution_end_ms\": 1747876700987, \"inference_end_ms\": 1747876700988, \"prompt_eval_end_ms\": 1747876699451, \"first_token_ms\": 1747876699500, \"aggregate_sampling_time_ms\": 1574, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 40 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.586000 (seconds)\t\t Rate: \t18.915511 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.049000 (seconds)\t\t Rate: \t816.326531 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t1.537000 (seconds)\t\t Rate: \t19.518543 (tokens/second)\n",
            "\tTime to first generated token:\t0.098000 (seconds)\n",
            "\tSampling time over 70 tokens:\t1.574000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 10, \"generated_tokens\": 7, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876701002, \"token_encode_end_ms\": 1747876701003, \"model_execution_start_ms\": 1747876701322, \"model_execution_end_ms\": 1747876701368, \"inference_end_ms\": 1747876701368, \"prompt_eval_end_ms\": 1747876701024, \"first_token_ms\": 1747876701069, \"aggregate_sampling_time_ms\": 363, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 10 Generated Tokens: 7\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.366000 (seconds)\t\t Rate: \t19.125683 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.022000 (seconds)\t\t Rate: \t454.545455 (tokens/second)\n",
            "\t\tGenerated 7 tokens:\t0.344000 (seconds)\t\t Rate: \t20.348837 (tokens/second)\n",
            "\tTime to first generated token:\t0.067000 (seconds)\n",
            "\tSampling time over 17 tokens:\t0.363000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876701371, \"token_encode_end_ms\": 1747876701371, \"model_execution_start_ms\": 1747876702522, \"model_execution_end_ms\": 1747876702568, \"inference_end_ms\": 1747876702569, \"prompt_eval_end_ms\": 1747876701403, \"first_token_ms\": 1747876701469, \"aggregate_sampling_time_ms\": 1191, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.198000 (seconds)\t\t Rate: \t19.198664 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.032000 (seconds)\t\t Rate: \t843.750000 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.166000 (seconds)\t\t Rate: \t19.725557 (tokens/second)\n",
            "\tTime to first generated token:\t0.098000 (seconds)\n",
            "\tSampling time over 50 tokens:\t1.191000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 43, \"generated_tokens\": 36, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876702572, \"token_encode_end_ms\": 1747876702573, \"model_execution_start_ms\": 1747876704436, \"model_execution_end_ms\": 1747876704485, \"inference_end_ms\": 1747876704486, \"prompt_eval_end_ms\": 1747876702614, \"first_token_ms\": 1747876702664, \"aggregate_sampling_time_ms\": 1904, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 43 Generated Tokens: 36\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.914000 (seconds)\t\t Rate: \t18.808777 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.042000 (seconds)\t\t Rate: \t1023.809524 (tokens/second)\n",
            "\t\tGenerated 36 tokens:\t1.872000 (seconds)\t\t Rate: \t19.230769 (tokens/second)\n",
            "\tTime to first generated token:\t0.092000 (seconds)\n",
            "\tSampling time over 79 tokens:\t1.904000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876704501, \"token_encode_end_ms\": 1747876704501, \"model_execution_start_ms\": 1747876705729, \"model_execution_end_ms\": 1747876705778, \"inference_end_ms\": 1747876705778, \"prompt_eval_end_ms\": 1747876704545, \"first_token_ms\": 1747876704594, \"aggregate_sampling_time_ms\": 1269, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.277000 (seconds)\t\t Rate: \t18.794049 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t727.272727 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.233000 (seconds)\t\t Rate: \t19.464720 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 56 tokens:\t1.269000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 37, \"generated_tokens\": 25, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876705792, \"token_encode_end_ms\": 1747876705793, \"model_execution_start_ms\": 1747876707068, \"model_execution_end_ms\": 1747876707117, \"inference_end_ms\": 1747876707117, \"prompt_eval_end_ms\": 1747876705846, \"first_token_ms\": 1747876705896, \"aggregate_sampling_time_ms\": 1314, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 37 Generated Tokens: 25\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.325000 (seconds)\t\t Rate: \t18.867925 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.054000 (seconds)\t\t Rate: \t685.185185 (tokens/second)\n",
            "\t\tGenerated 25 tokens:\t1.271000 (seconds)\t\t Rate: \t19.669552 (tokens/second)\n",
            "\tTime to first generated token:\t0.104000 (seconds)\n",
            "\tSampling time over 62 tokens:\t1.314000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 52, \"generated_tokens\": 41, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876707131, \"token_encode_end_ms\": 1747876707132, \"model_execution_start_ms\": 1747876710506, \"model_execution_end_ms\": 1747876710620, \"inference_end_ms\": 1747876710620, \"prompt_eval_end_ms\": 1747876707212, \"first_token_ms\": 1747876707291, \"aggregate_sampling_time_ms\": 3463, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 52 Generated Tokens: 41\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.489000 (seconds)\t\t Rate: \t11.751218 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.081000 (seconds)\t\t Rate: \t641.975309 (tokens/second)\n",
            "\t\tGenerated 41 tokens:\t3.408000 (seconds)\t\t Rate: \t12.030516 (tokens/second)\n",
            "\tTime to first generated token:\t0.160000 (seconds)\n",
            "\tSampling time over 93 tokens:\t3.463000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 13, \"generated_tokens\": 9, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876710632, \"token_encode_end_ms\": 1747876710632, \"model_execution_start_ms\": 1747876711291, \"model_execution_end_ms\": 1747876711340, \"inference_end_ms\": 1747876711341, \"prompt_eval_end_ms\": 1747876710676, \"first_token_ms\": 1747876710778, \"aggregate_sampling_time_ms\": 705, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 13 Generated Tokens: 9\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.709000 (seconds)\t\t Rate: \t12.693935 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t295.454545 (tokens/second)\n",
            "\t\tGenerated 9 tokens:\t0.665000 (seconds)\t\t Rate: \t13.533835 (tokens/second)\n",
            "\tTime to first generated token:\t0.146000 (seconds)\n",
            "\tSampling time over 22 tokens:\t0.705000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 26, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876711353, \"token_encode_end_ms\": 1747876711353, \"model_execution_start_ms\": 1747876712690, \"model_execution_end_ms\": 1747876712738, \"inference_end_ms\": 1747876712738, \"prompt_eval_end_ms\": 1747876711424, \"first_token_ms\": 1747876711475, \"aggregate_sampling_time_ms\": 1378, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 26\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.385000 (seconds)\t\t Rate: \t18.772563 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.071000 (seconds)\t\t Rate: \t422.535211 (tokens/second)\n",
            "\t\tGenerated 26 tokens:\t1.314000 (seconds)\t\t Rate: \t19.786910 (tokens/second)\n",
            "\tTime to first generated token:\t0.122000 (seconds)\n",
            "\tSampling time over 56 tokens:\t1.378000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 16, \"generated_tokens\": 9, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876712752, \"token_encode_end_ms\": 1747876712752, \"model_execution_start_ms\": 1747876713184, \"model_execution_end_ms\": 1747876713234, \"inference_end_ms\": 1747876713234, \"prompt_eval_end_ms\": 1747876712782, \"first_token_ms\": 1747876712828, \"aggregate_sampling_time_ms\": 480, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 16 Generated Tokens: 9\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.482000 (seconds)\t\t Rate: \t18.672199 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.030000 (seconds)\t\t Rate: \t533.333333 (tokens/second)\n",
            "\t\tGenerated 9 tokens:\t0.452000 (seconds)\t\t Rate: \t19.911504 (tokens/second)\n",
            "\tTime to first generated token:\t0.076000 (seconds)\n",
            "\tSampling time over 25 tokens:\t0.480000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 28, \"generated_tokens\": 21, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876713245, \"token_encode_end_ms\": 1747876713246, \"model_execution_start_ms\": 1747876714303, \"model_execution_end_ms\": 1747876714351, \"inference_end_ms\": 1747876714352, \"prompt_eval_end_ms\": 1747876713288, \"first_token_ms\": 1747876713336, \"aggregate_sampling_time_ms\": 1102, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 28 Generated Tokens: 21\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.107000 (seconds)\t\t Rate: \t18.970190 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t651.162791 (tokens/second)\n",
            "\t\tGenerated 21 tokens:\t1.064000 (seconds)\t\t Rate: \t19.736842 (tokens/second)\n",
            "\tTime to first generated token:\t0.091000 (seconds)\n",
            "\tSampling time over 49 tokens:\t1.102000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 37, \"generated_tokens\": 32, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876714356, \"token_encode_end_ms\": 1747876714357, \"model_execution_start_ms\": 1747876716013, \"model_execution_end_ms\": 1747876716061, \"inference_end_ms\": 1747876716061, \"prompt_eval_end_ms\": 1747876714411, \"first_token_ms\": 1747876714460, \"aggregate_sampling_time_ms\": 1696, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 37 Generated Tokens: 32\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.705000 (seconds)\t\t Rate: \t18.768328 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.055000 (seconds)\t\t Rate: \t672.727273 (tokens/second)\n",
            "\t\tGenerated 32 tokens:\t1.650000 (seconds)\t\t Rate: \t19.393939 (tokens/second)\n",
            "\tTime to first generated token:\t0.104000 (seconds)\n",
            "\tSampling time over 69 tokens:\t1.696000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 53, \"generated_tokens\": 51, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876716072, \"token_encode_end_ms\": 1747876716072, \"model_execution_start_ms\": 1747876718785, \"model_execution_end_ms\": 1747876718835, \"inference_end_ms\": 1747876718835, \"prompt_eval_end_ms\": 1747876716136, \"first_token_ms\": 1747876716188, \"aggregate_sampling_time_ms\": 2745, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 53 Generated Tokens: 51\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.763000 (seconds)\t\t Rate: \t18.458198 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.064000 (seconds)\t\t Rate: \t828.125000 (tokens/second)\n",
            "\t\tGenerated 51 tokens:\t2.699000 (seconds)\t\t Rate: \t18.895887 (tokens/second)\n",
            "\tTime to first generated token:\t0.116000 (seconds)\n",
            "\tSampling time over 104 tokens:\t2.745000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 35, \"generated_tokens\": 33, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876718852, \"token_encode_end_ms\": 1747876718852, \"model_execution_start_ms\": 1747876720512, \"model_execution_end_ms\": 1747876720560, \"inference_end_ms\": 1747876720560, \"prompt_eval_end_ms\": 1747876718898, \"first_token_ms\": 1747876718948, \"aggregate_sampling_time_ms\": 1698, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 35 Generated Tokens: 33\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.708000 (seconds)\t\t Rate: \t19.320843 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t760.869565 (tokens/second)\n",
            "\t\tGenerated 33 tokens:\t1.662000 (seconds)\t\t Rate: \t19.855596 (tokens/second)\n",
            "\tTime to first generated token:\t0.096000 (seconds)\n",
            "\tSampling time over 68 tokens:\t1.698000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 16, \"generated_tokens\": 8, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876720565, \"token_encode_end_ms\": 1747876720568, \"model_execution_start_ms\": 1747876720967, \"model_execution_end_ms\": 1747876721013, \"inference_end_ms\": 1747876721013, \"prompt_eval_end_ms\": 1747876720603, \"first_token_ms\": 1747876720649, \"aggregate_sampling_time_ms\": 442, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 16 Generated Tokens: 8\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.448000 (seconds)\t\t Rate: \t17.857143 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.038000 (seconds)\t\t Rate: \t421.052632 (tokens/second)\n",
            "\t\tGenerated 8 tokens:\t0.410000 (seconds)\t\t Rate: \t19.512195 (tokens/second)\n",
            "\tTime to first generated token:\t0.084000 (seconds)\n",
            "\tSampling time over 24 tokens:\t0.442000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 25, \"generated_tokens\": 20, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876721016, \"token_encode_end_ms\": 1747876721017, \"model_execution_start_ms\": 1747876723458, \"model_execution_end_ms\": 1747876723507, \"inference_end_ms\": 1747876723507, \"prompt_eval_end_ms\": 1747876721059, \"first_token_ms\": 1747876721106, \"aggregate_sampling_time_ms\": 2485, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 25 Generated Tokens: 20\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.491000 (seconds)\t\t Rate: \t8.028904 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t581.395349 (tokens/second)\n",
            "\t\tGenerated 20 tokens:\t2.448000 (seconds)\t\t Rate: \t8.169935 (tokens/second)\n",
            "\tTime to first generated token:\t0.090000 (seconds)\n",
            "\tSampling time over 45 tokens:\t2.485000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 37, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876723512, \"token_encode_end_ms\": 1747876723513, \"model_execution_start_ms\": 1747876725035, \"model_execution_end_ms\": 1747876725086, \"inference_end_ms\": 1747876725086, \"prompt_eval_end_ms\": 1747876723561, \"first_token_ms\": 1747876723621, \"aggregate_sampling_time_ms\": 1565, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 37 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.574000 (seconds)\t\t Rate: \t18.424396 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.049000 (seconds)\t\t Rate: \t755.102041 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.525000 (seconds)\t\t Rate: \t19.016393 (tokens/second)\n",
            "\tTime to first generated token:\t0.109000 (seconds)\n",
            "\tSampling time over 66 tokens:\t1.565000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 34, \"generated_tokens\": 28, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876725091, \"token_encode_end_ms\": 1747876725092, \"model_execution_start_ms\": 1747876726496, \"model_execution_end_ms\": 1747876726546, \"inference_end_ms\": 1747876726546, \"prompt_eval_end_ms\": 1747876725137, \"first_token_ms\": 1747876725196, \"aggregate_sampling_time_ms\": 1446, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 34 Generated Tokens: 28\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.455000 (seconds)\t\t Rate: \t19.243986 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t739.130435 (tokens/second)\n",
            "\t\tGenerated 28 tokens:\t1.409000 (seconds)\t\t Rate: \t19.872250 (tokens/second)\n",
            "\tTime to first generated token:\t0.105000 (seconds)\n",
            "\tSampling time over 62 tokens:\t1.446000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 63, \"generated_tokens\": 47, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876726550, \"token_encode_end_ms\": 1747876726551, \"model_execution_start_ms\": 1747876729095, \"model_execution_end_ms\": 1747876729147, \"inference_end_ms\": 1747876729147, \"prompt_eval_end_ms\": 1747876726610, \"first_token_ms\": 1747876726679, \"aggregate_sampling_time_ms\": 2584, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 63 Generated Tokens: 47\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.597000 (seconds)\t\t Rate: \t18.097805 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.060000 (seconds)\t\t Rate: \t1050.000000 (tokens/second)\n",
            "\t\tGenerated 47 tokens:\t2.537000 (seconds)\t\t Rate: \t18.525818 (tokens/second)\n",
            "\tTime to first generated token:\t0.129000 (seconds)\n",
            "\tSampling time over 110 tokens:\t2.584000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 34, \"generated_tokens\": 26, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876729156, \"token_encode_end_ms\": 1747876729157, \"model_execution_start_ms\": 1747876730480, \"model_execution_end_ms\": 1747876730528, \"inference_end_ms\": 1747876730529, \"prompt_eval_end_ms\": 1747876729208, \"first_token_ms\": 1747876729256, \"aggregate_sampling_time_ms\": 1367, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 34 Generated Tokens: 26\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.373000 (seconds)\t\t Rate: \t18.936635 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.052000 (seconds)\t\t Rate: \t653.846154 (tokens/second)\n",
            "\t\tGenerated 26 tokens:\t1.321000 (seconds)\t\t Rate: \t19.682059 (tokens/second)\n",
            "\tTime to first generated token:\t0.100000 (seconds)\n",
            "\tSampling time over 60 tokens:\t1.367000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 17, \"generated_tokens\": 12, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876730535, \"token_encode_end_ms\": 1747876730535, \"model_execution_start_ms\": 1747876731131, \"model_execution_end_ms\": 1747876731178, \"inference_end_ms\": 1747876731179, \"prompt_eval_end_ms\": 1747876730572, \"first_token_ms\": 1747876730618, \"aggregate_sampling_time_ms\": 639, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 17 Generated Tokens: 12\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.644000 (seconds)\t\t Rate: \t18.633540 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.037000 (seconds)\t\t Rate: \t459.459459 (tokens/second)\n",
            "\t\tGenerated 12 tokens:\t0.607000 (seconds)\t\t Rate: \t19.769357 (tokens/second)\n",
            "\tTime to first generated token:\t0.083000 (seconds)\n",
            "\tSampling time over 29 tokens:\t0.639000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 51, \"generated_tokens\": 36, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876731189, \"token_encode_end_ms\": 1747876731190, \"model_execution_start_ms\": 1747876733080, \"model_execution_end_ms\": 1747876733130, \"inference_end_ms\": 1747876733131, \"prompt_eval_end_ms\": 1747876731253, \"first_token_ms\": 1747876731303, \"aggregate_sampling_time_ms\": 1932, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 51 Generated Tokens: 36\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.942000 (seconds)\t\t Rate: \t18.537590 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.064000 (seconds)\t\t Rate: \t796.875000 (tokens/second)\n",
            "\t\tGenerated 36 tokens:\t1.878000 (seconds)\t\t Rate: \t19.169329 (tokens/second)\n",
            "\tTime to first generated token:\t0.114000 (seconds)\n",
            "\tSampling time over 87 tokens:\t1.932000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 17, \"generated_tokens\": 18, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876733143, \"token_encode_end_ms\": 1747876733144, \"model_execution_start_ms\": 1747876735418, \"model_execution_end_ms\": 1747876735529, \"inference_end_ms\": 1747876735529, \"prompt_eval_end_ms\": 1747876733189, \"first_token_ms\": 1747876733235, \"aggregate_sampling_time_ms\": 2380, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 17 Generated Tokens: 18\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.386000 (seconds)\t\t Rate: \t7.544007 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t369.565217 (tokens/second)\n",
            "\t\tGenerated 18 tokens:\t2.340000 (seconds)\t\t Rate: \t7.692308 (tokens/second)\n",
            "\tTime to first generated token:\t0.092000 (seconds)\n",
            "\tSampling time over 35 tokens:\t2.380000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 25, \"generated_tokens\": 20, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876735533, \"token_encode_end_ms\": 1747876735533, \"model_execution_start_ms\": 1747876736531, \"model_execution_end_ms\": 1747876736578, \"inference_end_ms\": 1747876736578, \"prompt_eval_end_ms\": 1747876735580, \"first_token_ms\": 1747876735637, \"aggregate_sampling_time_ms\": 1042, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 25 Generated Tokens: 20\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.045000 (seconds)\t\t Rate: \t19.138756 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.047000 (seconds)\t\t Rate: \t531.914894 (tokens/second)\n",
            "\t\tGenerated 20 tokens:\t0.998000 (seconds)\t\t Rate: \t20.040080 (tokens/second)\n",
            "\tTime to first generated token:\t0.104000 (seconds)\n",
            "\tSampling time over 45 tokens:\t1.042000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 21, \"generated_tokens\": 14, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876736582, \"token_encode_end_ms\": 1747876736583, \"model_execution_start_ms\": 1747876737273, \"model_execution_end_ms\": 1747876737324, \"inference_end_ms\": 1747876737325, \"prompt_eval_end_ms\": 1747876736625, \"first_token_ms\": 1747876736674, \"aggregate_sampling_time_ms\": 730, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 21 Generated Tokens: 14\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.743000 (seconds)\t\t Rate: \t18.842530 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t488.372093 (tokens/second)\n",
            "\t\tGenerated 14 tokens:\t0.700000 (seconds)\t\t Rate: \t20.000000 (tokens/second)\n",
            "\tTime to first generated token:\t0.092000 (seconds)\n",
            "\tSampling time over 35 tokens:\t0.730000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 67, \"generated_tokens\": 44, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876737331, \"token_encode_end_ms\": 1747876737332, \"model_execution_start_ms\": 1747876739762, \"model_execution_end_ms\": 1747876739814, \"inference_end_ms\": 1747876739814, \"prompt_eval_end_ms\": 1747876737417, \"first_token_ms\": 1747876737506, \"aggregate_sampling_time_ms\": 2466, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 67 Generated Tokens: 44\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.483000 (seconds)\t\t Rate: \t17.720499 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.086000 (seconds)\t\t Rate: \t779.069767 (tokens/second)\n",
            "\t\tGenerated 44 tokens:\t2.397000 (seconds)\t\t Rate: \t18.356279 (tokens/second)\n",
            "\tTime to first generated token:\t0.175000 (seconds)\n",
            "\tSampling time over 111 tokens:\t2.466000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 48, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876739821, \"token_encode_end_ms\": 1747876739822, \"model_execution_start_ms\": 1747876741864, \"model_execution_end_ms\": 1747876741913, \"inference_end_ms\": 1747876741913, \"prompt_eval_end_ms\": 1747876739883, \"first_token_ms\": 1747876739933, \"aggregate_sampling_time_ms\": 2082, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 48 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.092000 (seconds)\t\t Rate: \t18.642447 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.062000 (seconds)\t\t Rate: \t774.193548 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t2.030000 (seconds)\t\t Rate: \t19.211823 (tokens/second)\n",
            "\tTime to first generated token:\t0.112000 (seconds)\n",
            "\tSampling time over 87 tokens:\t2.082000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 27, \"generated_tokens\": 24, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876741919, \"token_encode_end_ms\": 1747876741919, \"model_execution_start_ms\": 1747876743119, \"model_execution_end_ms\": 1747876743166, \"inference_end_ms\": 1747876743166, \"prompt_eval_end_ms\": 1747876741971, \"first_token_ms\": 1747876742019, \"aggregate_sampling_time_ms\": 1239, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 27 Generated Tokens: 24\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.247000 (seconds)\t\t Rate: \t19.246191 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.052000 (seconds)\t\t Rate: \t519.230769 (tokens/second)\n",
            "\t\tGenerated 24 tokens:\t1.195000 (seconds)\t\t Rate: \t20.083682 (tokens/second)\n",
            "\tTime to first generated token:\t0.100000 (seconds)\n",
            "\tSampling time over 51 tokens:\t1.239000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 54, \"generated_tokens\": 42, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876743171, \"token_encode_end_ms\": 1747876743171, \"model_execution_start_ms\": 1747876745398, \"model_execution_end_ms\": 1747876745449, \"inference_end_ms\": 1747876745450, \"prompt_eval_end_ms\": 1747876743240, \"first_token_ms\": 1747876743290, \"aggregate_sampling_time_ms\": 2271, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 54 Generated Tokens: 42\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.279000 (seconds)\t\t Rate: \t18.429136 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.069000 (seconds)\t\t Rate: \t782.608696 (tokens/second)\n",
            "\t\tGenerated 42 tokens:\t2.210000 (seconds)\t\t Rate: \t19.004525 (tokens/second)\n",
            "\tTime to first generated token:\t0.119000 (seconds)\n",
            "\tSampling time over 96 tokens:\t2.271000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 48, \"generated_tokens\": 42, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876745456, \"token_encode_end_ms\": 1747876745456, \"model_execution_start_ms\": 1747876749135, \"model_execution_end_ms\": 1747876749186, \"inference_end_ms\": 1747876749187, \"prompt_eval_end_ms\": 1747876745519, \"first_token_ms\": 1747876745597, \"aggregate_sampling_time_ms\": 3716, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 48 Generated Tokens: 42\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.731000 (seconds)\t\t Rate: \t11.257036 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.063000 (seconds)\t\t Rate: \t761.904762 (tokens/second)\n",
            "\t\tGenerated 42 tokens:\t3.668000 (seconds)\t\t Rate: \t11.450382 (tokens/second)\n",
            "\tTime to first generated token:\t0.141000 (seconds)\n",
            "\tSampling time over 90 tokens:\t3.716000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 25, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876749193, \"token_encode_end_ms\": 1747876749194, \"model_execution_start_ms\": 1747876750465, \"model_execution_end_ms\": 1747876750514, \"inference_end_ms\": 1747876750514, \"prompt_eval_end_ms\": 1747876749247, \"first_token_ms\": 1747876749297, \"aggregate_sampling_time_ms\": 1314, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 25\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.321000 (seconds)\t\t Rate: \t18.925057 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.054000 (seconds)\t\t Rate: \t592.592593 (tokens/second)\n",
            "\t\tGenerated 25 tokens:\t1.267000 (seconds)\t\t Rate: \t19.731650 (tokens/second)\n",
            "\tTime to first generated token:\t0.104000 (seconds)\n",
            "\tSampling time over 57 tokens:\t1.314000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 83, \"generated_tokens\": 80, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876750519, \"token_encode_end_ms\": 1747876750519, \"model_execution_start_ms\": 1747876755046, \"model_execution_end_ms\": 1747876755099, \"inference_end_ms\": 1747876755100, \"prompt_eval_end_ms\": 1747876750614, \"first_token_ms\": 1747876750668, \"aggregate_sampling_time_ms\": 4551, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 83 Generated Tokens: 80\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t4.581000 (seconds)\t\t Rate: \t17.463436 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.095000 (seconds)\t\t Rate: \t873.684211 (tokens/second)\n",
            "\t\tGenerated 80 tokens:\t4.486000 (seconds)\t\t Rate: \t17.833259 (tokens/second)\n",
            "\tTime to first generated token:\t0.149000 (seconds)\n",
            "\tSampling time over 163 tokens:\t4.551000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 22, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876755113, \"token_encode_end_ms\": 1747876755113, \"model_execution_start_ms\": 1747876755898, \"model_execution_end_ms\": 1747876755945, \"inference_end_ms\": 1747876755945, \"prompt_eval_end_ms\": 1747876755153, \"first_token_ms\": 1747876755202, \"aggregate_sampling_time_ms\": 827, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 22 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.832000 (seconds)\t\t Rate: \t19.230769 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.040000 (seconds)\t\t Rate: \t550.000000 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.792000 (seconds)\t\t Rate: \t20.202020 (tokens/second)\n",
            "\tTime to first generated token:\t0.089000 (seconds)\n",
            "\tSampling time over 38 tokens:\t0.827000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 18, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876755954, \"token_encode_end_ms\": 1747876755954, \"model_execution_start_ms\": 1747876756732, \"model_execution_end_ms\": 1747876756778, \"inference_end_ms\": 1747876756778, \"prompt_eval_end_ms\": 1747876756009, \"first_token_ms\": 1747876756060, \"aggregate_sampling_time_ms\": 816, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 18 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.824000 (seconds)\t\t Rate: \t19.417476 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.055000 (seconds)\t\t Rate: \t327.272727 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.769000 (seconds)\t\t Rate: \t20.806242 (tokens/second)\n",
            "\tTime to first generated token:\t0.106000 (seconds)\n",
            "\tSampling time over 34 tokens:\t0.816000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 46, \"generated_tokens\": 38, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876756791, \"token_encode_end_ms\": 1747876756792, \"model_execution_start_ms\": 1747876760294, \"model_execution_end_ms\": 1747876760345, \"inference_end_ms\": 1747876760345, \"prompt_eval_end_ms\": 1747876756846, \"first_token_ms\": 1747876756896, \"aggregate_sampling_time_ms\": 3535, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 46 Generated Tokens: 38\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.554000 (seconds)\t\t Rate: \t10.692178 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.055000 (seconds)\t\t Rate: \t836.363636 (tokens/second)\n",
            "\t\tGenerated 38 tokens:\t3.499000 (seconds)\t\t Rate: \t10.860246 (tokens/second)\n",
            "\tTime to first generated token:\t0.105000 (seconds)\n",
            "\tSampling time over 84 tokens:\t3.535000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 52, \"generated_tokens\": 41, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876760362, \"token_encode_end_ms\": 1747876760362, \"model_execution_start_ms\": 1747876762531, \"model_execution_end_ms\": 1747876762582, \"inference_end_ms\": 1747876762582, \"prompt_eval_end_ms\": 1747876760423, \"first_token_ms\": 1747876760473, \"aggregate_sampling_time_ms\": 2212, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 52 Generated Tokens: 41\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.220000 (seconds)\t\t Rate: \t18.468468 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.061000 (seconds)\t\t Rate: \t852.459016 (tokens/second)\n",
            "\t\tGenerated 41 tokens:\t2.159000 (seconds)\t\t Rate: \t18.990273 (tokens/second)\n",
            "\tTime to first generated token:\t0.111000 (seconds)\n",
            "\tSampling time over 93 tokens:\t2.212000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 29, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876762598, \"token_encode_end_ms\": 1747876762598, \"model_execution_start_ms\": 1747876764051, \"model_execution_end_ms\": 1747876764100, \"inference_end_ms\": 1747876764101, \"prompt_eval_end_ms\": 1747876762644, \"first_token_ms\": 1747876762694, \"aggregate_sampling_time_ms\": 1490, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 29\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.503000 (seconds)\t\t Rate: \t19.294744 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.046000 (seconds)\t\t Rate: \t717.391304 (tokens/second)\n",
            "\t\tGenerated 29 tokens:\t1.457000 (seconds)\t\t Rate: \t19.903912 (tokens/second)\n",
            "\tTime to first generated token:\t0.096000 (seconds)\n",
            "\tSampling time over 62 tokens:\t1.490000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 14, \"generated_tokens\": 17, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876764105, \"token_encode_end_ms\": 1747876764106, \"model_execution_start_ms\": 1747876764935, \"model_execution_end_ms\": 1747876764982, \"inference_end_ms\": 1747876764983, \"prompt_eval_end_ms\": 1747876764142, \"first_token_ms\": 1747876764191, \"aggregate_sampling_time_ms\": 871, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 14 Generated Tokens: 17\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.878000 (seconds)\t\t Rate: \t19.362187 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.037000 (seconds)\t\t Rate: \t378.378378 (tokens/second)\n",
            "\t\tGenerated 17 tokens:\t0.841000 (seconds)\t\t Rate: \t20.214031 (tokens/second)\n",
            "\tTime to first generated token:\t0.086000 (seconds)\n",
            "\tSampling time over 31 tokens:\t0.871000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 57, \"generated_tokens\": 57, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876764994, \"token_encode_end_ms\": 1747876764995, \"model_execution_start_ms\": 1747876768102, \"model_execution_end_ms\": 1747876768153, \"inference_end_ms\": 1747876768153, \"prompt_eval_end_ms\": 1747876765061, \"first_token_ms\": 1747876765113, \"aggregate_sampling_time_ms\": 3137, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 57 Generated Tokens: 57\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.159000 (seconds)\t\t Rate: \t18.043685 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.067000 (seconds)\t\t Rate: \t850.746269 (tokens/second)\n",
            "\t\tGenerated 57 tokens:\t3.092000 (seconds)\t\t Rate: \t18.434670 (tokens/second)\n",
            "\tTime to first generated token:\t0.119000 (seconds)\n",
            "\tSampling time over 114 tokens:\t3.137000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 33, \"generated_tokens\": 25, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876768163, \"token_encode_end_ms\": 1747876768163, \"model_execution_start_ms\": 1747876769415, \"model_execution_end_ms\": 1747876769464, \"inference_end_ms\": 1747876769464, \"prompt_eval_end_ms\": 1747876768213, \"first_token_ms\": 1747876768261, \"aggregate_sampling_time_ms\": 1290, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 33 Generated Tokens: 25\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.301000 (seconds)\t\t Rate: \t19.215988 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.050000 (seconds)\t\t Rate: \t660.000000 (tokens/second)\n",
            "\t\tGenerated 25 tokens:\t1.251000 (seconds)\t\t Rate: \t19.984013 (tokens/second)\n",
            "\tTime to first generated token:\t0.098000 (seconds)\n",
            "\tSampling time over 58 tokens:\t1.290000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 58, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876769471, \"token_encode_end_ms\": 1747876769472, \"model_execution_start_ms\": 1747876772981, \"model_execution_end_ms\": 1747876773032, \"inference_end_ms\": 1747876773032, \"prompt_eval_end_ms\": 1747876769557, \"first_token_ms\": 1747876769609, \"aggregate_sampling_time_ms\": 3548, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 58 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.561000 (seconds)\t\t Rate: \t10.951980 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.086000 (seconds)\t\t Rate: \t674.418605 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t3.475000 (seconds)\t\t Rate: \t11.223022 (tokens/second)\n",
            "\tTime to first generated token:\t0.138000 (seconds)\n",
            "\tSampling time over 97 tokens:\t3.548000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 89, \"generated_tokens\": 17, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876773040, \"token_encode_end_ms\": 1747876773040, \"model_execution_start_ms\": 1747876774046, \"model_execution_end_ms\": 1747876774104, \"inference_end_ms\": 1747876774104, \"prompt_eval_end_ms\": 1747876773135, \"first_token_ms\": 1747876773191, \"aggregate_sampling_time_ms\": 1057, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 89 Generated Tokens: 17\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.064000 (seconds)\t\t Rate: \t15.977444 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.095000 (seconds)\t\t Rate: \t936.842105 (tokens/second)\n",
            "\t\tGenerated 17 tokens:\t0.969000 (seconds)\t\t Rate: \t17.543860 (tokens/second)\n",
            "\tTime to first generated token:\t0.151000 (seconds)\n",
            "\tSampling time over 106 tokens:\t1.057000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 19, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876774113, \"token_encode_end_ms\": 1747876774114, \"model_execution_start_ms\": 1747876774899, \"model_execution_end_ms\": 1747876774946, \"inference_end_ms\": 1747876774947, \"prompt_eval_end_ms\": 1747876774140, \"first_token_ms\": 1747876774197, \"aggregate_sampling_time_ms\": 826, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 19 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.834000 (seconds)\t\t Rate: \t19.184652 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.027000 (seconds)\t\t Rate: \t703.703704 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.807000 (seconds)\t\t Rate: \t19.826518 (tokens/second)\n",
            "\tTime to first generated token:\t0.084000 (seconds)\n",
            "\tSampling time over 35 tokens:\t0.826000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 98, \"generated_tokens\": 72, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876774953, \"token_encode_end_ms\": 1747876774954, \"model_execution_start_ms\": 1747876779078, \"model_execution_end_ms\": 1747876779134, \"inference_end_ms\": 1747876779134, \"prompt_eval_end_ms\": 1747876775053, \"first_token_ms\": 1747876775109, \"aggregate_sampling_time_ms\": 4157, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 98 Generated Tokens: 72\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t4.181000 (seconds)\t\t Rate: \t17.220761 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.100000 (seconds)\t\t Rate: \t980.000000 (tokens/second)\n",
            "\t\tGenerated 72 tokens:\t4.081000 (seconds)\t\t Rate: \t17.642735 (tokens/second)\n",
            "\tTime to first generated token:\t0.156000 (seconds)\n",
            "\tSampling time over 170 tokens:\t4.157000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 58, \"generated_tokens\": 50, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876779152, \"token_encode_end_ms\": 1747876779153, \"model_execution_start_ms\": 1747876781814, \"model_execution_end_ms\": 1747876781865, \"inference_end_ms\": 1747876781865, \"prompt_eval_end_ms\": 1747876779214, \"first_token_ms\": 1747876779264, \"aggregate_sampling_time_ms\": 2691, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 58 Generated Tokens: 50\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.713000 (seconds)\t\t Rate: \t18.429783 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.062000 (seconds)\t\t Rate: \t935.483871 (tokens/second)\n",
            "\t\tGenerated 50 tokens:\t2.651000 (seconds)\t\t Rate: \t18.860807 (tokens/second)\n",
            "\tTime to first generated token:\t0.112000 (seconds)\n",
            "\tSampling time over 108 tokens:\t2.691000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 35, \"generated_tokens\": 31, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876781871, \"token_encode_end_ms\": 1747876781872, \"model_execution_start_ms\": 1747876784899, \"model_execution_end_ms\": 1747876784946, \"inference_end_ms\": 1747876784947, \"prompt_eval_end_ms\": 1747876781934, \"first_token_ms\": 1747876781997, \"aggregate_sampling_time_ms\": 3066, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 35 Generated Tokens: 31\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.076000 (seconds)\t\t Rate: \t10.078023 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.063000 (seconds)\t\t Rate: \t555.555556 (tokens/second)\n",
            "\t\tGenerated 31 tokens:\t3.013000 (seconds)\t\t Rate: \t10.288749 (tokens/second)\n",
            "\tTime to first generated token:\t0.126000 (seconds)\n",
            "\tSampling time over 66 tokens:\t3.066000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 11, \"generated_tokens\": 10, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876784960, \"token_encode_end_ms\": 1747876784960, \"model_execution_start_ms\": 1747876785438, \"model_execution_end_ms\": 1747876785486, \"inference_end_ms\": 1747876785487, \"prompt_eval_end_ms\": 1747876784986, \"first_token_ms\": 1747876785041, \"aggregate_sampling_time_ms\": 522, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 11 Generated Tokens: 10\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.527000 (seconds)\t\t Rate: \t18.975332 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.026000 (seconds)\t\t Rate: \t423.076923 (tokens/second)\n",
            "\t\tGenerated 10 tokens:\t0.501000 (seconds)\t\t Rate: \t19.960080 (tokens/second)\n",
            "\tTime to first generated token:\t0.081000 (seconds)\n",
            "\tSampling time over 21 tokens:\t0.522000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 23, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876785498, \"token_encode_end_ms\": 1747876785499, \"model_execution_start_ms\": 1747876786669, \"model_execution_end_ms\": 1747876786717, \"inference_end_ms\": 1747876786718, \"prompt_eval_end_ms\": 1747876785542, \"first_token_ms\": 1747876785591, \"aggregate_sampling_time_ms\": 1205, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 23\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.220000 (seconds)\t\t Rate: \t18.852459 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t681.818182 (tokens/second)\n",
            "\t\tGenerated 23 tokens:\t1.176000 (seconds)\t\t Rate: \t19.557823 (tokens/second)\n",
            "\tTime to first generated token:\t0.093000 (seconds)\n",
            "\tSampling time over 53 tokens:\t1.205000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 19, \"generated_tokens\": 11, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876786731, \"token_encode_end_ms\": 1747876786732, \"model_execution_start_ms\": 1747876787275, \"model_execution_end_ms\": 1747876787321, \"inference_end_ms\": 1747876787321, \"prompt_eval_end_ms\": 1747876786766, \"first_token_ms\": 1747876786814, \"aggregate_sampling_time_ms\": 586, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 19 Generated Tokens: 11\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.590000 (seconds)\t\t Rate: \t18.644068 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.035000 (seconds)\t\t Rate: \t542.857143 (tokens/second)\n",
            "\t\tGenerated 11 tokens:\t0.555000 (seconds)\t\t Rate: \t19.819820 (tokens/second)\n",
            "\tTime to first generated token:\t0.083000 (seconds)\n",
            "\tSampling time over 30 tokens:\t0.586000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 17, \"generated_tokens\": 12, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876787324, \"token_encode_end_ms\": 1747876787324, \"model_execution_start_ms\": 1747876787899, \"model_execution_end_ms\": 1747876787945, \"inference_end_ms\": 1747876787946, \"prompt_eval_end_ms\": 1747876787344, \"first_token_ms\": 1747876787390, \"aggregate_sampling_time_ms\": 610, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 17 Generated Tokens: 12\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.622000 (seconds)\t\t Rate: \t19.292605 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.020000 (seconds)\t\t Rate: \t850.000000 (tokens/second)\n",
            "\t\tGenerated 12 tokens:\t0.602000 (seconds)\t\t Rate: \t19.933555 (tokens/second)\n",
            "\tTime to first generated token:\t0.066000 (seconds)\n",
            "\tSampling time over 29 tokens:\t0.610000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 44, \"generated_tokens\": 41, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876787949, \"token_encode_end_ms\": 1747876787949, \"model_execution_start_ms\": 1747876790065, \"model_execution_end_ms\": 1747876790115, \"inference_end_ms\": 1747876790115, \"prompt_eval_end_ms\": 1747876788008, \"first_token_ms\": 1747876788058, \"aggregate_sampling_time_ms\": 2155, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 44 Generated Tokens: 41\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.166000 (seconds)\t\t Rate: \t18.928901 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.059000 (seconds)\t\t Rate: \t745.762712 (tokens/second)\n",
            "\t\tGenerated 41 tokens:\t2.107000 (seconds)\t\t Rate: \t19.458946 (tokens/second)\n",
            "\tTime to first generated token:\t0.109000 (seconds)\n",
            "\tSampling time over 85 tokens:\t2.155000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 63, \"generated_tokens\": 48, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876790129, \"token_encode_end_ms\": 1747876790129, \"model_execution_start_ms\": 1747876792741, \"model_execution_end_ms\": 1747876792793, \"inference_end_ms\": 1747876792793, \"prompt_eval_end_ms\": 1747876790198, \"first_token_ms\": 1747876790259, \"aggregate_sampling_time_ms\": 2648, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 63 Generated Tokens: 48\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.664000 (seconds)\t\t Rate: \t18.018018 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.069000 (seconds)\t\t Rate: \t913.043478 (tokens/second)\n",
            "\t\tGenerated 48 tokens:\t2.595000 (seconds)\t\t Rate: \t18.497110 (tokens/second)\n",
            "\tTime to first generated token:\t0.130000 (seconds)\n",
            "\tSampling time over 111 tokens:\t2.648000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 16, \"generated_tokens\": 9, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876792808, \"token_encode_end_ms\": 1747876792809, \"model_execution_start_ms\": 1747876793234, \"model_execution_end_ms\": 1747876793282, \"inference_end_ms\": 1747876793283, \"prompt_eval_end_ms\": 1747876792839, \"first_token_ms\": 1747876792886, \"aggregate_sampling_time_ms\": 473, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 16 Generated Tokens: 9\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.475000 (seconds)\t\t Rate: \t18.947368 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.031000 (seconds)\t\t Rate: \t516.129032 (tokens/second)\n",
            "\t\tGenerated 9 tokens:\t0.444000 (seconds)\t\t Rate: \t20.270270 (tokens/second)\n",
            "\tTime to first generated token:\t0.078000 (seconds)\n",
            "\tSampling time over 25 tokens:\t0.473000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 56, \"generated_tokens\": 42, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876793288, \"token_encode_end_ms\": 1747876793289, \"model_execution_start_ms\": 1747876796992, \"model_execution_end_ms\": 1747876797042, \"inference_end_ms\": 1747876797043, \"prompt_eval_end_ms\": 1747876793373, \"first_token_ms\": 1747876793426, \"aggregate_sampling_time_ms\": 3742, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 56 Generated Tokens: 42\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.755000 (seconds)\t\t Rate: \t11.185087 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.085000 (seconds)\t\t Rate: \t658.823529 (tokens/second)\n",
            "\t\tGenerated 42 tokens:\t3.670000 (seconds)\t\t Rate: \t11.444142 (tokens/second)\n",
            "\tTime to first generated token:\t0.138000 (seconds)\n",
            "\tSampling time over 98 tokens:\t3.742000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 41, \"generated_tokens\": 39, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876797057, \"token_encode_end_ms\": 1747876797058, \"model_execution_start_ms\": 1747876799127, \"model_execution_end_ms\": 1747876799177, \"inference_end_ms\": 1747876799177, \"prompt_eval_end_ms\": 1747876797113, \"first_token_ms\": 1747876797162, \"aggregate_sampling_time_ms\": 2108, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 41 Generated Tokens: 39\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.120000 (seconds)\t\t Rate: \t18.396226 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.056000 (seconds)\t\t Rate: \t732.142857 (tokens/second)\n",
            "\t\tGenerated 39 tokens:\t2.064000 (seconds)\t\t Rate: \t18.895349 (tokens/second)\n",
            "\tTime to first generated token:\t0.105000 (seconds)\n",
            "\tSampling time over 80 tokens:\t2.108000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 21, \"generated_tokens\": 14, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876799187, \"token_encode_end_ms\": 1747876799187, \"model_execution_start_ms\": 1747876799885, \"model_execution_end_ms\": 1747876799932, \"inference_end_ms\": 1747876799932, \"prompt_eval_end_ms\": 1747876799229, \"first_token_ms\": 1747876799277, \"aggregate_sampling_time_ms\": 741, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 21 Generated Tokens: 14\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.745000 (seconds)\t\t Rate: \t18.791946 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.042000 (seconds)\t\t Rate: \t500.000000 (tokens/second)\n",
            "\t\tGenerated 14 tokens:\t0.703000 (seconds)\t\t Rate: \t19.914651 (tokens/second)\n",
            "\tTime to first generated token:\t0.090000 (seconds)\n",
            "\tSampling time over 35 tokens:\t0.741000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 29, \"generated_tokens\": 25, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876799937, \"token_encode_end_ms\": 1747876799938, \"model_execution_start_ms\": 1747876801193, \"model_execution_end_ms\": 1747876801241, \"inference_end_ms\": 1747876801241, \"prompt_eval_end_ms\": 1747876799984, \"first_token_ms\": 1747876800031, \"aggregate_sampling_time_ms\": 1300, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 29 Generated Tokens: 25\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.304000 (seconds)\t\t Rate: \t19.171779 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.047000 (seconds)\t\t Rate: \t617.021277 (tokens/second)\n",
            "\t\tGenerated 25 tokens:\t1.257000 (seconds)\t\t Rate: \t19.888624 (tokens/second)\n",
            "\tTime to first generated token:\t0.094000 (seconds)\n",
            "\tSampling time over 54 tokens:\t1.300000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 16, \"generated_tokens\": 12, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876801255, \"token_encode_end_ms\": 1747876801256, \"model_execution_start_ms\": 1747876801855, \"model_execution_end_ms\": 1747876801901, \"inference_end_ms\": 1747876801901, \"prompt_eval_end_ms\": 1747876801294, \"first_token_ms\": 1747876801340, \"aggregate_sampling_time_ms\": 638, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 16 Generated Tokens: 12\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.646000 (seconds)\t\t Rate: \t18.575851 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.039000 (seconds)\t\t Rate: \t410.256410 (tokens/second)\n",
            "\t\tGenerated 12 tokens:\t0.607000 (seconds)\t\t Rate: \t19.769357 (tokens/second)\n",
            "\tTime to first generated token:\t0.085000 (seconds)\n",
            "\tSampling time over 28 tokens:\t0.638000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876801913, \"token_encode_end_ms\": 1747876801914, \"model_execution_start_ms\": 1747876803433, \"model_execution_end_ms\": 1747876803481, \"inference_end_ms\": 1747876803482, \"prompt_eval_end_ms\": 1747876801957, \"first_token_ms\": 1747876802005, \"aggregate_sampling_time_ms\": 1559, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.569000 (seconds)\t\t Rate: \t19.120459 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.044000 (seconds)\t\t Rate: \t727.272727 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t1.525000 (seconds)\t\t Rate: \t19.672131 (tokens/second)\n",
            "\tTime to first generated token:\t0.092000 (seconds)\n",
            "\tSampling time over 62 tokens:\t1.559000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 42, \"generated_tokens\": 44, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876803489, \"token_encode_end_ms\": 1747876803489, \"model_execution_start_ms\": 1747876805759, \"model_execution_end_ms\": 1747876805826, \"inference_end_ms\": 1747876805826, \"prompt_eval_end_ms\": 1747876803545, \"first_token_ms\": 1747876803594, \"aggregate_sampling_time_ms\": 2320, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 42 Generated Tokens: 44\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.337000 (seconds)\t\t Rate: \t18.827557 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.056000 (seconds)\t\t Rate: \t750.000000 (tokens/second)\n",
            "\t\tGenerated 44 tokens:\t2.281000 (seconds)\t\t Rate: \t19.289785 (tokens/second)\n",
            "\tTime to first generated token:\t0.105000 (seconds)\n",
            "\tSampling time over 86 tokens:\t2.320000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 22, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876805841, \"token_encode_end_ms\": 1747876805842, \"model_execution_start_ms\": 1747876807544, \"model_execution_end_ms\": 1747876807678, \"inference_end_ms\": 1747876807678, \"prompt_eval_end_ms\": 1747876805883, \"first_token_ms\": 1747876805931, \"aggregate_sampling_time_ms\": 1827, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 22\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.837000 (seconds)\t\t Rate: \t11.976048 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.042000 (seconds)\t\t Rate: \t714.285714 (tokens/second)\n",
            "\t\tGenerated 22 tokens:\t1.795000 (seconds)\t\t Rate: \t12.256267 (tokens/second)\n",
            "\tTime to first generated token:\t0.090000 (seconds)\n",
            "\tSampling time over 52 tokens:\t1.827000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 22, \"generated_tokens\": 18, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876807690, \"token_encode_end_ms\": 1747876807691, \"model_execution_start_ms\": 1747876809408, \"model_execution_end_ms\": 1747876809456, \"inference_end_ms\": 1747876809457, \"prompt_eval_end_ms\": 1747876807819, \"first_token_ms\": 1747876808311, \"aggregate_sampling_time_ms\": 1762, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 22 Generated Tokens: 18\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.767000 (seconds)\t\t Rate: \t10.186757 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.129000 (seconds)\t\t Rate: \t170.542636 (tokens/second)\n",
            "\t\tGenerated 18 tokens:\t1.638000 (seconds)\t\t Rate: \t10.989011 (tokens/second)\n",
            "\tTime to first generated token:\t0.621000 (seconds)\n",
            "\tSampling time over 40 tokens:\t1.762000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 18, \"generated_tokens\": 14, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876809470, \"token_encode_end_ms\": 1747876809470, \"model_execution_start_ms\": 1747876810169, \"model_execution_end_ms\": 1747876810217, \"inference_end_ms\": 1747876810217, \"prompt_eval_end_ms\": 1747876809501, \"first_token_ms\": 1747876809549, \"aggregate_sampling_time_ms\": 746, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 18 Generated Tokens: 14\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.747000 (seconds)\t\t Rate: \t18.741633 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.031000 (seconds)\t\t Rate: \t580.645161 (tokens/second)\n",
            "\t\tGenerated 14 tokens:\t0.716000 (seconds)\t\t Rate: \t19.553073 (tokens/second)\n",
            "\tTime to first generated token:\t0.079000 (seconds)\n",
            "\tSampling time over 32 tokens:\t0.746000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 37, \"generated_tokens\": 30, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876810228, \"token_encode_end_ms\": 1747876810228, \"model_execution_start_ms\": 1747876811782, \"model_execution_end_ms\": 1747876811830, \"inference_end_ms\": 1747876811831, \"prompt_eval_end_ms\": 1747876810282, \"first_token_ms\": 1747876810332, \"aggregate_sampling_time_ms\": 1593, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 37 Generated Tokens: 30\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.603000 (seconds)\t\t Rate: \t18.714910 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.054000 (seconds)\t\t Rate: \t685.185185 (tokens/second)\n",
            "\t\tGenerated 30 tokens:\t1.549000 (seconds)\t\t Rate: \t19.367334 (tokens/second)\n",
            "\tTime to first generated token:\t0.104000 (seconds)\n",
            "\tSampling time over 67 tokens:\t1.593000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 15, \"generated_tokens\": 11, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876811845, \"token_encode_end_ms\": 1747876811846, \"model_execution_start_ms\": 1747876812405, \"model_execution_end_ms\": 1747876812452, \"inference_end_ms\": 1747876812452, \"prompt_eval_end_ms\": 1747876811874, \"first_token_ms\": 1747876811920, \"aggregate_sampling_time_ms\": 602, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 15 Generated Tokens: 11\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.607000 (seconds)\t\t Rate: \t18.121911 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.029000 (seconds)\t\t Rate: \t517.241379 (tokens/second)\n",
            "\t\tGenerated 11 tokens:\t0.578000 (seconds)\t\t Rate: \t19.031142 (tokens/second)\n",
            "\tTime to first generated token:\t0.075000 (seconds)\n",
            "\tSampling time over 26 tokens:\t0.602000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 50, \"generated_tokens\": 38, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876812456, \"token_encode_end_ms\": 1747876812457, \"model_execution_start_ms\": 1747876814469, \"model_execution_end_ms\": 1747876814520, \"inference_end_ms\": 1747876814520, \"prompt_eval_end_ms\": 1747876812520, \"first_token_ms\": 1747876812570, \"aggregate_sampling_time_ms\": 2048, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 50 Generated Tokens: 38\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.064000 (seconds)\t\t Rate: \t18.410853 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.064000 (seconds)\t\t Rate: \t781.250000 (tokens/second)\n",
            "\t\tGenerated 38 tokens:\t2.000000 (seconds)\t\t Rate: \t19.000000 (tokens/second)\n",
            "\tTime to first generated token:\t0.114000 (seconds)\n",
            "\tSampling time over 88 tokens:\t2.048000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 41, \"generated_tokens\": 37, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876814526, \"token_encode_end_ms\": 1747876814527, \"model_execution_start_ms\": 1747876816459, \"model_execution_end_ms\": 1747876816509, \"inference_end_ms\": 1747876816509, \"prompt_eval_end_ms\": 1747876814586, \"first_token_ms\": 1747876814635, \"aggregate_sampling_time_ms\": 1974, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 41 Generated Tokens: 37\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.983000 (seconds)\t\t Rate: \t18.658598 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.060000 (seconds)\t\t Rate: \t683.333333 (tokens/second)\n",
            "\t\tGenerated 37 tokens:\t1.923000 (seconds)\t\t Rate: \t19.240770 (tokens/second)\n",
            "\tTime to first generated token:\t0.109000 (seconds)\n",
            "\tSampling time over 78 tokens:\t1.974000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 22, \"generated_tokens\": 15, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876816515, \"token_encode_end_ms\": 1747876816516, \"model_execution_start_ms\": 1747876817275, \"model_execution_end_ms\": 1747876817326, \"inference_end_ms\": 1747876817326, \"prompt_eval_end_ms\": 1747876816558, \"first_token_ms\": 1747876816607, \"aggregate_sampling_time_ms\": 806, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 22 Generated Tokens: 15\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.811000 (seconds)\t\t Rate: \t18.495684 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.043000 (seconds)\t\t Rate: \t511.627907 (tokens/second)\n",
            "\t\tGenerated 15 tokens:\t0.768000 (seconds)\t\t Rate: \t19.531250 (tokens/second)\n",
            "\tTime to first generated token:\t0.092000 (seconds)\n",
            "\tSampling time over 37 tokens:\t0.806000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 21, \"generated_tokens\": 15, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876817330, \"token_encode_end_ms\": 1747876817331, \"model_execution_start_ms\": 1747876818061, \"model_execution_end_ms\": 1747876818112, \"inference_end_ms\": 1747876818113, \"prompt_eval_end_ms\": 1747876817372, \"first_token_ms\": 1747876817420, \"aggregate_sampling_time_ms\": 778, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 21 Generated Tokens: 15\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.783000 (seconds)\t\t Rate: \t19.157088 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.042000 (seconds)\t\t Rate: \t500.000000 (tokens/second)\n",
            "\t\tGenerated 15 tokens:\t0.741000 (seconds)\t\t Rate: \t20.242915 (tokens/second)\n",
            "\tTime to first generated token:\t0.090000 (seconds)\n",
            "\tSampling time over 36 tokens:\t0.778000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 43, \"generated_tokens\": 34, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876818122, \"token_encode_end_ms\": 1747876818122, \"model_execution_start_ms\": 1747876821379, \"model_execution_end_ms\": 1747876821427, \"inference_end_ms\": 1747876821428, \"prompt_eval_end_ms\": 1747876818179, \"first_token_ms\": 1747876818228, \"aggregate_sampling_time_ms\": 3296, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 43 Generated Tokens: 34\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.306000 (seconds)\t\t Rate: \t10.284332 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.057000 (seconds)\t\t Rate: \t754.385965 (tokens/second)\n",
            "\t\tGenerated 34 tokens:\t3.249000 (seconds)\t\t Rate: \t10.464758 (tokens/second)\n",
            "\tTime to first generated token:\t0.106000 (seconds)\n",
            "\tSampling time over 77 tokens:\t3.296000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 38, \"generated_tokens\": 35, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876821442, \"token_encode_end_ms\": 1747876821443, \"model_execution_start_ms\": 1747876823236, \"model_execution_end_ms\": 1747876823284, \"inference_end_ms\": 1747876823285, \"prompt_eval_end_ms\": 1747876821504, \"first_token_ms\": 1747876821553, \"aggregate_sampling_time_ms\": 1827, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 38 Generated Tokens: 35\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.843000 (seconds)\t\t Rate: \t18.990776 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.062000 (seconds)\t\t Rate: \t612.903226 (tokens/second)\n",
            "\t\tGenerated 35 tokens:\t1.781000 (seconds)\t\t Rate: \t19.651881 (tokens/second)\n",
            "\tTime to first generated token:\t0.111000 (seconds)\n",
            "\tSampling time over 73 tokens:\t1.827000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 60, \"generated_tokens\": 55, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876823299, \"token_encode_end_ms\": 1747876823300, \"model_execution_start_ms\": 1747876826256, \"model_execution_end_ms\": 1747876826307, \"inference_end_ms\": 1747876826308, \"prompt_eval_end_ms\": 1747876823363, \"first_token_ms\": 1747876823413, \"aggregate_sampling_time_ms\": 2982, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 60 Generated Tokens: 55\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.009000 (seconds)\t\t Rate: \t18.278498 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.064000 (seconds)\t\t Rate: \t937.500000 (tokens/second)\n",
            "\t\tGenerated 55 tokens:\t2.945000 (seconds)\t\t Rate: \t18.675722 (tokens/second)\n",
            "\tTime to first generated token:\t0.114000 (seconds)\n",
            "\tSampling time over 115 tokens:\t2.982000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 48, \"generated_tokens\": 40, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876826326, \"token_encode_end_ms\": 1747876826327, \"model_execution_start_ms\": 1747876828479, \"model_execution_end_ms\": 1747876828528, \"inference_end_ms\": 1747876828529, \"prompt_eval_end_ms\": 1747876826383, \"first_token_ms\": 1747876826433, \"aggregate_sampling_time_ms\": 2190, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 48 Generated Tokens: 40\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.203000 (seconds)\t\t Rate: \t18.157059 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.057000 (seconds)\t\t Rate: \t842.105263 (tokens/second)\n",
            "\t\tGenerated 40 tokens:\t2.146000 (seconds)\t\t Rate: \t18.639329 (tokens/second)\n",
            "\tTime to first generated token:\t0.107000 (seconds)\n",
            "\tSampling time over 88 tokens:\t2.190000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 20, \"generated_tokens\": 13, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876828544, \"token_encode_end_ms\": 1747876828544, \"model_execution_start_ms\": 1747876829177, \"model_execution_end_ms\": 1747876829223, \"inference_end_ms\": 1747876829223, \"prompt_eval_end_ms\": 1747876828577, \"first_token_ms\": 1747876828626, \"aggregate_sampling_time_ms\": 674, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 20 Generated Tokens: 13\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.679000 (seconds)\t\t Rate: \t19.145803 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.033000 (seconds)\t\t Rate: \t606.060606 (tokens/second)\n",
            "\t\tGenerated 13 tokens:\t0.646000 (seconds)\t\t Rate: \t20.123839 (tokens/second)\n",
            "\tTime to first generated token:\t0.082000 (seconds)\n",
            "\tSampling time over 33 tokens:\t0.674000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 58, \"generated_tokens\": 45, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876829235, \"token_encode_end_ms\": 1747876829236, \"model_execution_start_ms\": 1747876832811, \"model_execution_end_ms\": 1747876832928, \"inference_end_ms\": 1747876832928, \"prompt_eval_end_ms\": 1747876829300, \"first_token_ms\": 1747876829353, \"aggregate_sampling_time_ms\": 3681, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 58 Generated Tokens: 45\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.693000 (seconds)\t\t Rate: \t12.185215 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.065000 (seconds)\t\t Rate: \t892.307692 (tokens/second)\n",
            "\t\tGenerated 45 tokens:\t3.628000 (seconds)\t\t Rate: \t12.403528 (tokens/second)\n",
            "\tTime to first generated token:\t0.118000 (seconds)\n",
            "\tSampling time over 103 tokens:\t3.681000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 51, \"generated_tokens\": 55, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876832939, \"token_encode_end_ms\": 1747876832939, \"model_execution_start_ms\": 1747876836118, \"model_execution_end_ms\": 1747876836169, \"inference_end_ms\": 1747876836169, \"prompt_eval_end_ms\": 1747876833105, \"first_token_ms\": 1747876833213, \"aggregate_sampling_time_ms\": 3212, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 51 Generated Tokens: 55\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t3.230000 (seconds)\t\t Rate: \t17.027864 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.166000 (seconds)\t\t Rate: \t307.228916 (tokens/second)\n",
            "\t\tGenerated 55 tokens:\t3.064000 (seconds)\t\t Rate: \t17.950392 (tokens/second)\n",
            "\tTime to first generated token:\t0.274000 (seconds)\n",
            "\tSampling time over 106 tokens:\t3.212000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 40, \"generated_tokens\": 31, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876836185, \"token_encode_end_ms\": 1747876836185, \"model_execution_start_ms\": 1747876837754, \"model_execution_end_ms\": 1747876837803, \"inference_end_ms\": 1747876837803, \"prompt_eval_end_ms\": 1747876836234, \"first_token_ms\": 1747876836282, \"aggregate_sampling_time_ms\": 1611, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 40 Generated Tokens: 31\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.618000 (seconds)\t\t Rate: \t19.159456 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.049000 (seconds)\t\t Rate: \t816.326531 (tokens/second)\n",
            "\t\tGenerated 31 tokens:\t1.569000 (seconds)\t\t Rate: \t19.757808 (tokens/second)\n",
            "\tTime to first generated token:\t0.097000 (seconds)\n",
            "\tSampling time over 71 tokens:\t1.611000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 32, \"generated_tokens\": 25, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876837817, \"token_encode_end_ms\": 1747876837818, \"model_execution_start_ms\": 1747876839077, \"model_execution_end_ms\": 1747876839145, \"inference_end_ms\": 1747876839146, \"prompt_eval_end_ms\": 1747876837864, \"first_token_ms\": 1747876837912, \"aggregate_sampling_time_ms\": 1317, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 32 Generated Tokens: 25\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t1.329000 (seconds)\t\t Rate: \t18.811136 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.047000 (seconds)\t\t Rate: \t680.851064 (tokens/second)\n",
            "\t\tGenerated 25 tokens:\t1.282000 (seconds)\t\t Rate: \t19.500780 (tokens/second)\n",
            "\tTime to first generated token:\t0.095000 (seconds)\n",
            "\tSampling time over 57 tokens:\t1.317000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 41, \"generated_tokens\": 40, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876839154, \"token_encode_end_ms\": 1747876839155, \"model_execution_start_ms\": 1747876841243, \"model_execution_end_ms\": 1747876841293, \"inference_end_ms\": 1747876841294, \"prompt_eval_end_ms\": 1747876839212, \"first_token_ms\": 1747876839264, \"aggregate_sampling_time_ms\": 2120, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 41 Generated Tokens: 40\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.140000 (seconds)\t\t Rate: \t18.691589 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.058000 (seconds)\t\t Rate: \t706.896552 (tokens/second)\n",
            "\t\tGenerated 40 tokens:\t2.082000 (seconds)\t\t Rate: \t19.212296 (tokens/second)\n",
            "\tTime to first generated token:\t0.110000 (seconds)\n",
            "\tSampling time over 81 tokens:\t2.120000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 20, \"generated_tokens\": 16, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876841301, \"token_encode_end_ms\": 1747876841301, \"model_execution_start_ms\": 1747876842085, \"model_execution_end_ms\": 1747876842131, \"inference_end_ms\": 1747876842132, \"prompt_eval_end_ms\": 1747876841342, \"first_token_ms\": 1747876841389, \"aggregate_sampling_time_ms\": 826, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 20 Generated Tokens: 16\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.831000 (seconds)\t\t Rate: \t19.253911 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.041000 (seconds)\t\t Rate: \t487.804878 (tokens/second)\n",
            "\t\tGenerated 16 tokens:\t0.790000 (seconds)\t\t Rate: \t20.253165 (tokens/second)\n",
            "\tTime to first generated token:\t0.088000 (seconds)\n",
            "\tSampling time over 36 tokens:\t0.826000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 20, \"generated_tokens\": 19, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876842139, \"token_encode_end_ms\": 1747876842140, \"model_execution_start_ms\": 1747876843058, \"model_execution_end_ms\": 1747876843106, \"inference_end_ms\": 1747876843107, \"prompt_eval_end_ms\": 1747876842179, \"first_token_ms\": 1747876842242, \"aggregate_sampling_time_ms\": 962, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 20 Generated Tokens: 19\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t0.968000 (seconds)\t\t Rate: \t19.628099 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.040000 (seconds)\t\t Rate: \t500.000000 (tokens/second)\n",
            "\t\tGenerated 19 tokens:\t0.928000 (seconds)\t\t Rate: \t20.474138 (tokens/second)\n",
            "\tTime to first generated token:\t0.103000 (seconds)\n",
            "\tSampling time over 39 tokens:\t0.962000 (seconds)\n",
            "\n",
            "⚠️ DISCLAIMER: Python-based perf measurements are approximate and may not match absolute speeds on Android/iOS apps. They are intended for relative comparisons—-e.g. SDPA vs. custom SDPA, FP16 vs. FP32—-so you can gauge performance improvements from each optimization step. For end-to-end, platform-accurate benchmarks, please use the official ExecuTorch apps:\n",
            "  • iOS:     https://github.com/pytorch/executorch/tree/main/extension/benchmark/apple/Benchmark\n",
            "  • Android: https://github.com/pytorch/executorch/tree/main/extension/benchmark/android/benchmark\n",
            "\n",
            "PyTorchObserver {\"prompt_tokens\": 30, \"generated_tokens\": 20, \"model_load_start_ms\": 0, \"model_load_end_ms\": 0, \"inference_start_ms\": 1747876843120, \"token_encode_end_ms\": 1747876843121, \"model_execution_start_ms\": 1747876845563, \"model_execution_end_ms\": 1747876845685, \"inference_end_ms\": 1747876845685, \"prompt_eval_end_ms\": 1747876843162, \"first_token_ms\": 1747876843214, \"aggregate_sampling_time_ms\": 2558, \"SCALING_FACTOR_UNITS_PER_SECOND\": 1000}\n",
            "\tPrompt Tokens: 30 Generated Tokens: 20\n",
            "\tModel Load Time:\t\t0.000000 (seconds)\n",
            "\tTotal inference time:\t\t2.565000 (seconds)\t\t Rate: \t7.797271 (tokens/second)\n",
            "\t\tPrompt evaluation:\t0.042000 (seconds)\t\t Rate: \t714.285714 (tokens/second)\n",
            "\t\tGenerated 20 tokens:\t2.523000 (seconds)\t\t Rate: \t7.927071 (tokens/second)\n",
            "\tTime to first generated token:\t0.094000 (seconds)\n",
            "\tSampling time over 50 tokens:\t2.558000 (seconds)\n"
          ]
        }
      ],
      "source": [
        "# затраченное время: 2 часа 28 минут\n",
        "tokens_count[\"ExecuTorch\"], latency[\"ExecuTorch\"], translations[\"ExecuTorch\"] = translate_exet(model_exet, tokenizer, dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfMDMZ_JhxQD"
      },
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MuVy_mChxQA",
        "outputId": "f61041b8-8a0a-41c4-8d33-6fdf89216e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Модель по пути /content/drive/MyDrive/tmp/models/t5_pruned_0.2_finetuned уже была сохранена ранее, используем её!\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(MODELS_DIR + MODEL_NAME):\n",
        "    print(\"Скачиваю и сохраняю модель...\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(MODELS_DIR + MODEL_NAME)\n",
        "    tokenizer = T5Tokenizer.from_pretrained(MODELS_DIR + MODEL_NAME)\n",
        "\n",
        "    model.save_pretrained(MODELS_DIR + MODEL_NAME, from_pt=True) # сохранение модели\n",
        "    tokenizer.save_pretrained(MODELS_DIR + MODEL_NAME) # сохранение токенизатора\n",
        "else:\n",
        "    print(f\"Модель по пути {MODELS_DIR + MODEL_NAME} уже была сохранена ранее, используем её!\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(MODELS_DIR + MODEL_NAME)\n",
        "    tokenizer = T5Tokenizer.from_pretrained(MODELS_DIR + MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xl3grslvhxQE"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def translate_pytorch(model, tokenizer, texts) -> tuple:\n",
        "    tokens_count = [] # список под количество токенов в тексте\n",
        "    latency = [] # список под величину задержки между запуском модели и выводом ответа\n",
        "    translations = [] # список под переводы\n",
        "\n",
        "    if isinstance(texts, str): # если пришёл объект типа строки\n",
        "        texts = [texts] # делаем из объекта список с одним элементом\n",
        "    elif isinstance(texts, Dataset) or isinstance(texts, dict): # если пришёл объект типа Dataset или словарь (полученный с помощью среза объекта Dataset)\n",
        "        texts = texts[\"src\"] # берём из него только текста, что нужно переводить\n",
        "\n",
        "    model.eval() # перевод модели в режим оценивания (dropout перестаёт работать, а BatchNorm собирать статистику)\n",
        "\n",
        "    model = torch.compile(model) # компилируем модель для оптимизации скорости работы\n",
        "\n",
        "    with torch.no_grad(): # отключаем подсчёт градиентов\n",
        "        for text in tqdm(texts):\n",
        "            time_start = time.time() # замеряем время начала работы  с моделью\n",
        "            tokens_encoded = tokenizer(text, max_length=MAX_SEQUENCE_LEN, return_tensors=\"pt\", truncation=True, padding=True) # токенизируем данные (max_length — максимальное число токенов в документе, return_tensors — тип возвращаемых данных, np для numpy.array, pt для torch.tensor; truncation и padding — обрезание лишних токенов и автозаполнение недостающих до max_length)\n",
        "            tokens_generated = model.generate(**tokens_encoded) # генерируем новую последовательность токенов (переводим текст)\n",
        "\n",
        "            latency.append(time.time()  - time_start)\n",
        "            tokens_count.append(tokens_encoded[\"input_ids\"].shape[1]) # запоминаем количество токенов\n",
        "            translations.append(tokenizer.decode(tokens_generated[0], skip_special_tokens=True)) # декодирование последовательности токенов, skip_special_tokens — выводить ли специальные токены\n",
        "    return tokens_count, latency, translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "846cc56c63764f1ab7078ff8e3d5253b",
            "5d7c6d5a8aa44defb52a616a4fcc3200",
            "751b2bc0ea574360b7ddcd6ab0321cfc",
            "0ce7f5a7f4f34875a2e5f76c7ab1c1ad",
            "2fd8ea7f4d464746825a84a4bab5b493",
            "68a515ae47344cb98647b5188c126dde",
            "b0638526152e45d29b202295136100c4",
            "335d41d1236e4a0fa991c9c2f3291044",
            "e1ac9da6441143b795947e7f9f0da62e",
            "e3390ba3aa5345c29be3e4a30939f220",
            "94a31662eeaa489c863a51b838bc6453"
          ]
        },
        "id": "IWfx9pY1hxQE",
        "outputId": "bd351839-21c7-4fa0-f76c-129455fe8f42"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "846cc56c63764f1ab7078ff8e3d5253b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# затраченное время: 2 часа 19 минут\n",
        "tokens_count[\"PyTorch\"], latency[\"PyTorch\"], translations[\"PyTorch\"] = translate_pytorch(model, tokenizer, dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eHQQyxThxQH"
      },
      "source": [
        "## ONNX (optimum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifzhh0JihxQI",
        "outputId": "4890363b-2b3c-413b-b863-6941226d2879"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py:1318: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if sequence_length != 1:\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py:457: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  or not self.key_cache[layer_idx].numel()  # the layer has no cache\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py:440: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  elif (\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<optimum.onnxruntime.modeling_seq2seq.ORTModelForSeq2SeqLM at 0x7f6d23cd6450>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_onnx = ORTModelForSeq2SeqLM.from_pretrained(MODELS_DIR + MODEL_NAME, export=True) # export — для моделей трансформеров с версии optimum>=2.0, from_transformers — для optimum<2.0\n",
        "\n",
        "if not os.path.exists(MODELS_DIR + \"t5_ONNX\"):\n",
        "    model_onnx.save_pretrained(MODELS_DIR + \"t5_ONNX\")\n",
        "    tokenizer.save_pretrained(MODELS_DIR + \"t5_ONNX\")\n",
        "\n",
        "model_onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "F47Tq1Q6hxQI"
      },
      "outputs": [],
      "source": [
        "def translate_onnx(model, tokenizer, texts) -> tuple:\n",
        "    tokens_count = [] # список под количество токенов в тексте\n",
        "    latency = [] # список под величину задержки между запуском модели и выводом ответа\n",
        "    translations = [] # список под переводы\n",
        "\n",
        "    if isinstance(texts, str): # если пришёл объект типа строки\n",
        "        texts = [texts] # делаем из объекта список с одним элементом\n",
        "    elif isinstance(texts, Dataset) or isinstance(texts, dict): # если пришёл объект типа Dataset или словарь (полученный с помощью среза объекта Dataset)\n",
        "        texts = texts[\"src\"] # берём из него только текста, что нужно переводить\n",
        "\n",
        "    for text in tqdm(texts):\n",
        "        time_start = time.time() # замеряем время начала работы  с моделью\n",
        "        tokens_encoded = tokenizer(text, max_length=MAX_SEQUENCE_LEN, return_tensors=\"pt\", truncation=True, padding=True) # токенизируем данные (max_length — максимальное число токенов в документе, return_tensors — тип возвращаемых данных, np для numpy.array, pt для torch.tensor; truncation и padding — обрезание лишних токенов и автозаполнение недостающих до max_length)\n",
        "        tokens_generated = model.generate(**tokens_encoded) # генерируем новую последовательность токенов (переводим текст)\n",
        "\n",
        "        latency.append(time.time()  - time_start)\n",
        "        tokens_count.append(tokens_encoded[\"input_ids\"].shape[1]) # запоминаем количество токенов\n",
        "        translations.append(tokenizer.decode(tokens_generated[0], skip_special_tokens=True)) # декодирование последовательности токенов, skip_special_tokens — выводить ли специальные токены\n",
        "    return tokens_count, latency, translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2585e621c0894d84aeb21446c675c6da",
            "ca6f01005c6144cdb03e739c1851fcf4",
            "1e627f156d354dc2a009bae9496b9ef4",
            "1fee0bd838334505a7bbef5b4abb3c50",
            "7f91c2cead89495aa0c8ea7d2b55efb5",
            "e9a58fca9453456889d2215e20fbfc91",
            "985ec8892ef94587bfaa1e085e4e9154",
            "df89159858eb4f34be373edb6a4e3983",
            "9309a56c69b74cd5b92d8fc5b2ea938f",
            "8b14b3fbc1954b2487361e06229e2885",
            "c153d59db1004af3b38f6660d4b9fba3"
          ]
        },
        "id": "50saKldFhxQI",
        "outputId": "c3370601-4066-493b-bad4-399d413ab335"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2585e621c0894d84aeb21446c675c6da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# затраченное время: 52 минуты\n",
        "tokens_count[\"ONNX\"], latency[\"ONNX\"], translations[\"ONNX\"] = translate_onnx(model_onnx, tokenizer, dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifNnKclThxQK"
      },
      "source": [
        "## OpenVINO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KMB-bUr_iis",
        "outputId": "db79ddae-9009-44c6-d97a-490240ed5e7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        }
      ],
      "source": [
        "from optimum.intel.openvino import OVModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1-47St9hxQM",
        "outputId": "46be8188-980c-4f6f-853a-2c5e43d7c290"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "WARNING:root:Cannot apply model.to_bettertransformer because of the exception:\n",
            "BetterTransformer requires transformers<4.49 but found 4.51.3. `optimum.bettertransformer` is deprecated and will be removed in optimum v2.0.. Usage model with stateful=True may be non-effective if model does not contain torch.functional.scaled_dot_product_attention\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py:457: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  or not self.key_cache[layer_idx].numel()  # the layer has no cache\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py:1318: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if sequence_length != 1:\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py:440: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  elif (\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<optimum.intel.openvino.modeling_seq2seq.OVModelForSeq2SeqLM at 0x7f6d29ebb0d0>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_ov = OVModelForSeq2SeqLM.from_pretrained(MODELS_DIR + MODEL_NAME, export=True) # export — для моделей трансформеров с версии optimum>=2.0, from_transformers — для optimum<2.0\n",
        "\n",
        "if not os.path.exists(MODELS_DIR + \"t5_openVINO\"):\n",
        "    model_ov.save_pretrained(MODELS_DIR + \"t5_openVINO\")\n",
        "    tokenizer.save_pretrained(MODELS_DIR + \"t5_openVINO\")\n",
        "\n",
        "model_ov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ep06iFCyhxQM"
      },
      "outputs": [],
      "source": [
        "def translate_ov(model, tokenizer, texts) -> tuple:\n",
        "    tokens_count = [] # список под количество токенов в тексте\n",
        "    latency = [] # список под величину задержки между запуском модели и выводом ответа\n",
        "    translations = [] # список под переводы\n",
        "\n",
        "    if isinstance(texts, str): # если пришёл объект типа строки\n",
        "        texts = [texts] # делаем из объекта список с одним элементом\n",
        "    elif isinstance(texts, Dataset) or isinstance(texts, dict): # если пришёл объект типа Dataset или словарь (полученный с помощью среза объекта Dataset)\n",
        "        texts = texts[\"src\"] # берём из него только текста, что нужно переводить\n",
        "\n",
        "    for text in tqdm(texts):\n",
        "        time_start = time.time() # замеряем время начала работы  с моделью\n",
        "        tokens_encoded = tokenizer(text, max_length=MAX_SEQUENCE_LEN, return_tensors=\"pt\", truncation=True, padding=True) # токенизируем данные (max_length — максимальное число токенов в документе, return_tensors — тип возвращаемых данных, np для numpy.array, pt для torch.tensor; truncation и padding — обрезание лишних токенов и автозаполнение недостающих до max_length)\n",
        "        tokens_generated = model.generate(**tokens_encoded) # генерируем новую последовательность токенов (переводим текст)\n",
        "\n",
        "        latency.append(time.time()  - time_start)\n",
        "        tokens_count.append(tokens_encoded[\"input_ids\"].shape[1]) # запоминаем количество токенов\n",
        "        translations.append(tokenizer.decode(tokens_generated[0], skip_special_tokens=True)) # декодирование последовательности токенов, skip_special_tokens — выводить ли специальные токены\n",
        "    return tokens_count, latency, translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "967d47843d134fd3b28915e3b1e4463b",
            "0ca5cf698bdf4e3192ed006827eb4e43",
            "8a840f178acc4f4680a78c2b0534f9bd",
            "7f4a9eeb068b49359a7cb62fc82f6d2e",
            "701f56278ee141c895a6f5c62e269086",
            "939d6b6e67be435c839402b6082cfd09",
            "baf1c9eb192b4591bb5a8b71601f262a",
            "d57ce600befb4a08b568885c26988eba",
            "31caa162f60543a8a0030d5ed8442f30",
            "26a80cfb9cc24a37993f441b9c9c1609",
            "20073ee424d245e0a11f38dba9451485"
          ]
        },
        "id": "372hnoQFhxQM",
        "outputId": "cc6e3c41-9f09-4577-e38c-c1640e0ae45e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "967d47843d134fd3b28915e3b1e4463b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# затраченное время: 1 час 3 минуты\n",
        "tokens_count[\"openVINO\"], latency[\"openVINO\"], translations[\"openVINO\"] = translate_ov(model_ov, tokenizer, dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxBTBIzjhxQO"
      },
      "source": [
        "## Latency charts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "S_RySEI2hxQO"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(RESULTS_DIR + \"runtimes\"):\n",
        "    os.makedirs(RESULTS_DIR + \"runtimes\")\n",
        "\n",
        "with open(RESULTS_DIR + \"runtimes/tokens_count.json\", mode='w', encoding='utf-8') as f: # открываем файл для записи (w — не побитовой)\n",
        "    json.dump(tokens_count, f, ensure_ascii=False, indent=4) # сохраняем объект в файл f\n",
        "with open(RESULTS_DIR + \"runtimes/latency.json\", mode='w', encoding='utf-8') as f: # открываем файл для записи (w — не побитовой)\n",
        "    json.dump(latency, f, ensure_ascii=False, indent=4) # сохраняем объект в файл f\n",
        "with open(RESULTS_DIR + \"runtimes/translations.json\", mode='w', encoding='utf-8') as f: # открываем файл для записи (w — не побитовой)\n",
        "    json.dump(translations, f, ensure_ascii=False, indent=4) # сохраняем объект в файл f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ACEW2IDwhxQO",
        "outputId": "a02406f9-87ea-48e4-c1ee-23c720d4503a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ExecuTorch: затрачиваемое время увеличивается, в среднем, на 0.05841 секунд за каждый новый токен, при этом модель работает не менее -0.25661 секунд.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch: затрачиваемое время увеличивается, в среднем, на 0.04854 секунд за каждый новый токен, при этом модель работает не менее -0.01646 секунд.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX: затрачиваемое время увеличивается, в среднем, на 0.01853 секунд за каждый новый токен, при этом модель работает не менее -0.01955 секунд.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "openVINO: затрачиваемое время увеличивается, в среднем, на 0.02187 секунд за каждый новый токен, при этом модель работает не менее -0.00335 секунд.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "approximations = {}\n",
        "\n",
        "for runtime in latency.keys():\n",
        "    results = pd.DataFrame({\"Tokens count\": tokens_count[runtime], \"Latency\": latency[runtime]}) # собираем данные в DataFrame\n",
        "    results.sort_values(by=[\"Tokens count\"], inplace=True)\n",
        "    results.reset_index(drop=True, inplace=True) # обновляем индексы, так как они остались от предыдущего варианта датасета (inplace=True - перезаписываем существующий датасет)\n",
        "\n",
        "    stats = results.groupby(by=\"Tokens count\", as_index=True).agg(mean=(\"Latency\", \"mean\"),\n",
        "                                                                std=(\"Latency\", \"std\")\n",
        "                                                                )\n",
        "\n",
        "    outlier_indexes = []\n",
        "\n",
        "    for index in results.index:\n",
        "        tokens_count_, latency_ = results.loc[index]\n",
        "        if np.abs(latency_ - stats.loc[tokens_count_][\"mean\"]) > 3 * stats.loc[tokens_count_][\"std\"]:\n",
        "            outlier_indexes.append(index)\n",
        "\n",
        "    results.drop(outlier_indexes, inplace=True)\n",
        "\n",
        "    stats = results.groupby(by=\"Tokens count\", as_index=True).agg(mean=(\"Latency\", \"mean\"),\n",
        "                                                                std=(\"Latency\", \"std\")\n",
        "                                                                )\n",
        "\n",
        "    a, b = np.polyfit(stats.index[:100], stats[\"mean\"][:100], deg=1) # считаем линейную аппроксимацию (deg=1), [:100] — так как после идёт большой разброс по времени из-за малой представленности в датасете\n",
        "    approximations[runtime] = [a, b]\n",
        "    print(f\"{runtime}: затрачиваемое время увеличивается, в среднем, на {a:.5f} секунд за каждый новый токен, при этом модель работает не менее {b:.5f} секунд.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(25,10)) # задание размера фигуры\n",
        "    sns.boxplot(x=results[\"Tokens count\"], y=results[\"Latency\"], native_scale=True, showfliers=False) # строим \"ящики с усами\", showfliers — отображать ли выбросы, native_scale — воспринимать ли ось X как непрерывную (а не категориальную)\n",
        "\n",
        "    x = np.linspace(stats.index[0], stats.index[-1])\n",
        "    # x = stats.index.to_numpy() # рассмотренные значения по оси x для линейного графика\n",
        "    y = a * x + b\n",
        "    sns.lineplot(x=x, y=y, color=\"red\", label=\"Аппроксимация\")\n",
        "    # sns.pointplot(x=x, y=y, color=\"red\", label=\"Аппроксимация\") # pointplot в данном случае идёт как аналог линейного графика, у которого ось X воспринимается \"категориально\", то есть так же, как в boxplot\n",
        "\n",
        "    plt.xticks(rotation=45, ha='right') # поворот на 45 градусов подписей под осью OX (ha='right' ~ правый конец соответствует колонке)\n",
        "    plt.title(\"Зависимость времени перевода от размера текста\") # название фигуры\n",
        "    plt.xlabel(\"Количество токенов\") # подпись по оси x\n",
        "    plt.ylabel(\"Задержка перевода (latency, sec)\") # подпись по оси y\n",
        "    plt.legend() # отображение подписей графиков\n",
        "    plt.savefig(f\"{RESULTS_DIR}runtimes/latency_{runtime}.png\", dpi=\"figure\", bbox_inches=\"tight\", facecolor=\"white\") # сохранение графика\n",
        "    plt.show() # показ фигуры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Lup7yyTIjLxj"
      },
      "outputs": [],
      "source": [
        "colors = {\n",
        "    \"PyTorch\": \"blue\",\n",
        "    \"ExecuTorch\": \"red\",\n",
        "    \"ONNX\": \"green\",\n",
        "    \"openVINO\": \"orange\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "L9oaWs8ahxQO",
        "outputId": "81838ea6-e43a-41d5-a3c2-f63b196908dc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(25,10)) # задание размера фигуры\n",
        "\n",
        "x = np.linspace(1, 256)\n",
        "\n",
        "for runtime in approximations.keys():\n",
        "    a, b = approximations[runtime]\n",
        "    y = a * x + b\n",
        "    sns.lineplot(x=x, y=y, label=runtime, color=colors[runtime], linewidth=3.0)\n",
        "\n",
        "plt.axis([10, 256, 0, 20])\n",
        "plt.xticks(rotation=45, ha='right') # поворот на 45 градусов подписей под осью OX (ha='right' ~ правый конец соответствует колонке)\n",
        "plt.title(\"Зависимость времени перевода от количества токенов\") # название фигуры\n",
        "plt.xlabel(\"Количество токенов\") # подпись по оси x\n",
        "plt.ylabel(\"Задержка перевода (latency, sec)\") # подпись по оси y\n",
        "plt.legend() # отображение подписей графиков\n",
        "plt.savefig(f\"{RESULTS_DIR}runtimes/latency_comparison.png\", dpi=\"figure\", bbox_inches=\"tight\", transparent=False, facecolor=\"white\") # сохранение графика\n",
        "plt.show() # показ фигуры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L36BJW4dhxQP"
      },
      "source": [
        "# BLEU check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibChKKRfhxQP",
        "outputId": "d367d751-daa3-407e-e598-576bbc7e929e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "metric_BLEU = evaluate.load(\"bleu\") # загружаем метрику\n",
        "\n",
        "def compute_metrics(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels] # создаём список возможных переводов\n",
        "\n",
        "    metric = metric_BLEU.compute(predictions=preds, references=labels)[\"bleu\"]\n",
        "    return metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeJfr4VmhxQP",
        "outputId": "a3c31d1e-53fe-457b-e561-c290a8cdab34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU для рантайма ExecuTorch: 0.27302\n",
            "BLEU для рантайма PyTorch: 0.27558\n",
            "BLEU для рантайма ONNX: 0.27558\n",
            "BLEU для рантайма openVINO: 0.27566\n"
          ]
        }
      ],
      "source": [
        "for runtime in translations.keys():\n",
        "    bleu = compute_metrics(translations[runtime], dataset[\"test\"][\"tgt\"])\n",
        "    with open(RESULTS_DIR + f\"runtimes/bleu_{runtime}.json\", mode='w', encoding='utf-8') as f: # открываем файл для записи (w — не побитовой)\n",
        "        json.dump(bleu, f, ensure_ascii=False, indent=4) # сохраняем объект в файл f\n",
        "    print(f\"BLEU для рантайма {runtime}: {bleu:.5f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b30ac49f9d748b497589b694bc35051": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4782776578346d58e929e3dc0f33b2e",
            "placeholder": "​",
            "style": "IPY_MODEL_6fb6d72af4684caa9ada9fd29efd74a9",
            "value": "100%"
          }
        },
        "0ca5cf698bdf4e3192ed006827eb4e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_939d6b6e67be435c839402b6082cfd09",
            "placeholder": "​",
            "style": "IPY_MODEL_baf1c9eb192b4591bb5a8b71601f262a",
            "value": "100%"
          }
        },
        "0ce7f5a7f4f34875a2e5f76c7ab1c1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3390ba3aa5345c29be3e4a30939f220",
            "placeholder": "​",
            "style": "IPY_MODEL_94a31662eeaa489c863a51b838bc6453",
            "value": " 5000/5000 [2:19:23&lt;00:00,  1.42s/it]"
          }
        },
        "1e627f156d354dc2a009bae9496b9ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df89159858eb4f34be373edb6a4e3983",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9309a56c69b74cd5b92d8fc5b2ea938f",
            "value": 5000
          }
        },
        "1fee0bd838334505a7bbef5b4abb3c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b14b3fbc1954b2487361e06229e2885",
            "placeholder": "​",
            "style": "IPY_MODEL_c153d59db1004af3b38f6660d4b9fba3",
            "value": " 5000/5000 [52:18&lt;00:00,  1.93it/s]"
          }
        },
        "20073ee424d245e0a11f38dba9451485": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2585e621c0894d84aeb21446c675c6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca6f01005c6144cdb03e739c1851fcf4",
              "IPY_MODEL_1e627f156d354dc2a009bae9496b9ef4",
              "IPY_MODEL_1fee0bd838334505a7bbef5b4abb3c50"
            ],
            "layout": "IPY_MODEL_7f91c2cead89495aa0c8ea7d2b55efb5"
          }
        },
        "26a80cfb9cc24a37993f441b9c9c1609": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fd8ea7f4d464746825a84a4bab5b493": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31caa162f60543a8a0030d5ed8442f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "335d41d1236e4a0fa991c9c2f3291044": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43505cac29dc40c19c8181b12e81d10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d7c6d5a8aa44defb52a616a4fcc3200": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a515ae47344cb98647b5188c126dde",
            "placeholder": "​",
            "style": "IPY_MODEL_b0638526152e45d29b202295136100c4",
            "value": "100%"
          }
        },
        "68a515ae47344cb98647b5188c126dde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f1c49395ce4978ac7e8bb6342174b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a55910e5224b41804912c6ac68fb5b",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43505cac29dc40c19c8181b12e81d10b",
            "value": 5000
          }
        },
        "6fb6d72af4684caa9ada9fd29efd74a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "701f56278ee141c895a6f5c62e269086": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "751b2bc0ea574360b7ddcd6ab0321cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_335d41d1236e4a0fa991c9c2f3291044",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1ac9da6441143b795947e7f9f0da62e",
            "value": 5000
          }
        },
        "7f4a9eeb068b49359a7cb62fc82f6d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26a80cfb9cc24a37993f441b9c9c1609",
            "placeholder": "​",
            "style": "IPY_MODEL_20073ee424d245e0a11f38dba9451485",
            "value": " 5000/5000 [1:03:18&lt;00:00,  1.50it/s]"
          }
        },
        "7f91c2cead89495aa0c8ea7d2b55efb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838d57a56a5e40cca724b2c814ad1c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "846cc56c63764f1ab7078ff8e3d5253b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d7c6d5a8aa44defb52a616a4fcc3200",
              "IPY_MODEL_751b2bc0ea574360b7ddcd6ab0321cfc",
              "IPY_MODEL_0ce7f5a7f4f34875a2e5f76c7ab1c1ad"
            ],
            "layout": "IPY_MODEL_2fd8ea7f4d464746825a84a4bab5b493"
          }
        },
        "87378b29de5741288730e23800f80097": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89eb3b78d1054a21916213b4c061eec7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a840f178acc4f4680a78c2b0534f9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d57ce600befb4a08b568885c26988eba",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31caa162f60543a8a0030d5ed8442f30",
            "value": 5000
          }
        },
        "8b14b3fbc1954b2487361e06229e2885": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9309a56c69b74cd5b92d8fc5b2ea938f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "939d6b6e67be435c839402b6082cfd09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94a31662eeaa489c863a51b838bc6453": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96028b1182774d09bbf5b0dfe617bbe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87378b29de5741288730e23800f80097",
            "placeholder": "​",
            "style": "IPY_MODEL_838d57a56a5e40cca724b2c814ad1c8a",
            "value": " 5000/5000 [2:28:33&lt;00:00,  1.81s/it]"
          }
        },
        "967d47843d134fd3b28915e3b1e4463b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ca5cf698bdf4e3192ed006827eb4e43",
              "IPY_MODEL_8a840f178acc4f4680a78c2b0534f9bd",
              "IPY_MODEL_7f4a9eeb068b49359a7cb62fc82f6d2e"
            ],
            "layout": "IPY_MODEL_701f56278ee141c895a6f5c62e269086"
          }
        },
        "985ec8892ef94587bfaa1e085e4e9154": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98a55910e5224b41804912c6ac68fb5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4782776578346d58e929e3dc0f33b2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0638526152e45d29b202295136100c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baf1c9eb192b4591bb5a8b71601f262a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c153d59db1004af3b38f6660d4b9fba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca6f01005c6144cdb03e739c1851fcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9a58fca9453456889d2215e20fbfc91",
            "placeholder": "​",
            "style": "IPY_MODEL_985ec8892ef94587bfaa1e085e4e9154",
            "value": "100%"
          }
        },
        "d57ce600befb4a08b568885c26988eba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df89159858eb4f34be373edb6a4e3983": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ac9da6441143b795947e7f9f0da62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3390ba3aa5345c29be3e4a30939f220": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9a58fca9453456889d2215e20fbfc91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43cf28e61fc4bada1a957b33290c295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b30ac49f9d748b497589b694bc35051",
              "IPY_MODEL_69f1c49395ce4978ac7e8bb6342174b4",
              "IPY_MODEL_96028b1182774d09bbf5b0dfe617bbe6"
            ],
            "layout": "IPY_MODEL_89eb3b78d1054a21916213b4c061eec7"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
